Higher-order Comparisons of Sentence Encoder Representations Mostafa Abdou† Artur Kulmizev♣ Felix Hill♦ Daniel M. Low♠ Anders Søgaard† †Department of Computer Science, University of Copenhagen abdou,soegaard@di.ku.dk ♣Department of Linguistics and Philology, Uppsala University artur.kulmizev@lingfil.uu.se ♦DeepMind felixhill@google.com ♠Program in Speech and Hearing Bioscience and Technology, Harvard Medical School-MIT dlow@mit.edu Abstract resentational methods and modalities (e.g. behav- ioral data, fMRI measurements, etc.). In context of Representational Similarity Analysis (RSA) is the latter concern, the present-day interpretability a technique developed by neuroscientists for toolkit has not yet been able to afford a practical comparing activity patterns of different mea- way of reconciling this. surement modalities (e.g., fMRI, electrophys- iology, behavior). As a framework, RSA has In this work, we employ Representational Simi- several advantages over existing approaches to larity Analysis (RSA) as a simple method of inter- interpretation of language encoders based on preting neural models’ representational spaces as probing or diagnostic classification: namely, they relate to other models and modalities. In par- it does not require large training samples, is not prone to overfitting, and it enables a more ticular, we conduct an experiment wherein we in- transparent comparison between the represen- vestigate the correspondence between human pro- tational geometries of different models and cessing difficulty (as reflected by gaze fixation modalities. We demonstrate the utility of RSA measurements) and the representations induced by by establishing a previously unknown cor- popular pretrained language models. In our exper- respondence between widely-employed pre- iments, we hypothesize that there exists an over- trained language encoders and human process- lap between the sentences which are difficult for ing difficulty via eye-tracking data, showcas- humans to process and those for which per-layer ing its potential in the interpretability toolbox for neural models. encoder representations are least correlated. Our intuition is that such sentences may exhibit 1 Introduction factors such as low-frequency vocabulary, lexical Examining the parallels between human and ma- ambiguity, and syntactic complexity (e.g. multi- chine learning is a natural way for us to better un- ple embedded clauses), etc. that are uncommon in derstand the former and track our progress in the both standard language and, relatedly, the corpora latter. The “black box” aspect of neural networks employed in training large-scale language mod- has recently inspired a large body of work related els. In the case of a human reader, encountering to interpretability, i.e. understanding of represen- such a sentence may result in a number of pro- tations that such models learn. In NLP, this push cessing delays, e.g. longer aggregate gaze dura- has been largely motivated by linguistic questions, tion. In the case of a sentence encoder, an un- such as: what linguistic properties are captured by common sentence may lead to a degradation of neural networks? and to what extent do decisions representations in the encoder’s layers, wherein a made by neural models reflect established linguis- lower layer might learn to encode vastly different tic theories? Given the relative recency of such information than a higher one. Similarly, differ- questions, much work in the domain so far has ent models’ representations may emphasize differ- been focused on the context of models in isolation ent aspects of these more complex sentences and (e.g. what does model X learn about linguistic therefore diverge from each other. With this in phenomenon Y?) In order to more broadly under- mind, our hypothesis is that sentences which are stand models’ representational tendencies, how- difficult for humans to process are likely to have ever, it is vital that such questions be formed not divergent representations within models’ internal only with other models in mind, but also other rep- layers and between different models’ layers. 9102 peS 5 ]LC.sc[ 2v30300.9091:viXra
Understanding and analysing language en- multi-task neural pipeline. Similarly, Bouchacourt coders In recent years, some prominent efforts and Baroni (2018) used the framework to measure towards interpreting neural networks for NLP have the similarity between input image embeddings included: developing suites that evaluate network and the representations of the same image by an representations through performance on down- agent in an language game setting. More recently, stream tasks (Conneau et al., 2017a; Wang et al., Chrupała and Alishahi (2019) correlated activation 2018; McCann et al., 2018); analyzing network patterns of sentence encoders with symbolic rep- predictions on carefully curated datasets (Linzen resentations, such as syntax trees. Lastly, similar et al., 2016; Marvin and Linzen, 2018; Gulordava to our work here, Abnar et al. (2019) proposed an et al., 2018; Loula et al., 2018; Dasgupta et al., extension to RSA that enables the comparison of 2018; Tenney et al., 2018); and employing diag- a single model in the face of isolated, changing nostic classifiers to assess whether certain classes parameters, and employed this metric along with of information are encoded in a model’s (interme- RSA to correlate NLP models’ and human brains’ diate) representations (Adi et al., 2016; Chrupała respective representations of language. We hope et al., 2017; Hupkes et al., 2017; Belinkov et al., to position our work among this brief survey and 2017). further demonstrate the flexibility of RSA across several levels of abstraction. While these approaches provide valuable in- sights into how neural networks process a large 2 Representational Similarity Analysis variety of phenomena, they rely on decoding ac- curacy as a probe for encoded linguistic informa- RSA was proposed by Kriegeskorte et al. (2008) tion. If properly biased, this means that they can as a method of relating the different representa- detect whether information is encoded in a rep- tional modalities employed in neuroscientific stud- resentation or not. However, they do not allow ies. Due to the lack of correspondence between the for a direct comparison of representational struc- activity patterns of disparate measurement modal- ture between models. Consider a toy dataset of ities (e.g. brain activity via fMRI, behavioural five sentences of interest and three encodings de- responses), RSA aims to abstract away from the rived from quite different processing models; a activity patterns themselves and instead compute hidden state of a trained neural language model, a representational dissimilarity matrices (RDMs), tf-idf weighted bag-of-words representation, and which characterize the information carried by a measurements of fixation duration from an eye- given representation method through dissimilarity tracking device. Probing methods do not allow us structure. to quantify or visualise, for each of these encoding Given a set of representational methods (e.g., strategies, how the encoder’s responses to the five pretrained encoders) M and a set of experimental sentences relate to each other. Moreover, probing conditions (sentences) N , we can construct RDMs methods would not directly reveal whether the fix- for each method in M . Each cell in an RDM cor- ations from the eye-tracking device aligned more responds to the dissimilarity between the activity closely with the tf-idf representation or the states patterns associated with pairs of experimental con- of the neural language model. In short, while ditions n , n ∈ N , say, a pair of sentences. When i j probing classifier methods can establish if phe- n = n , the dissimilarity between an experimen- i j nomena are separable based on the provided repre- tal condition and itself is intuitively 0, thus making sentations, they do not tell us about the overall ge- the N × N RDM symmetric along a diagonal of ometry of the representational spaces. RSA, on the zeros (Kriegeskorte et al., 2008). other hand, provides a basis for higher-order com- The RDMs of the different representational parisons between spaces of representations, and a methods in M can then be directly compared in way to visualise and quantify the extent to which a Representational Similarity Matrix (RSM). This they are isomorphic. comparison of RDMs is known as second-order Indeed, RSA has seen a modest introduction analysis, which is broadly based on the idea of within interpretable NLP in recent years. For ex- a second-order isomorphism (Shepard and Chip- ample, Chrupała et al. (2017) employed RSA as man, 1970). In such an analysis, the principal a means of correlating encoder representations of point of comparison is the match between the speech, text, and images in a post-hoc analysis of a dissimilarity structure of the different representa-
Figure 1: An example of first- and second-order analyses, where N = # of experimental conditions, M = # of models, and H = # of activity patterns observed for a given model (i.e. dimensionality). The right-most side of the figure depicts a representational similairty matrix (RSM) of correlations between RDMs. tional methods. Intuitively, this can be expressed human readers (Raney et al., 2014; Ashby et al., through the notion of distance between distances, 2005) and to be dependent upon a number of lin- and is thus related to Earth Mover’s Distance guistic factors (Van Gompel, 2007). Specifically, (Rubner et al., 2000).1 Figure 1 shows an illus- it has been demonstrated that word frequency, syn- tration of the first and second order analyses for tactic complexity, and lexical ambiguity play a pretrained language encoders. strong part in determining which sentences are dif- Note that RSA is meaningfully different from, ficult for humans to process (Rayner and Duffy, and complementary to, methods that employ sat- 1986; Duffy et al., 1988; Levy, 2008). urating functions of representation distances (e.g. Using the RSA framework, we aim to explore decoding F1-score, mutual information), which how gaze fixation patterns and the linguistic fac- suffer from (a) a ceiling effect: being able to tors associated with sentence processing difficulty distinguish experimental phenomenon A from B relate to the representational spaces of popular lan- with with an F1-score of 100% and experimental guage encoders. Namely, we hypothesize that, for phenomenon C from D with an F1-score of 100% a given sentence, disagreement between hidden does not mean that the distance between A and B layers corresponds to processing difficulty. Be- is the same as that between C and D; and (b) dis- cause layer disagreement for a sentence measures cretization (Nili et al., 2014). the extent to which two layers (e.g. within BERT) We follow Kriegeskorte et al. (2008) in us- disagree with each other about the pairwise simi- ing the correlation distance of experimental con- larity of the sentence (with other sentences in the dition pairs n , n ∈ N as a dissimilarity mea- corpus), a sentence with high layer disagreement i j sure, where n¯ is the mean of n ’s elements, · is will have unstable similarity relationships to other i i the dot product, and (cid:107) is the l norm: corr(x) = sentences in the corpus. This indicates that it has 2 1 − (ni−n¯i)·(nj−n¯j) . Compared to other mea- a degraded encoder representation. Going further, (cid:107)(ni−n¯i(cid:107) 2(cid:107)(nj−n¯j(cid:107) 2 we also hypothesize that models’ representations sures, correlation distance is preferable as it nor- of said sentences may be confounded, in part, by malizes both the mean and variance of activity pat- factors that are known to influence humans. terns over experimental conditions. Other popular measures include the Euclidean distance and the Eye-tracking data For our experiments, we Malahanobis distance (Kriegeskorte et al., 2006). make use of the Dundee eye-tracking corpus (Kennedy et al., 2003), the English part of which 3 Fixation Duration and Encoder consists of eye-movement data recorded as 10 Disagreement native participants read 2,368 sentences from 20 Gaze fixation patterns have been shown to strongly newspaper articles. We consider the following fix- reflect the online cognitive processing demands of ation features: TOTAL FIXATION DURATION and FIRST PASS DURATION. For each of the features, 1More precisely, our measure of dissimilarity between ex- we first take the average of the measurements perimental conditions is analogous to ground distance and dissimilarity between RDMs to earth mover’s distance. recorded for all 10 participants per word, then ob-
tain sentence-level annotations by summing the length 2, 368, which has the correlations between measurements of all words in a sentence and di- two layers L and L ’s RDMs for each of the sen- i j viding by its length. The result of this is two vec- tences. tors V and V of length 2, 368, where totfix firstpass Third-order analysis The final part of our anal- each cell in the vector corresponds to a sentence’s ysis involves computing correlations (Spearman’s average total fixation and average first pass dura- ρ) of {V , V , V , V } tion, respectively. CorrLi−Lj logF req Y ngve wordSense with each of V and V . The results totfix firstpass Syntactic complexity, word frequency, and lex- from this are shown in Table 1. The top section of ical ambiguity We also consider the three fol- the table shows correlations when L and L are i j lowing linguistic features which affect processing the three final adjacent layers in BERT and ELMo. difficulty. For each of the following the result is The middle section shows the results for top three also a vector of length 2, 368 where each cell cor- BERT layer pairs L and L which maximize the i j responds to a sentence: correlation scores. The final section shows cor- relation with the linguistic features. Finally, Fig- a. the average word log frequency per sentence ure 2 shows Spearman’s ρ correlations between extracted from the British National Corpus V and each of V , and V for all (Leech, 1992), V . CorrLi−Lj totfix Y ngve logF req. combinations of the 24 BERT layers. b. the average number of senses per word per sentence extracted from WordNet (Miller, 4 Discussion 1995), V . wordSense Our results show highly significant negative corre- c. Yngve scores, a standard measure of syntac- lations between V and sentence gaze fix- tic complexity based on cognitive load (Yn- CorrLi−Lj ation times. These findings confirm the hypothesis gve, 1960) , V . Y ngve that the sentences that are most challenging for hu- Pretrained encoders We conduct our analysis mans to process, are the sentences (a) the layers of on pretrained BERT-large (Devlin et al., 2018) and BERT disagree most on among themselves; and ELMo (Peters et al., 2018), two widely employed (b) that ELMo and BERT disagree most on, indi- contextual sentence encoders. To obtain a repre- cating that there may be common factors which sentation of a sentence from a given layer L, we affect human processing difficulty and result in perform mean-pooling over the time-steps which disagreement between layers. By Layer disagree- correspond to the words of a sentence, obtaining ment we refer to the expression 1 − V CorrLi−Lj . It a vector representation of the sentence. Mean- is important to note that these encoders are trained pooling is a common approach for obtaining vec- with a language modelling objective, unlike mod- tor representations of sentences for downstream els where reading behaviour is explicitly modelled tasks (Peters et al., 2018; Conneau et al., 2017b). (Hahn and Keller, 2016) or predicted (Matthies We refer to ELMo’s lowest layer as E1, BERT’s and Søgaard, 2013). Indeed, the similarities here 11th layer as B11, etc. emerge naturally as a function of the task being performed. This can be seen as analogous to the RDMs We construct an RDM (see §2) for each case of similarities observed between neural net- contextual encoder’s layers. Each RDM is a 2, 368 works trained to perform object recognition and × 2, 368 matrix which represents the dissimilar- spatio-temporal cortical dynamics (Cichy et al., ity structure of the layer, (i.e., each row vector 2016). in the matrix contains the dissimilarity of a given sentence to every other sentence). We then com- Syntactic complexity Figure 2 shows that, for pute the correlations between the two different all combinations of BERT layers, total fixation RDMs. For our evaluation of how well the rep- time and Yngve scores have strong negative and resentational geometry of a layer correlates to an- positive correlations (respectively) with layer dis- other, we employ Kendall’s τ as suggested in agreement. Furthermore, we observe that dis- A Nili et al. (2014), computing the pairwise cor- agreement between middle layers seems to show relation for each two corresponding rows in two the strongest correlation with Yngve scores. To RDMs. This second-order analysis gives us a confirm this, we split the correlations into four pairwise relational similarity vector V of groups: “low” (i, j ∈ [1, 8]), “middle” (i, j ∈ CorrLi−Lj
Figure 2: RSMs showing (Spearman’s ρ) correlation between disagreement among layers i and j (V ) CorrLi−Lj and V (left) and V (Right). BERT layers are denoted with numbers from 1 (topmost) to 24 (lowest). totfix Y ngve Layer Disagreement Total Fixation First Pass Duration most syntax, and are therefore possibly more sen- E1-B22 -0.46 -0.46 sitive towards syntactic complexity. A very similar E2-B23 -0.66 -0.67 pattern is observed for total fixation time. When E3-B24 -0.22 -0.23 considered together with the correlation between B11-B12 -0.88 -0.87 V and fixation times, this indicates a tripar- B12-B13 -0.87 -0.85 Y ngve tite affinity between layer disagreement, syntactic B10-B21 -0.87 -0.86 Linguistic Features complexity, and fixation. Log Freq. -0.20 -0.19 Lexical Ambiguity and Word Frequency Fi- Avg. Senses per Word -0.007* -0.004* nally, we observe that V has a moderate Yngve Score 0.66 0.66 logF req. correlation with both fixation time and layer dis- Table 1: Spearman’s ρ between V CorrLi−Lj , V logF req., agreement and that V wordSense is nearly uncorre- V wordSense, V Y ngve and each of V totfix and V firstpass. lated to both. Detailed plots of the latter can be All correlations significant with p < 0.0001 after Bon- found in Appendix A. ferroni correction unless marked with *. 5 Conclusion [9, 16]), “high” (i, j ∈ [17, 24]), and “out” (|i − We presented a framework for analyzing neural j| > 7), with the latter representing out-of- network representations (RSA) that allowed us to group correlations (e.g. Corr ). To ac- relate human sentence processing data with lan- L1−L24 count for correlations between disagreeing adja- guage encoder representations. In experiments cent layers (e.g. |i − j| = 1) and Yngve scores conducted on two widely used encoders, our find- being higher (as a possible confounding factor), ings show that sentences which are difficult for hu- we also distinguish layers as either “adjacent” or mans to process have more divergent representa- “non-adjacent”. Considering these two factors as tions both intra-encoder and between different en- three- and two-leveled independent variables re- coders. Furthermore, we lend modest support to spectively, we conduct a two-way analysis of vari- the intuition that a model’s middle layers encode ance. The analysis reveals that the effect of group comparatively more syntax. Our framework of- is significant at F (3, 275) = 78.47, p < 0.0001, fers insight that is complimentary to decoding or with “low” (µ = 0.65, σ = 0.08), “middle” (µ = probing approaches, and is particularly useful to 0.84, σ = 0.03), “high” (µ = 0.80, σ = 0.05), and compare representations from across modalities. “out” (µ = 0.80, σ = 0.05). Neither the effect of Acknowledgements adjacency nor its interaction with group proved to be significant. We would like to thank Vinit Ravishankar, Matt This can be seen as (modest) support for the Lamm, and the anonymous reviewers for their findings of previous work (Blevins et al., 2018; helpful comments. Mostafa Abdou and Anders Tenney et al., 2019): namely, that the intermedi- Søgaard are supported by a Google Focused Re- ate layers of neural language models encode the search Award and a Facebook Research Award.
References Dasgupta, I., Guo, D., Stuhlmu¨ller, A., Gershman, S. J., and Goodman, N. D. (2018). Evaluating compo- Abnar, S., Beinborn, L., Choenni, R., and Zuidema, sitionality in sentence embeddings. arXiv preprint W. (2019). Blackbox meets blackbox: Representa- arXiv:1802.04302. tional similarity & stability analysis of neural lan- guage models and brains. In Proceedings of the Devlin, J., Chang, M.-W., Lee, K., and Toutanova, 2019 ACL Workshop BlackboxNLP: Analyzing and K. (2018). Bert: Pre-training of deep bidirectional Interpreting Neural Networks for NLP, pages 191– transformers for language understanding. arXiv 203, Florence, Italy. Association for Computational preprint arXiv:1810.04805. Linguistics. Duffy, S. A., Morris, R. K., and Rayner, K. (1988). Adi, Y., Kermany, E., Belinkov, Y., Lavi, O., and Gold- Lexical ambiguity and fixation times in reading. berg, Y. (2016). Fine-grained analysis of sentence Journal of memory and language, 27(4):429–446. embeddings using auxiliary prediction tasks. arXiv preprint arXiv:1608.04207. Gulordava, K., Bojanowski, P., Grave, E., Linzen, T., and Baroni, M. (2018). Colorless green recur- Ashby, J., Rayner, K., and Clifton, C. (2005). Eye rent networks dream hierarchically. arXiv preprint movements of highly skilled and average readers: arXiv:1803.11138. Differential effects of frequency and predictability. Hahn, M. and Keller, F. (2016). Modeling hu- The Quarterly Journal of Experimental Psychology man reading with neural attention. arXiv preprint Section A, 58(6):1065–1086. arXiv:1608.05604. Belinkov, Y., Ma`rquez, L., Sajjad, H., Durrani, N., Hupkes, D., Veldhoen, S., and Zuidema, W. Dalvi, F., and Glass, J. (2017). Evaluating layers of (2017). Visualisation and’diagnostic classifiers’ representation in neural machine translation on part- reveal how recurrent and recursive neural net- of-speech and semantic tagging tasks. In Proceed- works process hierarchical structure. arXiv preprint ings of the Eighth International Joint Conference on arXiv:1711.10203. computer vision (Volume 1: Long Pa- pers), volume 1, pages 1–10. Kennedy, A., Hill, R., and Pynte, J. (2003). The dundee corpus. In Proceedings of the 12th European confer- Blevins, T., Levy, O., and Zettlemoyer, L. (2018). ence on eye movement. Deep rnns encode soft hierarchical syntax. arXiv preprint arXiv:1805.04218. Kriegeskorte, N., Goebel, R., and Bandettini, P. (2006). Information-based functional brain mapping. Pro- Bouchacourt, D. and Baroni, M. (2018). How agents ceedings of the National Academy of Sciences, see things: On visual representations in an emergent 103(10):3863–3868. language game. In Proceedings of the 2018 Con- ference on Empirical Methods in Natural Language Kriegeskorte, N., Mur, M., and Bandettini, P. A. Processing, pages 981–985, Brussels, Belgium. As- (2008). Representational similarity analysis- sociation for Computational Linguistics. connecting the branches of systems neuroscience. Frontiers in systems neuroscience, 2:4. Chrupała, G. and Alishahi, A. (2019). Correlating neu- ral and symbolic representations of language. arXiv Leech, G. N. (1992). 100 million words of english: the preprint arXiv:1905.06401. british national corpus (bnc). Levy, R. (2008). Expectation-based syntactic compre- Chrupała, G., Gelderloos, L., and Alishahi, A. (2017). hension. Cognition, 106(3):1126–1177. Representations of language in a model of vi- sually grounded speech signal. arXiv preprint Linzen, T., Dupoux, E., and Goldberg, Y. (2016). As- arXiv:1702.01991. sessing the ability of lstms to learn syntax-sensitive dependencies. arXiv preprint arXiv:1611.01368. Cichy, R. M., Khosla, A., Pantazis, D., Torralba, A., and Oliva, A. (2016). Comparison of deep neu- Loula, J., Baroni, M., and Lake, B. M. (2018). Re- ral networks to spatio-temporal cortical dynamics of arranging the familiar: Testing compositional gen- human visual object recognition reveals hierarchical eralization in recurrent networks. arXiv preprint correspondence. Scientific reports, 6:27755. arXiv:1807.07545. Conneau, A., Kiela, D., Schwenk, H., Barrault, L., and Marvin, R. and Linzen, T. (2018). Targeted syntac- Bordes, A. (2017a). Supervised learning of univer- tic evaluation of language models. arXiv preprint sal sentence representations from natural language arXiv:1808.09031. inference data. CoRR, abs/1705.02364. Matthies, F. and Søgaard, A. (2013). With blinkers on: Conneau, A., Kiela, D., Schwenk, H., Barrault, L., and Robust prediction of eye movements across readers. Bordes, A. (2017b). Supervised learning of univer- In Proceedings of the 2013 Conference on Empiri- sal sentence representations from natural language cal Methods in computer vision, pages inference data. arXiv preprint arXiv:1705.02364. 803–807.
McCann, B., Keskar, N. S., Xiong, C., and Socher, R. (2018). The natural language decathlon: Multi- task learning as question answering. arXiv preprint arXiv:1806.08730. Miller, G. A. (1995). Wordnet: a lexical database for english. Communications of the ACM, 38(11):39– 41. Nili, H., Wingfield, C., Walther, A., Su, L., Marslen- Wilson, W., and Kriegeskorte, N. (2014). A toolbox for representational similarity analysis. PLoS com- putational biology, 10(4):e1003553. Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365. Raney, G. E., Campbell, S. J., and Bovee, J. C. (2014). Using eye movements to evaluate the cognitive pro- cesses involved in text comprehension. Journal of visualized experiments: JoVE, (83). Rayner, K. and Duffy, S. A. (1986). Lexical complex- ity and fixation times in reading: Effects of word frequency, verb complexity, and lexical ambiguity. Memory & cognition, 14(3):191–201. Rubner, Y., Tomasi, C., and Guibas, L. (2000). The earth mover’s distance as a metric for image re- trieval. In IJCV. Shepard, R. N. and Chipman, S. (1970). Second-order isomorphism of internal representations: Shapes of states. Cognitive psychology, 1(1):1–17. Tenney, I., Das, D., and Pavlick, E. (2019). Bert re- discovers the classical nlp pipeline. arXiv preprint arXiv:1905.05950. Tenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., Mc- Coy, R. T., Kim, N., Van Durme, B., Bowman, S., Das, D., et al. (2018). What do you learn from con- text? probing for sentence structure in contextual- ized word representations. Van Gompel, R. P. (2007). Eye movements: A window on mind and brain. Elsevier. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. (2018). Glue: A multi-task bench- mark and analysis platform for natural language un- derstanding. arXiv preprint arXiv:1804.07461. Yngve, V. H. (1960). A model and an hypothesis for language structure. Proceedings of the American philosophical society, 104(5):444–466. A Correlation Heatmaps
Figure 3: RSM heatmaps showing (Spearman’s ρ) correlation between disagreement among layers i and j (V ) and (a) V (top), (b) V (middle) and, (c) V (bottom). CorrLi−Lj firstpass wordSense logF req
