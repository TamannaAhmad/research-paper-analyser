Wasserstein Fair Classification Ray Jiang∗ Aldo Pacchiano∗ Tom Stepleton DeepMind UC Berkeley, DeepMind DeepMind rayjiang@google.com pacchiano@berkeley.edu stepleton@google.com Heinrich Jiang Silvia Chiappa Google Research DeepMind heinrichj@google.com csilvia@google.com Abstract a criterion called demographic parity (Feldman et al., 2015). We propose an approach to fair classification In the common scenario in which the model outputs con- that enforces independence between the classi- tinuous values from which class predictions are obtained fier outputs and sensitive information by mini- through thresholds, this approach would however ensure mizing Wasserstein-1 distances. The approach fairness only with respect to the particular choice of has desirable theoretical properties and is ro- thresholds. Furthermore, as independence constraints bust to specific choices of the threshold used on the class predictions are difficult to impose in practice, to obtain class predictions from model outputs. uncorrelation constraints on the model outputs are often We introduce different methods that enable hid- imposed instead. ing sensitive information at test time or have In this paper, we propose an approach that overcomes a simple and fast implementation. We show these limitations by imposing independence constraints empirical performance against different fair- directly on the model outputs. This is achieved through ness baselines on several benchmark fairness enforcing small Wasserstein distances between the distri- datasets. butions of the model outputs corresponding to groups of individuals with different sensitive attributes. We demon- strate that using Wasserstein-1 distances to the barycenter 1 INTRODUCTION is optimal, in the sense that it achieves independence with minimal changes to the class predictions that would The increasing use of machine learning in decision- have been obtained without constraints. We introduce a making scenarios that have serious implications for in- Wasserstein-1 penalized logistic regression method that dividuals and society, such as health care, criminal risk learns the optimal transport map in the logistic model assessment, social services, hiring, financial lending, and parameters, with a variation that has the advantage of online advertising (De Fauw et al., 2018; Dieterich et al., being demographically blind at test time. In addition, 2016; Eubanks, 2018; Hoffman et al., 2018; Malekipir- we provide a simpler and faster post-processing method. bazari and Aksakalli, 2015; Perlich et al., 2014), is raising We show that the proposed methods outperform previous concern that bias in the data and model inaccuracies can approaches in the literature on four benchmark fairness lead to decisions that are “unfair” towards underrepre- datasets. sented or historically discriminated groups. This concern has motivated researchers to investigate 2 STRONG DEMOGRAPHIC PARITY ways of ensuring that sensitive information (e.g. race and gender) does not unfairly influence the decisions. In the classification case considered in this paper, the most Let D = {(an, xn, yn)}N be a sequence of N i.i.d. n=1 widely used approach is to enforce statistical indepen- samples drawn from an unknown probability distribution dence between class predictions and sensitive attributes, over A × X × Y = Nk × Rd × {0, 1}. Each datapoint (an, xn, yn) corresponds to information from an individ- ∗ Equal contribution. ual (or community): yn indicates a binary class, each In Proceedings of the Thirty-Fifth Conference on Un- certainty in Artificial Intelligence, 2019. Code available at element an i of an corresponds to a different sensitive at- github.com/deepmind/wasserstein fairness. tribute, e.g. to the gender of the individual, and xn is a 9102 luJ 82 ]LM.tats[ 1v95021.7091:viXra
feature vector that, possibly together with an, can be used where U (Ω) denotes the uniform distribution over Ω. This to form a prediction yˆn ∈ {0, 1} of the class yn. We de- result leads us to use note with D = {(an, xn, yn) ∈ D s.t. an = a} the set a (cid:88) of N a individuals belonging to group a. We indicate with E τ∼U(Ω)|P(S a > τ ) − P(S a¯ > τ )| , A, X, Y and Yˆ the random variables corresponding to a,a¯∈A s.t. a(cid:54)=a¯ an, yn and yˆn, and with p(·) or p (·) probability density X functions (pdfs), where the latter is used to emphasize the as a measure of dependence of S on A, the we call strong associated random variable. pairwise demographic disparity (SPDD). Many classifiers, rather than a binary class prediction yˆn, output a non-binary value sn. In the logistic regression 3 WASSERSTEIN FAIR case considered in this paper, sn ∈ Ω = [0, 1] indicates CLASSIFICATION the model belief that individual n belongs to class 1, i.e. sn = P(Y = 1|A = an, X = xn)2. From sn, a We suggest to achieve SDP by enforcing the model output pdfs corresponding to groups of individuals with differ- class prediction yˆn ∈ {0, 1} is obtained using a threshold τ ∈ Ω, i.e. yˆn := 1 sn>τ , where 1 sn>τ equals to one if ent sensitive attributes, {p Sa} a∈A, to coincide with their sn > τ and zero otherwise. We call the random variable Wasserstein-1 barycenter distribution p S¯. The use of the Wasserstein distance is motivated because this distance is S corresponding to sn the belief variable, and denote defined and computable even between distributions with with S the belief variable for group a, i.e. with pdf a disjoint supports. This is critical because the empirical p(S ) = p(S|A = a). a estimates {pˆ Sa}, pˆ S¯ of {p Sa} and p S¯ used to implement We are interested in ensuring that sensitive information the methods and their supports are typically disjoint. does not influence the decisions. This is often achieved by imposing that the model satisfies a fairness criterion 3.1 OPTIMALITY OF WASSERSTEIN-1 called demographic parity (DP), defined as DISTANCE P(Yˆ = 1|A = a) = P(Yˆ = 1|A = a¯) , ∀a, a¯ ∈ A . Preliminary. Given two pdfs p and p on X and X Y DP can equivalently be expressed as requiring statistical Y, a transportation map T : X → Y is defined by independence between Yˆ and A, denoted as Yˆ ⊥⊥ A. (cid:82) p (y)dy = (cid:82) p (x)dx for any measurable sub- B Y T −1(B) X Enforcing demographic parity at a given threshold τ set B ⊂ Y (indicating that the mass of the set B with re- does not necessarily imply that the criterion is satisfied spect to the density p Y equals the mass of the set T −1(B) for other thresholds. Furthermore, to alleviate difficul- with respect to the density p X ). Let T be the set of trans- ties in optimizing on the class prediction Yˆ , relaxations portation maps from X to Y, and c : X × Y → [0, ∞] are often considered, such as imposing the constraint be a cost function such that c(x, T (x)) indicates the cost E[S|A = a] = E[S|A = a¯] ∀a, a¯ ∈ A, where E[·] of transporting x to T (x). In the original formulation denotes expectation (Goh et al., 2016; Zafar et al., 2017). (Monge, 1781), the optimal transport map T ∗ is the one that minimizes the total transportation cost, i.e. To deal with these limitations, we propose an approach (cid:90) that enforces statistical independence between S and A, T ∗ = arg min c(x, T (x))p (x)dx. S ⊥⊥ A. We call this fairness criterion strong demo- X T ∈T x∈X graphic parity (SDP), as it ensures that the decision does To address limitations of this formulation, Kantorovich not depend on the sensitive attribute regardless of the threshold τ used, since S ⊥⊥ A implies Yˆ ⊥⊥ A for any (1942) reformulated the optimal transport problem as value of τ . SDP can be defined as finding an optimal pdf p X×Y in the set Γ(p X , p Y ) of joint pdfs on X × Y with marginals over Y and X given p = p , ∀a, a¯ ∈ A . Sa Sa¯ by p X and p Y such that In Remark 1, we prove that this definition is equivalent (cid:90) γ∗ = arg min c(x, y)p dxdy. to3 X×Y γ∈Γ(fX,fY ) X ×Y E |P(S > τ ) − P(S > τ )| = 0, ∀a, a¯ ∈ A , τ∼U(Ω) a a¯ The p-Wasserstein distance is defined as 2Throughout the paper, we use P(·) to indicate probability measures associated with the corresponding probability spaces (cid:18)(cid:90) (cid:19) 1 (O, F, P(·)) where F is a σ-algebra on the sample output space W (p , p ) = min d(x, y)pp dxdy p , O. p X Y γ∈Γ(fX,fY ) X ×Y X×Y 3We omit the brackets from the expectation to simplify the notation. where X = Y, d is a distance on X , and p ≥ 1.
Fair Optimal Post-Processing. Let us first consider Thus, the problem of post-processing the beliefs of a model (cid:90) to achieve SDP while making minimal model class pre- W (p , p ) = min |x − T (x)|p (x)dx diction changes. 1 S1 S2 T ∈T x S1 (cid:90) = |x − T ∗(x)|p (x)dx Let S 1 and S 2 be two belief variables with values in S1 x Ω = [0, 1] and pdfs p and p , and let T : Ω → S1 S2 (cid:82) = E P(τ ∈ (mT ∗ , M T ∗ )) . Ω be a transportation map satisfying p (y)dy = τ∼U(Ω) x x (cid:82) p (x)dx for any measurable suB bsS e2 t B ⊂ Ω. x∼pS1 T −1(B) S1 Let T be the set of all such transportation maps. A This prove that (i) equals (iii). c t mil oa in nss [T sp (r ,se T1d ) (ic sifti )o a ]nn ad nyˆ o dn= Mly1 Tis f1 =τ>τ ∈ mc ( ah m xa [n T s s1g ,e ,Ms Td (sT su 1)e )w ]t .o h Tetr r ha e in sms op T s bo 1 sr et =a r-- R Pe (m S 2ar >k τ1. )| N =ot 0ice if t ah na dt ( oi ni) ly= ifE pτ S∼ 1 U =(Ω p)| SP 2.(S I1 nd> eedτ ,) b− y 1 1 s1 1 1 Proposition 1 and the property of the W 1 metric, (ii) = 0 vation leads to the following result. ⇐⇒ W (p , p ) = 0 ⇐⇒ p = p . 1 S1 S2 S1 S2 Proposition 1. Given two belief variables S and S in 1 2 Ω qua= nti[ t0 ie, s1] arw ei eth qup ad lf :s p S1 and p S2, the following three wTo her re eac ph ∗ ∈SD PP (, Ωw )e , tn he ee sd pato cea oc fh pie dv fe s op nSa Ω.= Wp e∗ w∀ oa uld∈ liA ke, to choose transportation maps T and a target distribution (cid:82) p∗ such that the transportation process from p to p∗ in- (i) W 1(p S1, p S2) = Tm ∈i Tn x∈Ω |x − T (x)|p S1(x)dx. curs minimal total expected class prediction chS aa nges. As- (ii) E |P(S > τ ) − P(S > τ )|. sume that the groups are all disjoint, so that the per-group τ∼U(Ω) 1 2 transportation maps T are independent from each other. (iii) Expected class prediction changes due to transport- Let T(p∗) be the set of transportation maps with elements ing p into p through the map T ∗ T such that, restricted to group a, T is a transportation S1 S2 map from p to p∗ (i.e. T(p∗) = {T ∈ T (p , p∗) | E τ∼U(Ω),x∼pS1 P(τ ∈ (mT x ∗ , M xT ∗ )) . T (S)(cid:12) (cid:12) A=a =Sa T a ∈ T a = T (p Sa, p∗)} where T S (p S, p∗) denotes the space of transportation maps from p to p∗). S We would like to obtain Proof. In the one-dimensional case of p and p , the S1 S2 total transportation cost W 1(p S1, p S2) can be written as T ∈m Ti (n p∗) τ∼UE (Ω) P(τ ∈ (mT x , M xT )) (cid:90) 1 p∗∈P(Ω) x∼pS W 1(p S1, p S2) = 4 x=0 |P S− 11(x) − P S− 21(x)|dx = T ∈m Ti (n p∗) (cid:88) p (cid:124)(A (cid:123)= (cid:122) a (cid:125)) τ∼UE (Ω) P(τ ∈ (mT x , M xT )) = (cid:90) 1 |P (τ ) − P (τ )|dτ p∗∈P(Ω) a∈A pa x∼pSa τ=0 S1 S2 = min (cid:88) p a min E P(τ ∈ (mT x , M xT )) (by Lemma 6 in Appendix C) p∗∈P(Ω) a∈A T ∈Ta τ∼U(Ω) = E τ∼U(Ω)|P(S 1 ≤ τ ) − P(S 2 ≤ τ )| (cid:88) (cid:90)x∼pSa = E τ∼U(Ω)|P(S 1 > τ ) − P(S 2 > τ )| , = p∗m ∈Pin (Ω) a∈A p a Tm ∈i Tn a x∈Ω |x − T (x)|p Sa(x)dx (cid:88) w tioh ne sre ofP SS1 a an nd d SP S2 rea sr pe et ch tie vc eu lym . Tul ha it siv pe rod vi est tr hib au t t (i io )n eqfu un alc s- = p∗m ∈Pin (Ω) p aW 1(p Sa, p∗) . 1 2 a∈A (ii). Therefore we are interested in The expected class prediction changes due to applying (cid:88) the transportation map T is given by p S¯ = arg min p aW 1(p Sa, p∗) , (1) p∗∈P(Ω) a∈A E P(τ ∈ (mT , M T )) τ∼U(Ω) x x which coincides with the Wasserstein-1 barycenter with x∼pS1 normalized subgroup size as weight to every group distri- (cid:90) 1 (cid:90) bution p (Agueh and Carlier, 2011). = |x − T (x)|p S1(x)dxdτ Sa τ=0 x (cid:90) In summary, we have demonstrated that the optimal post- = |x − T (x)|p (x)dx. processing procedure that minimizes total expected model S1 x prediction changes is to use the Wasserstein-1 optimal 4The proof of this equality can be found in Rachev and transport map T ∗ to transport all group distributions p Sa Ru¨schendorf (1998). to their weighted barycenter distribution p S¯.
Optimal Trade-Offs. We have shown that post- Empirical Computation of the Barycenter. In prac- processing the beliefs of a model through optimal trans- tice, as building the barycenter from the population dis- portation achieves SDP (and therefore SPDD = 0) whilst tributions p is impossible, we use the empirical distri- Sa minimizing expected prediction changes. We now exam- butions pˆ obtained from D . The choice is justified by Sa a ine the case in which, after transportation, SDP is not the following result: attained, i.e. SPDD is positive. By triangle inequality Lemma 1. If the samples in D are i.i.d., as |D| → ∞, SPDD ≤ = 2 2( (| |A A| |− −1 1) ) a(cid:88) (cid:88)∈A E Wτ 1∼ (U p S(Ω a) ,| pP S¯( )S .a > τ )−P(S¯ > τ )| i t (cid:80)f erW a d p1 i a( sp WtrS i, 1bp (u pS t Sia ¯o ,) n p< Ss aa )∞ ti as lfi mfo e or s sa tll i sl m ua re(cid:80), lyt ah 5.e pˆ aem Wp 1i (r pi ˆc S¯a ,l pˆb Sa ar )yce →n- a∈A The proof is given in Appendix A. We call this upper bound on SPDD pseudo-SPDD. In the next two sections we introduce two different ap- Pseudo-SPDD is the tightest upper bound to SPDD among proaches to achieve SDP with Wasserstein-1 distances: A all possible target distributions by the definition of the penalization approach to logistic regression and a simpler barycenter p S¯ and Proposition 1. Indeed practical approach consisting in post-processing model (cid:88) E |P(S > τ ) − P(S¯ > τ )| beliefs. τ∼U(Ω) a a∈A 3.2 WASSERSTEIN-1 PENALIZED LOGISTIC (cid:88) (cid:88) = W 1(p Sa, p S¯) ≤ W 1(p Sa, p S0) REGRESSION a∈A a∈A = (cid:88) E |P(S > τ ) − P(S0 > τ )|, The average logistic regression loss function over D = τ∼U(Ω) a {an, xn, yn}N is given by a∈A n=1 for any distribution p S0 ∈ P(Ω). Since SPDD is difficult 1 (cid:88)N to derive optimal trade-offs for, we do that with respect to J (θ) = −yn log sn − (1 − yn) log (1 − sn) , D N the pseudo-SPDD as the measure of fairness instead. n=1 W toe rea ar ce hin ate fr ae irs nte ed ssin boc uh na dng λin ∈g p RS +a t fo orp pS sa∗ e, u∀ doa -S∈ PDA D, 1w ,h se nr ,e it sh oe bm tao ind ee dl b asel sie nf =tha σt (i θn (cid:62)di wvi ndu )a =l n 1/b (e 1lo +ng es −t θo (cid:62)c wla ns )s , such that the required model prediction changes are min- with wn = (xn, an, 1)(cid:62), and where θ ∈ Rd+k+1 are imal in expectation. This is obtained by choosing the the model parameters. We denote with {si } the model a p S a∗ ∈ P(Ω) that minimizes (cid:80)the total expected predic- beliefs for group a and with {s¯j}N j¯ =1 the atoms of p S¯. tion changes, which equals p W (p , p ) by a∈A a 1 Sa S a∗ The gradient of J (θ) with respect to θ is given by Proposition 1, while bounding the pseudo-SPDD by λ, D (cid:80) i a. re e. disa jo∈ iA nt,W w1 e(p caS na∗ , op pS t¯ i) m≤ izeλ e. aA chss gu rm ouin pg trt ah na st pt oh re tag tir oo nup ins ∇ J (θ) = 1 (cid:88)N wn (cid:0) σ (cid:0) θ(cid:62)wn(cid:1) − yn(cid:1) . turn independently assuming the other groups are fixed. θ D N n=1 This gives We propose to find model parameters θ∗ that minimize p S a∗ = p∗a ∈r Pg (m Ω)in s.t. p aW 1(p Sa, p∗) the population level logistic loss E [J D(θ)] under the con- W1(p∗,p S¯)≤λ−γ straint of small Wasserstein-1 distances W 1(pˆ Sa, pˆ S¯) be- = arg min W 1(p Sa, p∗) , tween pˆ Sa and the empirical barycenter pˆ S¯, ∀a ∈ A. p∗∈P(Ω) s.t. The Wasserstein-1 distance between any two empir- W1(p∗,p S¯)≤λ−γ ical distributions pˆ and pˆ underlying two datasets b c where γ = (cid:80) a¯∈A\a W 1(p S a∗ ¯ , p S¯). By triangle inequal- {bi}N i=b 1, {cj}N j=c 1 ⊂ R is given by ity, W 1(p Sa, p∗) ≥ |W 1(p Sa, p S¯) − W 1(p∗, p S¯)|. The d pi ∗st la ien sce onW a1 s( hp oS ra te, sp t∗ p) ar te hac bh ee tws eit es nm pi Sn aim au nm d pif S¯a . n Td ho un sl iy t ii sf W 1(pˆ b, pˆ c) = Tb,cm ∈Uin (b,c)(cid:104)T b,c, C(cid:105) , (2) optimal to transport p Sa along any shortest path between where U (b, c) = {T ∈ RNb×Nc s.t. T b,c1 c = itself and p S¯ in the Wasserstein-1 metric space. In the 1 1 and T (cid:62) 1 = 1 1 } with 1 denoting a vector approach proposed in the next section, we approximate Nb b b,c b Nc c c of ones of size N . The brackets (cid:104)·, ·(cid:105) denote the trace transporting group distributions along these shortest paths c with data augmentation of a gradient descent method 5See Klenke (2013) for a formal definition of almost sure to minimize W 1(p Sa, p S¯) for every group. convergence of random variables.
dot product and C is the cost matrix associated with the Algorithm 1 Wass-1 Penalized Logistic Regression Wasserstein-1 cost function c of elements C i,j = |bi − cj|. Input: Dataset D = {(an, xn, yn)}N , penalization n=1 coefficients α, β, gradient step size η, number of opti- In particular, the Wasserstein-1 distance W 1(pˆ Sa, pˆ S¯) can mization rounds M , frequency of barycenter compu- be computed by solving the optimization problem of Eq. (2) with cost matrix Cθ ∈ RNa×N¯ satisfying tation K. a Compute datasets {D }. a (Cθ a) i,j = (cid:12) (cid:12)si a − s¯j(cid:12) (cid:12) , Initialize model parameters θ 0. for m = 1, · · · , M do w thh ee rr ee at dh ee r u thp ap ter ms oc dri ep lt pθ rei dn icC tθ a ionis sm ara ein ata fi un ne cd tit oo nre om f i tn hd e 1 a. ndC Com oup ru tyte (2th 0e 17b )a )ry oc ne cn et ee vr ed ri yst Krib su tt ei po sn , apˆ nS¯ d( {F s¯la i}m N¯ary . i=1 model parameter θ. 2. Compute optimal couplings {T a∗} as defined in Lemma 3. The Wasserstein-1 penalized logistic regression objective 3. Update parameter θ = θ − η∇ J (θ ). is given by m m−1 θ W1 m end J W1(θ) = αJ D(θ) + (1 − α)β (cid:88) W 1(pˆ Sa, pˆ S¯) , (3) Return: θ M . a∈A where α and β are penalization coefficients. This lemma characterizes the coupling matrix between Lemma 2. If the datasets {bi}Nb , {cj}Nc ⊂ R have the empirical distributions of two datasets made of real i=1 j=1 numbers. When N = N and the datasets are {bi}N and empirical distributions pˆ and pˆ , and C is the cost matrix b c b b c {ci}N , with b1 < . . . < bN , and a1 < . . . < aN , then of elements C = |bi − cj|: c i,j the optimal coupling equals 1/N × I where I denotes N N ∇ W (pˆ , pˆ ) = T ∗ , the N × N identity matrix. Lemma 4 extends this simple C 1 b c b,c case to the general case of datasets of arbitrary orderings where T ∗ = arg min (cid:104)T , C(cid:105) is the optimal and sizes, see Deshpande et al. (2018) for a proof. It is b,c Tb,c∈U(b,c) b,c coupling resulting from the optimization objective of Eq. easy to see that the optimal coupling T ∗ is sparse and has b,c (2). at most O(N + N ) nonzero entries (see Cuturi (2013)). b c As a consequence, the computation of ∇ J (θ) can Proof. The result follows immediately from the subgra- be performed in linear time O(cid:0) (cid:80) (N +θ NW ¯ )1(cid:1) where a a dient rule for a pointwise max function (see Boyd and N = |D |. In the computation of ∇ J (θ) only the a a θ W1 Vandenberghe (2004)). nonzero entries of T ∗ matter. b,c Lemma 3. The gradient of J W1(θ) equals: We compute the empirical barycenter pˆ S¯ and {s¯i}N i¯ =1, using the POT library by Flamary and Courty (2017). α∇ θJ D(θ) + (1 − α)β(cid:0) (cid:88) (cid:88) T a∗(θ)∇ θ (cid:12) (cid:12)si a − s¯i(cid:12) (cid:12) (cid:1) , We fix the support of potential barycenters to bins of a∈A i,j equal-width spanning the [0, 1] interval, and use the iter- ative KL-projection method proposed by Benamou et al. where T a∗ is the optimal coupling between pˆ Sa and pˆ S¯6. (2015). We then generate a number of samples from the normalized probability distribution of the computed Proof. This formula is a consequence of the chain rule barycenter. and Lemma 1. Demographically-Blind Wasserstein-1 Penalized Lo- Computation Method. We propose to optimize the gistic Regression. In real-world applications, the use Wasserstein penalized logistic loss objective (Eq. (3)) of sensitive attributes might be prohibited when deploy- via gradient descent. The procedure is detailed in Algo- ing a system. We therefore consider the variation where rithm 1. We start by describing how to perform Step 2. wn = (xn, 1)(cid:62). This variation still uses the sensitive under the assumption that pˆ S¯ and {s¯i}N i¯ =1 have been com- attributes to calculate the Wasserstein-1 loss but, by not puted. The computation of the optimal coupling family including them into the feature set, does not require knowl- {T ∗} hinges on the following Lemma. edge of sensitive information at test time. a Lemma 4. If {bi}Nb , {cj}Nc ⊂ R, and B = [i × i=1 j=1 i (N − 1) + 1, · · · , i × N ] for all i and C = [j × (N − 3.3 WASSERSTEIN-1 POST-PROCESSING c c j b 1) + 1, · · · , j × N ] for all j, then: (T ∗ ) = #|Bi∩Cj| . c b,c i,j NbNc In this section, we propose a simple, fast quantile match- 6Recall that T ∗ is a function of θ. ing method to post-process the beliefs of a classifier a
Algorithm 2 Wass-1 Post-Processing The first approach consists in pre-processing the data to Input: dataset D = {(an, xn, yn)}N , set of quantile remove bias, or in extracting representations that do not n=1 bins B, model beliefs {sn} contain sensitive information during training (Beutel et al., Compute datasets {D } and their barycenter D¯. 2017; Calders et al., 2009; Calmon et al., 2017; Edwards a Define the i-th quantile of dataset D as and Storkey, 2016; Feldman et al., 2015; Fish et al., 2015; a Kamiran and Calders, 2009, 2012; Louizos et al., 2016; (cid:40) 1 (cid:88) i − 1 (cid:41) Zemel et al., 2013; Zˇ liobaite et al., 2011). This approach q Da(i) := sup s : N 1 sn≤s ≤ |B| , includes current methods to fairness using Wasserstein a n s.t. an=a distances consisting in achieving SDP through transporta- tion of features (Del Barrio et al., 2019; Johndrow and and its inverse as q−1(s) := sup{i ∈ B : q (i) ≤ s}. Return: (cid:110) q D¯ (cid:0) q D− a1D (sa n)(cid:1) (cid:111) . Da L a u pm os, t2 -p0 r1 o9 c) e. sT sh ine gse oc fo tn hd e a mp op dro ea lc oh uc tpo un ts sis (t Cs hin iap pe pr afo , r 2m 0i 1n 9g ; Doherty et al., 2012; Feldman, 2015; Hardt et al., 2016; Kusner et al., 2017). The third approach consists in en- forcing fairness notions by imposing constraints into the trained on D. This method corresponds to an approximate optimization, or by using an adversary. Some methods Wasserstein-1 optimal transport map by the formulation transform the constrained optimization problem via the of Rachev and Ru¨schendorf (1998): method of Lagrange multipliers (Agarwal et al., 2018; (cid:90) 1 Corbett-Davies et al., 2017; Cotter et al., 2018; Goh et al., W 1(p Sa, p S¯) = |P S− a1(τ ) − P S¯−1(τ )|dτ . 2016; Narasimhan, 2018; Wu et al., 2018; Zafar et al., τ=0 2017). Other work similar in spirit adds penalties to the The procedure is detailed in Algorithm 2. For each group objective (Donini et al., 2018; Komiyama et al., 2018). a, we compute quantiles of pˆ and map all group beliefs Sa Adversarial methods maximize the system ability to pre- belonging in each quantile bin to the supremum of those dict Y while minimizing the ability to predict A (Zhang belonging to the corresponding quantile bin of pˆ S¯. et al., 2018). 3.4 GENERALIZATION 5 EXPERIMENTS The following lemma addresses generalization of the Wasserstein-1 objective. Assume W 1(p Sa, p S¯) ≤ L In this section, we evaluate the methods introduced in f do er nsa il tl ya fu∈ ncA tio. nL se ot fP SS ,, P SSa aa nn dd S¯P .S¯ Ab se suth me ecu thm eu selat ri av ne - S ite oc rytio (n Ls ic3 h. m2 a an nd , 23 0.3 13o )n . Ffo ou rr pd ea nt aa ls ie zt es dfr lo om gist th ie c U reC grI er se sp ioo ns- , a dom variables all have domain Ω = [0, 1] and that all we refer to the method in which sensitive information P ∈ {P S, P S¯} ∪ {P Sa} a∈A are continuous, then: is included in the feature set, i.e. wn = (xn, an, 1)(cid:62), Lemma 5. For any (cid:15), δ > 0, if min (cid:2) N¯ , min (cid:2) N (cid:3)(cid:3) ≥ as Wass-1 Penalty; and to the demographically-blind a a variant in which sensitive information is not included, 16 log(2|A|/δ)|A|2 max[1,L]2 , with probability 1 − δ: (cid:15)2 i.e. wn = (xn, 1)(cid:62), as Wass-1 Penalty DB. We refer (cid:88) (cid:88) to the post-processing method as Wass-1 Post-Process. p aW 1(p Sa, p S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + (cid:15) . We also include a variant of this method using pˆ instead S a∈A a∈A of the barycenter pˆ S¯ (Wass-1 Post-Process pˆ S), which In other words, provided access to sufficient samples, a gives a simpler algorithm that only requires computing (cid:80) l (cid:80)ow value of a pˆ aW 1(pˆ Sa, pˆ S¯) implies a low value for basic quantile functions. We compare these methods with a p aW 1(p Sa, p S¯) with high probability and therefore the following baselines: good performance at test time. Unconstrained: Logistic regression with no fairness The proof is given in Appendix B. constraints. Lemma 5 implies that under appropriate conditions, the Hardt’s Post-Process: Post-processing of the logistic value of the population objective of the Wasserstein cost regression beliefs sn of all individuals in group a by is upper bounded by the empirical Wasserstein cost plus adding 0.5 − τ a, where the threshold τ a is found using a small constant. the method of Hardt et al. (2016). This ensures that DP is satisfied at threshold τ = 0.5. Constrained Optimization: Lagrangian-based method 4 RELATED WORK (see e.g. Eban et al. (2017); Goh et al. (2016)) using Broadly speaking, we can group current literature on fair a linear model as the underlying predictor and equal classification and regression into three main approaches. positive prediction rate between each group D and D a
Table 1: Adult Dataset – German Credit Dataset Adult German Err-.5 Err-Exp DD-.5 SDD SPDD Err-.5 Err-Exp DD-.5 SDD SPDD Unconstrained .142 .198 .413 .426 .806 .248 .319 .124 .102 .103 Hardt’s Post-Process .165 .289 .327 .551 1.058 .248 .333 .056 .045 .045 Constrained Opt. .205 .198 .065 .087 .166 .318 .320 .173 .149 .149 Adv. Constr. Opt. .219 .207 .0 .114 .203 .306 .307 .0 .021 .021 Wass-1 Penalty .199 .208 .014 .022 .044 .306 .311 .0 .003 .003 Wass-1 Penalty DB .230 .233 .010 .012 .023 .306 .309 .0 .010 .010 Wass-1 Post-Process .174 .214 .013 .017 .042 .258 .327 .068 .023 .023 Wass-1 Post-Process pˆ .165 .216 .032 .022 .059 .248 .320 .056 .025 .025 S as fairness constraints with threshold τ = 0. found feasibility issues leading to degenerate classifiers. Adv. Constr. Opt.: The same as the previous method, but with more fairness constraints. Specifically, the fair- 5.2 DATASETS ness constraints are equal positive prediction rates for a set of thresholds from −2 to 2 in increments of 0.2 on The UCI Adult Dataset. The Adult dataset contains 14 the output of the linear model. attributes including age, working class, education level, marital status, occupation, relationship, race, gender, cap- ital gain and loss, working hours, and nationality for 5.1 TRAINING DETAILS 48,842 individuals; 32,561 and 16,281 for the training and test sets respectively. The goal is to predict whether In the approaches Unconstrained, Hardt’s Post-Process, the individual’s annual income is above or below $50,000. Wass-1 Penalty, and Wass-1 Post-Process, we trained a logistic regression model using Scikit-Learn with default Pre-processing and Sensitive Attributes. We pre- hyper-parameters (Pedregosa and et al., 2011). processed the data in the same way as done in Goh et al. (2016); Zafar et al. (2017). The categorical features were For Wass-1 Penalty (Algorithm 1), as initial model encoded into binary features (one for each category), and parameters θ we used the ones given by the 0 the continuous features were transformed into binary trained logistic regression. We swept over penal- encodings depending on five quantile values, obtaining ization coefficients α = [0, 0.5], β = [10−2, 3 · a total of 122 features. As sensitive attributes, we 10−2, 10−1, 3·10−1, 1, 3, 10, 30, 102], gradient step sizes considered race (Black and White) and gender (female η = [10−4, 10−3, 10−2, 10−1], set the maximum num- and male), obtaining four groups corresponding to black ber of training steps to M = 80, 000, and computed females, white females, black males, and white males. the barycenter once every K > M steps, effectively only once after the initialization of θ . In the compu- 0 tation of the barycenter (using the POT library by Fla- The UCI German Credit Dataset. This dataset contains mary and Courty (2017)), we swept over numbers of bins 20 attributes for 1,000 individuals applying for loans. B = [50, 90], entropy penalty δ = [10−3, 5 · 10−3, 10−2], Each applicant is classified as a good or bad credit risk, and used number of iterations M = 1, 000. The time i.e. as likely or not likely to repay the loan. We randomly complexity of our implementation is O(N log(N )). Our divided the dataset into training and test sets of sizes 670 gradient steps take on average ∼0.02 seconds. and 330 respectively. For Wass-1 Post-Process (Algorithm 2), we used a number Pre-processing and Sensitive Attributes. We did not do of bins |B| = 100. any pre-processing. As sensitive attributes, we considered age (≤ 30 and > 30 years old), obtaining two groups. For Constrained Optimization, we used the hinge loss as objective and the hinge relaxation for the fairness constraints. We trained by jointly optimizing the model The UCI Bank Marketing Dataset. This dataset con- parameters and Lagrange multipliers on the Lagrangian tains 20 attributes for 41,188 individuals. Each individual using ADAM with the default step-size of 0.001 and mini- is classified as subscribed or not to a term deposit. We batch size of 100, and trained for 50 steps. We allowed an divided the dataset into train and test sets of sizes 32,950 additive slack of 0.05 on the constraints, as otherwise we and 8,238 respectively.
Table 2: Bank Marketing Dataset – Community & Crime Dataset Bank Marketing Community & Crime Err-.5 Err-Exp DD-.5 SDD SPDD Err-.5 Err-Exp DD-.5 SDD SPDD Unconstrained .094 .138 .135 .134 .61 .116 .195 .581 1.402 7.649 Hardt’s Post-Process .097 .181 .018 .367 1.057 .321 .441 .226 .536 2.679 Constrained Opt. .105 .110 .049 .026 .076 .289 .263 .193 .369 2.003 Adv. Constr. Opt. .105 .105 .050 .064 .184 .303 .275 .022 .312 1.628 Wass-1 Penalty .114 .151 .001 .015 .050 .313 .315 .0 .008 .039 Wass-1 Penalty DB .114 .131 .001 .006 .018 .313 .315 .0 .011 .051 Wass-1 Post-Process .100 .144 .016 .020 .062 .321 .363 .226 .133 .680 Wass-1 Post-Process pˆ .097 .141 .014 .020 .063 .321 .335 .226 .159 .822 S Pre-processing and Sensitive Attributes. We pre- distribution. processed the data as for the Adult dataset. We trans- SPDD: SPDD = (cid:80) E |P(S > τ ) − a,a¯∈A τ∼U([0,1]) a formed the categorical features into binary ones, and the P(S > τ )|. This metric is the most important, a¯ continuous features into five binary features based on five target-neutral, (un)fairness measurement as it does quantile bins, obtaining a total of 60 features. We also not depend on the target distribution, e.g. the full- subtracted the mean from cons.price.idx, cons.conf.idx, dataset belief distribution or the barycenter. euribor3m, and nr.employed to make them zero-centered. As sensitive attributes, we considered age, which was Figure 1 shows overlaying model belief histograms for discretized based on five quantiles leading to five groups. four demographic groups and their barycenter in the The UCI Communities & Crime Dataset. This dataset Adult dataset. Wasserstein-1 Penalty effectively matches contains 135 attributes for 1994 communities; 1495 and all group histograms to the barycenter after training for 499 for the training and test sets respectively. The goal is 10,000 steps with β = 100. to predict whether a community has high (above the 70-th The main experiment results are shown in Tables 1 and percentile) crime rate. 27. Focusing on the three more relevant metrics – namely Pre-processing and Sensitive Attributes. We pre- Err-Exp as the robust error measure, SDD as the conven- processed the data as in Wu et al. (2018). As sensi- tional fairness comparison metric, and SPDD as the target- tive attributes, we considered race (Black, White, Asian neural, preferred fairness metric (according to which we and Hispanic), thresholded at the median to form height picked the best hyperparameter settings) – we can see that groups. Wass-1 Penalty and Wass-1 Penalty DB have lowest SDD and SPDD (blue) on the German and Crime datasets and on the Adult and Bank datasets respectively. The fairness 5.3 RESULTS performance of these two methods are followed closely by the simpler Wass-1 Post-Process methods on all datasets. We compared the different methods using the following Hardt’s Post-Process method incurs largest errors (red) metrics: on all datasets. After the Unconstrained baseline, Con- strained Optimization and Adv. Contr. Opt. give lowest Err-.5: Binary classification error using threshold τ = 0.5, i.e. Err-.5 = 1 (cid:80)N 1 . error on the Adult, Bank and Crime datasets, whilst Con- N n=1 yˆn(cid:54)=yn strained Optimization and Wass-1 Penalty (DB) give low- Err-Exp: As above, but averaging over 100 uniformly- est error on the German dataset. Overall the Wasserstein-1 spaced thresholds τ ∈ [0, 1]. methods gave best fairness performance on all the datasets DD-.5: Demographic disparity at τ = 0.5, summed over with similar or lower compromise on F1-score than the all groups a ∈ A, i.e. DD-.5 = (cid:80) |P(S > a∈A a baselines. 0.5) − P(S > 0.5)|, where e.g. P(S > τ ) is estimated as P(S > τ ) ≈ 1 (cid:80)N 1 . Since Wass-1 Penalty is trained by gradient descent, early- N n=1 sn>τ stopping can be an effective way to control trade-off be- SDD (strong demographic disparity): As above, but tween F1-score and fairness. Figure 2 shows a typical averaging over 100 uniformly-spaced thresholds τ ∈ [0, 1], i.e. SDD = (cid:80) E |P(S > example of two trade-off curves between SDD/SPDD and a∈A τ∼U([0,1]) a τ ) − P(S > τ )|. We use this metric to compare 7Given the deterministic baseline logistic regression model, with other baselines that use the full-dataset belief all standard deviations are on the order of 10−4 or below.
30 barycenter 25 group 20 15 10 5 0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 30 barycenter 25 group 20 15 10 5 0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 Figure 1: Histograms of model beliefs for groups of Black females, Black males, White females, and White males, and their barycenter on the Adult dataset using Wass-1 Penalty. Top: Initial state. Bottom: After 10,000 training steps with α = 0, β = 100 each group histogram matches the barycenter. 0.8 strated that using the Wasserstein-1 barycenter enables SPDD us to reach independence with minimal modifications SDD 0.7 of the model decisions. We introduced two methods 0.6 with different desirable properties, a Wasserstein-1 con- strained method that does not necessarily require access 0.5 to sensitive information at deployment time, and an al- ternative fast and practical approximation method that 0.4 requires knowledge of sensitive information at test time. 0.3 We showed that these methods outperform previous ap- proaches in the literature. 0.2 0.1 0.200 0.205 0.210 0.215 0.220 Acknowledgements Err-Exp Figure 2: Err-Exp v.s. SDD, Err-Exp v.s. SPDD trade-off The authors would like to thank Mark Rowland for useful curves on Bank test set using Wass-1 Penalty DB, points feedback on the manuscript. plotted every 100 steps over 80,000 total training steps. References Err-Exp. Though not always the case, often as the learn- A. Agarwal, A. Beygelzimer, M. Dud´ık, J. Langford, and ing model moves towards the fairness goal of SDP, model H. Wallach. A reduction approach to fair classification. F1-score decreases (Err-Exp increases). In Proceedings of the 35th International Conference on Machine Learning, 2018. 6 CONCLUSIONS M. Agueh and G. Carlier. Barycenters in the Wasserstein space. SIAM Journal on Mathematical Analysis, 43(2): 904–924, 2011. We introduced an approach to ensure that the output of a classification system does not depend on sensitive in- J. Benamou, G. Carlier, M. Cuturi, L. Nenna, and formation using the Wasserstein-1 distance. We demon- G. Peyre´. Iterative Bregman projections for regularized
transportation problems. SIAM Journal on Scientific constraints. In Advances in Neural Information Pro- Computing, 2(37):A1111–A1138, 2015. cessing Systems 31, pages 2791–2801, 2018. A. Beutel, J. Chen, Z. Zhao, and E. H. Chi. Data deci- E. Eban, M. Schain, A. Mackey, A. Gordon, R. Rifkin, sions and theoretical implications when adversarially and G. Elidan. Scalable learning of non-decomposable learning fair representations. CoRR, abs/1707.00075, objectives. In Proceedings of the 20th International 2017. Conference on Artificial Intelligence and Statistics, S. Boyd and L. Vandenberghe. Convex Optimization. pages 832–840, 2017. Cambridge University Press, 2004. H. Edwards and A. Storkey. Censoring representations T. Calders, F. Kamiran, and M. Pechenizkiy. Building with an adversary. In 4th International Conference on classifiers with independency constraints. In Data min- Learning Representations, 2016. ing workshops, 2009. ICDMW’09. IEEE international V. Eubanks. Automating Inequality: How High-Tech conference on, pages 13–18, 2009. Tools Profile, Police, and Punish the Poor. St. Martin’s F. Calmon, D. Wei, B. Vinzamuri, K. N. Ramamurthy, and Press, 2018. K. R. Varshney. Optimized pre-processing for discrim- M. Feldman. Computational fairness: Preventing ination prevention. In Advances in Neural Information machine-learned discrimination. 2015. Processing Systems 30, pages 3995–4004, 2017. M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, S. Chiappa. Path-specific counterfactual fairness. In and S. Venkatasubramanian. Certifying and removing Thirty-Third AAAI Conference on Artificial Intelligence, disparate impact. In Proceedings of the 21th ACM pages 7801–7808, 2019. SIGKDD International Conference on Knowledge Dis- S. Corbett-Davies, E. Pierson, A. Feller, S. Goel, and covery and Data Mining, pages 259–268, 2015. A. Huq. Algorithmic decision making and the cost of B. Fish, J. Kun, and A. D. Lelkes. Fair boosting: a case fairness. In Proceedings of the 23rd ACM SIGKDD study. In FAT/ML Workshop, 2015. International Conference on Knowledge Discovery and Data Mining, pages 797–806, 2017. R. Flamary and N. Courty. POT python optimal transport library, 2017. https://github.com/ A. Cotter, H. Jiang, and K. Sridharan. Two-player rflamary/POT. games for efficient non-convex constrained optimiza- tion. CoRR, abs/1804.06500, 2018. G. Goh, A. Cotter, M. Gupta, and M. P. Friedlander. Sat- isfying real-world goals with dataset constraints. In M. Cuturi. Sinkhorn distances: Lightspeed computation Advances in Neural Information Processing Systems of optimal transport. In Advances in Neural Informa- 29, pages 2415–2423, 2016. tion Processing Systems 26, pages 2292–2300, 2013. M. Hardt, E. Price, and N. Srebro. Equality of oppor- J. De Fauw et al. Clinically applicable deep learning tunity in supervised learning. In Advances in Neural for diagnosis and referral in retinal disease. Nature Information Processing Systems 29, pages 3315–3323, Medicine, 24(9):1342–1350, 2018. 2016. E. Del Barrio, F. Gamboa, P. Gordaliza, and J.-M. Loubes. M. Hoffman, L. B. Kahn, and D. Li. Discretion in hiring. Obtaining fairness using optimal transport theory. In The Quarterly Journal of Economics, 133(2):765–800, Proceedings of the 36th International Conference on 2018. Machine Learning, pages 2357–2365, 2019. I. Deshpande, Z. Zhang, and A. G. Schwing. Generative J. Johndrow and K. Lum. An algorithm for removing modeling using the sliced Wasserstein distance. In sensitive information: Application to race-independent The IEEE Conference on Computer Vision and Pattern recidivism prediction. The Annals of Applied Statistics, Recognition, 2018. 13(1):189–220, 2019. W. Dieterich, C. Mendoza, and T. Brennan. Compas risk F. Kamiran and T. Calders. Classifying without dis- scales: Demonstrating F1-score equity and predictive criminating. In Computer, Control and Communica- parity, 2016. tion, 2009. IC4 2009. 2nd International Conference on, pages 1–6, 2009. N. A. Doherty, A. V. Kartasheva, and R. D. Phillips. Infor- mation effect of entry into credit ratings market: The F. Kamiran and T. Calders. Data preprocessing techniques case of insurers’ ratings. Journal of Financial Eco- for classification without discrimination. Knowledge nomics, 106(2):308–330, 2012. and Information Systems, 33(1):1–33, 2012. M. Donini, L. Oneto, S. Ben-David, J. Shawe-Taylor, and L. Kantorovich. On the transfer of masses (in Russian). M. Pontil. Empirical risk minimization under fairness Doklady Akademii Nauk, 37(2):227–229, 1942.
A. Klenke. Probability Theory: A Comprehensive Course. M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. Springer Science & Business Media, 2013. P. Gummadi. Fairness constraints: Mechanisms for fair classification. In Proceedings of the 20th Interna- J. Komiyama, A. Takeda, J. Honda, and H. Shimao. Non- tional Conference on Artificial Intelligence and Statis- convex optimization for regression with fairness con- tics, pages 962–970, 2017. straints. In Proceedings of the 35th International Con- ference on Machine Learning, pages 2742–2751, 2018. R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork. Learning fair representations. In Proceedings of the M. J. Kusner, J. R. Loftus, C. Russell, and R. Silva. Coun- 30th International Conference on Machine Learning, terfactual fairness. In Advances in Neural Information pages 325–333, 2013. Processing Systems 30, pages 4069–4079, 2017. B. Zhang, H Lemoine, and M. Mitchell. Mitigating un- C.-A. Laisant. Inte´gration des fonctions inverses. Nou- wanted biases with adversarial learning. In Proceedings velles annales de mathmatiques, journal des candidats of the 2018 AAAI/ACM Conference on AI, Ethics, and aux coles polytechnique et normale, 5 (4):253–257, Society, pages 335–340, 2018. 1905. I. Zˇ liobaite, F. Kamiran, and T. Calders. Handling condi- M. Lichman. UCI Machine Learning Repository, 2013. tional discrimination. In Proceedings of the 2011 IEEE http://archive.ics.uci.edu/ml. 11th International Conference on Data Mining, pages 992–1001, 2011. C. Louizos, K. Swersky, Y. Li, M. Welling, and R. Zemel. The variational fair autoencoder. In 4th International Conference on Learning Representations, 2016. M. Malekipirbazari and V. Aksakalli. Risk assessment in social lending via random forests. Expert Systems with Applications, 42(10):4621–4631, 2015. P. Massart. The tight constant in the Dvoretzky-Kiefer- Wolfowitz inequality. The Annals of Probability, pages 1269–1283, 1990. G. Monge. Memoire sur la theorie des de´blais et des remblais. Histoire de l’ Acade´mie des Sciences de Paris, 1781. H. Narasimhan. Learning with complex loss functions and constraints. In Proceedings of the 21st Interna- tional Conference on Artificial Intelligence and Statis- tics, pages 1646–1654, 2018. F. Pedregosa and et al. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12: 2825–2830, 2011. C. Perlich, B. Dalessandro, T. Raeder, O. Stitelman, and F. Provost. Machine learning for targeted display adver- tising: Transfer learning in action. Machine Learning, 95(1):103–127, 2014. S. Rachev and L. Ru¨schendorf. Mass Transportation Problems. Springer, 1998. J. Weed and F. Bach. Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasser- stein distance. CoRR, abs/1707.00087, 2017. S. Wu, M. Kearns, S. Neel, and A. Roth. Preventing fair- ness gerrymandering: Auditing and learning for sub- group fairness. In Proceedings of the 35th International Conference on Machine Learning, pages 2564–2572, 2018.
Appendix A Empirical Estimates (cid:80) L (cid:80)e am pm aa W1 1. (pA S¯s ,| pD S| a→ ) al∞ mo, sif t W su1 re( lp yS 8, . p Sa) < ∞ for all a, the empirical barycenter satisfies lim a pˆ aW 1(pˆ S¯, pˆ Sa) → Proof. By triangle inequality: (cid:88) (cid:88) pˆ aW 1(pˆ S¯, p Sa) ≤ pˆ aW 1(pˆ S¯, pˆ Sa) + pˆ aW 1(p Sa, pˆ Sa) , (4) a a (cid:88) (cid:88) p aW 1(p S¯, pˆ Sa) ≤ p aW 1(p S¯, p Sa) + p aW 1(p Sa, pˆ Sa) . (5) a a Since p S¯ and pˆ S¯ are the weighted barycenters of {p Sa} and {pˆ Sa} respectively: (cid:88) (cid:88) p aW 1(p S¯, p Sa) ≤ p aW 1(pˆ S¯, p Sa) , (6) a a (cid:88) (cid:88) pˆ aW 1(pˆ S¯, pˆ Sa) ≤ pˆ aW 1(p S¯, pˆ Sa) . (7) a a Combining Eqs. (4) and (6), and (5) and (7): (cid:88) (cid:88) p aW 1(p S¯, p Sa) ≤ p aW 1(pˆ S¯, pˆ Sa) + p aW 1(p Sa, pˆ Sa) a a (cid:88) ≤ pˆ aW 1(pˆ S¯, pˆ Sa) + |pˆ aW 1(pˆ S¯, pˆ Sa) − p aW 1(pˆ S¯, pˆ Sa)| + p aW 1(p Sa, pˆ Sa) a (cid:88) ≤ pˆ aW 1(pˆ S¯, pˆ Sa) + |pˆ a − p a| · |W 1(pˆ S¯, pˆ Sa)| + p aW 1(p Sa, pˆ Sa) a (cid:88) (cid:88) pˆ aW 1(pˆ S¯, pˆ Sa) ≤ pˆ aW 1(p S¯, p Sa) + pˆ aW 1(p Sa, pˆ Sa) a a (cid:88) ≤ p aW 1(p S¯, p Sa) + |p aW 1(p S¯, p Sa) − pˆ aW 1(p S¯, p Sa)| + pˆ aW 1(p Sa, pˆ Sa) a (cid:88) ≤ p aW 1(p S¯, p Sa) + |p a − pˆ a| · |W 1(p S¯, p Sa)| + pˆ aW 1(p Sa, pˆ Sa) . a Therefore the following inequality holds almost surely: (cid:12) (cid:88) (cid:88) (cid:12) (cid:88) (cid:12) (cid:12) p aW 1(p S¯, p Sa) − pˆ aW 1(pˆ S¯, pˆ Sa)(cid:12) (cid:12) ≤ pˆ aW 1(p Sa, pˆ Sa) + |p a − pˆ a| · W 1(p S¯, p Sa) a a a (cid:88) ≤ W 1(p Sa, pˆ Sa) + |p a − pˆ a| · W 1(p S¯, p Sa) a (cid:88) ≤ W (p , pˆ ) + |p − pˆ | · W (p , p ) . 1 Sa Sa a a 1 S Sa a Since W (p , pˆ ) → 0 almost surely for all a (see Weed and Bach (2017)), and pˆ → p almost surely (by the 1 Sa Sa a a strong law of large numbers) and W (p , p ) < ∞ for all a, the result follows: 1 S Sa (cid:88) (cid:88) lim pˆ aW 1(pˆ S¯, pˆ Sa) → p aW 1(p S¯, p Sa) , a a almost surely. 8See Klenke (2013) for a formal definition of almost sure convergence of random variables.
B Generalization T Lh ee t Pfo Sll ,o Pw Si ang anle dm Pm S¯a ba edd tr he ess ce us mg uen lae tr ia vl eiz da eti no sn ito yf ft uh ne cW tioas ns ser os fte Sin ,- S1 aob aj ne dcti S¯v .e. AA ss ss uu mm ee tW he1 s( ep rS aa n, dp oS¯ m) ≤ vaL riaf bo lr ea sll ala l h∈ avA e. domain Ω = [0, 1] and that all P ∈ {P S, P S¯} ∪ {P Sa} a∈A are continuous, then: Lemma 5. For any (cid:15), δ > 0, if min (cid:2) N¯ , min (cid:2) N (cid:3)(cid:3) ≥ 16 log(2|A|/δ)|A|2 max[1,L]2 , with probability 1 − δ: a a (cid:15)2 (cid:88) (cid:88) p aW 1(p Sa, p S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + (cid:15) . a∈A a∈A (cid:80) I (cid:80)n other words, provided access to sufficient samples, a low value of a pˆ aW 1(pˆ Sa, pˆ S¯) implies a low value for a p aW 1(p Sa, p S¯) with high probability and therefore good performance at test time. Proof. We start with the case when p S¯ = p S. By the triangle inequality for Wasserstein-1 distances, for all a ∈ A: pˆ aW 1(p Sa, p S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + pˆ aW 1(pˆ S¯, p S¯) + pˆ aW 1(pˆ Sa, p Sa) . (8) Let Pˆ for P ∈ {P S, P S¯} ∪ {P Sa} a∈A denote the empirical CDF of P . Since their domain is restricted to [0, 1] and are one dimensional random variables: (cid:90) 1 W (pˆ , p ) = |Pˆ(x) − P (x)|dx . (9) 1 S∗ S∗ 0 For S ∗ ∈ {S, S¯} ∪ {S a} a∈A. Since P ∈ {P S, P S¯} ∪ {P Sa} a∈A are all continuous, the Dvorestky-Kiefer-Wolfowitz theorem (see main theorem in Massart (1990) ) and the condition min (cid:2) N¯ , min (cid:2) N (cid:3)(cid:3) ≥ 16 log(2|A|/δ)|A|2 max[1,L]2 a a (cid:15)2 implies that: (cid:32) (cid:33) (cid:15) δ P sup |Pˆ(x) − P (x)| ≥ ≤ . 4 2|A| x∈[0,1] Since all the random variables have domain [0, 1] this in turn implies that for all S ∈ {S, S¯} ∪ {S } : ∗ a a∈A (cid:16) (cid:15) (cid:17) δ P W (pˆ , p ) ≥ ≤ . 1 S∗ S∗ 4 2|A| And therefore that with probability ≥ 1 − δ the following inequalities hold simultaneously for all a ∈ A: 2 pˆ (cid:15) pˆ (cid:15) pˆ aW 1(pˆ S¯, p S¯) ≤ 4a , pˆ aW 1(pˆ Sa, p Sa) ≤ 4a . (10) Summing Eq. (8) over a and applying the last observation yields (cid:88) (cid:88) (cid:15) pˆ aW 1(p Sa, p S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + 2 . a∈A a∈A Recall that we assume ∀a ∈ A, W 1(p Sa, p S¯) ≤ L . By concentration of measure of Bernoulli random variables, with probability ≥ 1 − δ the following inequality holds 2 simultaneously for all a ∈ A: (cid:15) |p − pˆ | ≤ . (11) a a 4|A| max[L, 1] Consequently the desired result holds: (cid:88) (cid:88) p aW 1(p Sa, p S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + (cid:15) . a∈A a∈A
f g 0 1 1 f g 1 0 1 (a) Left side of Eq. (12) (b) Right side of Eq. (12) Figure 3: Integrating |f −1 − g−1| along the x axis (left) and integrating |f − g| along the y axis (right) both compute the area of the same shaded region, thus the equality in Eq. (12). If p S¯ equals the weighted barycenter of the population level distributions {p Sa}, then (cid:88) (cid:88) p aW 1(p Sa, p S¯) ≤ p aW 1(p Sa, pˆ S¯) . a∈A a∈A Since pˆ aW 1(p Sa, pˆ S¯) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + pˆ aW 1(pˆ Sa, p Sa), with probability 1 − δ: (cid:88) (cid:88) (cid:15) p aW 1(p Sa, p S¯) ≤ pˆ aW 1(p Sa, p S¯) + 2 a∈A a∈A (cid:88) (cid:15) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + pˆ aW 1(pˆ Sa, p Sa) + 2 a∈A (cid:88) ≤ pˆ aW 1(pˆ Sa, pˆ S¯) + (cid:15) a∈A The first inequality follows from Eq. (11), and the third one by Eq. (10). The result follows. C Inverse CDFs Lemma 6. Given two differentiable and invertible cumulative distribution functions f, g over the probability space Ω = [0, 1], thus f, g : [0, 1] → [0, 1], we have (cid:90) 1 (cid:90) 1 |f −1(s) − g−1(s)|ds = |f (τ ) − g(τ )|dτ. (12) s=0 τ=0 Intuitively, we see that the left and right side of Eq. (12) correspond to two ways of computing the same shaded area in Figure 3. Here is a complete proof. Proof. Invertible CDFs f, g are strictly increasing functions due to being bijective and non-decreasing. Furthermore, we have f (0) = 0, f (1) = 1 by definition of CDFs and Ω = [0, 1], since P (X ≤ 0) = 0, P (X ≤ 1) = 1 where X is the corresponding random variable. The same holds for the function g. Given an interval (x , x ) ⊂ [0, 1], let 1 2 y = f (x ), y = f (x ). Since f is differentiable, we have 1 1 2 2 (cid:90) x2 (cid:90) y2 f (x)dx + f −1(y)dy = x y − x y . (13) 2 2 1 1 x=x1 y=y1
The proof of Eq. (13) is the following (see also Laisant (1905)). f −1(f (x)) = x =⇒f (cid:48)(x)f −1(f (x)) = f (cid:48)(x)x (multiply both sides by f (cid:48)(x)) (cid:90) x2 (cid:90) x2 =⇒ f (cid:48)(x)f −1(f (x))dx = f (cid:48)(x)xdx (integrate both sides) x=x1 x=x1 (cid:90) y2 (cid:90) x2 =⇒ f −1(y)dy = f (cid:48)(x)xdx (apply change of variable y = f (x) on the left side) y=y1 x=x1 =⇒ (cid:90) y2 f −1(y)dy = xf (x)(cid:12) (cid:12) (cid:12)x2 − (cid:90) x2 f (x)dx (integrate by parts on the right side) (cid:12) y=y1 x=x1 x=x1 (cid:90) y2 (cid:90) x2 =⇒ f −1(y)dy + f (x)dx = x y − x y . 2 2 1 1 y=y1 x=x1 Define a function h := f − g on [0, 1]. Then h is differentiable and thus continuous. Define the set of roots A := {x ∈ [0, 1] | h(x) = 0}. Define the set of open intervals on which either h > 0 or h < 0 by B := {(a, b) | b = inf{s ∈ A | a < s}, 0 ≤ a < b ≤ 1, a ∈ A}. By continuity of h, for any (a, b) ∈ B, we have b ∈ A, i.e. b is also a root of h. Since there are no other roots of h in (a, b), by continuity of h, we must have either h > 0 or h < 0 on (a, b). For any two elements (a, b), (c, d) ∈ B, we argue that they must be disjoint intervals. Without loss of generality, we assume a < c. Since b = inf{s ∈ A | a < s} ≤ c, i.e. b ≤ c, then (a, b) ∩ (c, d) = ∅. For any open interval (a, b) ∈ B, there exists a rational number q ∈ Q such that a < q < b. We pick such a rational number and call it q . Since all (a,b) elements of B are disjoint, for any two intervals (a , b ), (a , b ) containing q , q ∈ Q respectively, we must 0 0 1 1 (a0,b0) (a1,b1) have q (cid:54)= q . We define the set Q := {q ∈ Q | (a, b) ∈ B}. Then Q ⊂ Q and |Q | = |B|. Since (a0,b0) (a1,b1) B (a,b) B B the set of rational numbers Q is countable, the set B must also be countable. Let B = {(a , b )}N where N ∈ N or i i i=0 N = ∞. Recall that h = f − g on [0, 1], h(a ) = 0, h(b ) = 0 and either h < 0 or h > 0 on (a , b ) for ∀i > 0. i i i i Consider the interval (a , b ) for some i > 0, by Eq.13 we have i i (cid:90) bi (cid:90) f(bi) f (τ )dτ + f −1(s)ds = b f (b ) − a f (a ) i i i i τ=ai s=f(ai) (cid:90) bi (cid:90) g(bi) = b g(b ) − a g(a ) = g(τ )dτ + g−1(s)ds. i i i i τ=ai s=g(ai) Thus (cid:90) bi (cid:90) f(bi) f (τ ) − g(τ )dτ = g−1(s) − f −1(s)ds. τ=ai s=f(ai) Notice that if f > g on [a , b ], then f −1 < g−1 on [f (a ), f (b )]. This is due to the following. Given any y ∈ i i i i [f (a ), f (b )] = [g(a ), g(b )], we have g−1(y) ∈ [a , b ] and f (g−1(y)) > g(g−1(y)) = y = f (f −1(y)). Thus i i i i i i g−1 > f −1 since f is strictly increasing. The contrary holds by the same reasoning, i.e. if f < g on [a , b ], then i i f −1 > g−1 on [f (a ), f (b )]. Therefore, i i (cid:90) bi (cid:90) f(bi) |f (τ ) − g(τ )|dτ = |g−1(s) − f −1(s)|ds, τ=ai s=f(ai) which holds for all intervals (a , b ). Summing over i on both sides, we have i i (cid:88)N (cid:90) bi (cid:88)N (cid:90) f(bi) |f (τ ) − g(τ )|dτ = |g−1(s) − f −1(s)|ds, i=0 τ=ai i=0 s=f(ai) or equivalently, (cid:90) 1 (cid:90) 1 |f −1(s) − g−1(s)|ds = |f (τ ) − g(τ )|dτ. s=0 τ=0
