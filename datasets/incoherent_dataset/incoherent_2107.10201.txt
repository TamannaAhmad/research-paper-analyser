Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Nicolas Sonnerat * 1 Pengming Wang * 1 Ira Ktena 1 Sergey Bartunov 2 3 Vinod Nair 2 4 *Equal contribution Abstract (CP) (Perron et al., 2004; Berthold et al., 2012). Given a problem instance and an initial feasible assignment (i.e., Large Neighborhood Search (LNS) is a combi- an assignment satisfying all constraints of the problem) of natorial optimization heuristic that starts with an values to the variables of the problem, LNS searches for a assignment of values for the variables to be op- better assignment within a neighborhood of the current one timized, and iteratively improves it by searching at each iteration. Iterations continue until the search budget a large neighborhood around the current assign- (e.g., time) is exhausted. The neighborhood is ‚Äúlarge‚Äù in ment. In this paper we consider a learning-based the sense that it contains too many assignments to tractably LNS approach for mixed integer programs (MIPs). search with naive enumeration. Large neighborhoods make We train a Neural Diving model to generate an the search less susceptible to getting stuck in poor local initial assignment. Formulating the subsequent optima. search steps as a Markov Decision Process, we train a Neural Neighborhood Selection policy to Two key choices that determine the effectiveness of LNS are select a search neighborhood at each step, which 1) the initial assignment, and 2) the search neighborhood is searched using a MIP solver to find the next as- at each iteration. A good initial assignment makes good signment. The policy network is trained using imi- optima more likely to be reached. A good neighborhood tation learning. We propose a target policy for im- selection policy allows faster convergence to good optima. itation that is designed to select the neighborhood Domain experts design sophisticated heuristics by exploiting containing the optimal next assignment amongst problem structure to find an initial feasible assignment, e.g. all possible choices for the neighborhood of a for MIPs, (Fischetti et al., 2005; Berthold, 2007) and to specified size. Our approach matches or outper- define the neighborhood, e.g. Pisinger & Ropke (2010); forms all the baselines on five diverse real-world Shaw (1998); Danna et al. (2005). MIP datasets with large-scale instances, including In this paper we use learned models to make both of these two production applications at a large technology choices. We focus specifically on Mixed Integer Programs company. It achieves 2√ó to 37.8√ó better average to demonstrate the approach, but it can be adapted to other primal gap than the best baseline on three datasets combinatorial optimization problems also. Figure 1 gives at large running times. a summary. To compute an initial feasible assignment of values for the variables, we use Neural Diving (section 2.2) proposed in Nair et al. (2020), which has been shown to 1. Introduction produce high quality assignments quickly. The assignment is computed using a generative model that conditions on the Large Neighborhood Search (LNS) (Shaw, 1998; Pisinger & input MIP and defines a distribution over assignments such Ropke, 2010) is a powerful heuristic for hard combinatorial that ones with better objective values are more probable. optimization problems such as Mixed Integer Programs To define the search neighborhood at each LNS iteration, (MIPs) (Danna et al., 2005; Rothberg, 2007; Berthold, 2007; we use a Neural Neighborhood Selection policy (section 3) Ghosh, 2007), Traveling Salesman Problem (TSP) (Smith that, conditioned on the current assignment, selects a subset & Imeson, 2017), Vehicle Routing Problem (VRP) (Shaw, of the integer variables in the input MIP to unassign their 1998; Hojabri et al., 2018), and Constraint Programming values. The policy‚Äôs decisions can then be used to derive 1DeepMind, London, UK 2Work done at DeepMind from the input MIP a smaller ‚Äúsub-MIP‚Äù to optimize the 3Charm Therapeutics, London, UK 4Google Research, unassigned variables. By setting the number of unassigned Bangalore, India. Correspondence to: Nicolas Sonnerat integer variables sufficiently small, the sub-MIP can be <sonnerat@deepmind.com>, Pengming Wang <peng- solved quickly using an off-the-shelf solver to compute the ming@deepmind.com>. assignment for the next LNS step. The policy is trained by 2202 yaM 02 ]CO.htam[ 3v10201.7012:viXra
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Neural Neighborhood Input MIP asIn sii gtia nl miz ee n t 1 Selection Select ùúÇ 1 Sub-problem 1 t with ùúÇ Neural 10 va ur nia ab sl se igs nto ** variablet s Off-the-shelf 01 Output final Diving 1 1 Solver 1 assignment 0 * 0 0 0 0 Update current assignment Figure 1: Overview of our approach at test time. The input is a mixed integer program (MIP). Neural Diving (Nair et al., 2020) combines a generative model with an off-the-shelf MIP solver to output an initial assignment x for the variables x to 0 be optimized. At the tth iteration of LNS the Neural Neighborhood Selection policy selects Œ∑ variables to be unassigned t (indicated by red, with Œ∑ = 3) from the current assignment x . A sub-MIP defined on those Œ∑ variables is solved with t t t a MIP solver to assign them new values (orange) to define the next assignment x . Iterations continue until the search t+1 budget is exhausted. imitating an expert neighborhood selection policy (section 1. We present a scalable learning-based LNS algorithm 3.2). At each LNS iteration, the expert is designed to select that combines learned models for computing the initial the best assignment in a Hamming ball centered around the assignment and for selecting the search neighborhood current assignment by solving a MIP optimally. The changes at each LNS step. in the values of the integer variables between the current and 2. We propose an imitation learning approach to train the new assignments give the expert‚Äôs unassignment decisions to neighborhood selection policy using as the imitation use as targets for imitation learning. The expert itself is too target an expert policy that, under certain assumptions, computationally expensive for a practical LNS algorithm, is guaranteed to select the neighborhood containing the but is still tractable for generating imitation training data optimal next assignment at a given LNS step. offline. The neural network trained to approximate it can be orders of magnitude faster, making it practical to use at test 3. We show results on five diverse large-scale real-world time. datasets, including two from the production systems Previous works have combined learning with LNS. Hottung of a large technology company. It matches or outper- & Tierney (2019) use an approach complementary to ours forms all baselines on all of them, with a 2 ‚àí 37.8√ó for Capacitated VRPs by learning to search the neighbor- improvement over the best baseline with respect to the hood, instead of to select it. In our setting, since off-the-shelf main performance metric, average primal gap, on three MIP solvers can already search neighborhoods, we expect of them. learning to be more useful for neighborhood selection. Song et al. (2020) learn a neighborhood selection policy using We have also published source code for the key compo- imitation learning and supervised learning (RL). Their nents of our approach, covering data generation, training, method restricts the neighborhood selection policy to choose and inference, at https://github.com/deepmind/ fixed, predefined variable subsets, instead of arbitrary sub- neural_lns. sets in our work. It uses a random neighborhood selection policy to generate training data for imitation learning. Ad- 2. Background danki et al. (2020) use RL to learn a policy that unassigns one variable at a time, interleaved with solving a sub-MIP 2.1. Mixed Integer Programming every Œ∑ steps to compute a new assignment. For large MIPs, A Mixed Integer Program is defined as min {f (x) = one neural network policy evaluation per variable can be x cT x | Ax ‚â§ b, x ‚àà Z, i ‚àà I}, where x ‚àà Rn are the prohibitively slow. Our approach is scalable ‚Äì both selecting i variables to be optimized, A ‚àà Rm√ón and b ‚àà Rm specify an initial assignment and a search neighbourhood at each m linear constraints, c ‚àà Rn specifies the linear objective LNS step are posed as modelling the joint distribution of function, and I ‚äÜ {1, . . . , n} is the index set of integer a large number of simultaneous decisions. This allows us variables. If I = ‚àÖ, the resulting continuous optimization to exploit high-dimensional generative models for scalable problem is called a linear program, which is solvable in training and inference. To demonstrate scalability, we eval- polynomial time. A feasible assignment is a point x ‚àà Rn uate on real world datasets with large-scale MIPs, unlike that satisfies all the constraints. A complete solver tries to earlier works. produce a feasible assignment and a lower bound on the opti- Contributions: mal objective value, and given sufficient compute resources will find the optimal assignment or prove that there exists no
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs feasible one. A primal heuristic (see, e.g., Berthold 2006) 3. Neural Neighborhood Selection only attempts to find a feasible assignment. This work fo- 3.1. MDP Formulation cuses on primal heuristics as production applications often only require finding a good feasible assignment quickly. We consider a contextual Markov Decision Process (Abbasi- Yadkori & Neu, 2014; Hallak et al., 2015) M parameter- z 2.2. Neural Diving ized with respect to a context z, where the state space, action space, reward function, and the environment all depend on Neural Diving (Nair et al., 2020) is a learning-based primal z. Here we define z to be the parameters of the input MIP, heuristic. It learns a probability distribution for assignments i.e., z = M = {A, b, c}. The state s at the tth step of an of integer variables of the input MIP M such that assign- t episode is the current assignment x of values for all the ments with better objective values have higher probability. t integer variables in M . The action a ‚àà {0, 1}|I| at step t Assuming minimization, an energy function is defined over t is the choice of the set of integer variables to be unassigned, the integer variables of the problem x = {x |i ‚àà I} as I i specified by one indicator variable per integer variable in M where 1 means unassigned. All continuous variables are labelled as unassigned at every LNS step. For real-world applications the number of integer variables |I| is typically (cid:40) fÀÜ(x ) if x is feasible, large (103 ‚àí106), so the actions are high-dimensional binary E(x ; M ) = I I (1) I ‚àû otherwise, vectors. The policy œÄ Œ∏(a t|s t, M ) defines the distribution over actions, parameterized by Œ∏. We use a conditional gen- erative model to represent this high-dimensional distribution over binary vectors (section 3.3). where fÀÜ(x ) is the objective value obtained by substi- Given s t and a t, the environment derives a sub-MIP M t(cid:48) = I {A(cid:48) , b(cid:48) , c(cid:48) } from M containing only the unassigned integer tuting x for the integer variables in M and assigning t t t I variables and all continuous variables, and optimizes it. M (cid:48) the continuous variables to the solution of the result- t is computed by substituting the values in x of the assigned ing linear program. The target distribution is defined as t variables into M to derive constraints and objective function p(x |M ) = exp(‚àíE(x ; M ))/Z(M ) where Z(M ) = (cid:80) I exp(‚àíE(x(cid:48) ; M )) isI the partition function. The model with respect to the rest of the variables. M t(cid:48) is guaranteed is tx r(cid:48) I ained to minI imize a weighted negative log likelihood to have a non-empty feasible set ‚Äì the values in x t of the unassigned variables itself is a feasible assignment for M (cid:48). loss on the training set {(M (j), x( Ij)))}N j=1 of N MIPs and The set of feasible assignments for M (cid:48) is the search neight - t corresponding assignments collected with an off-the-shelf borhood for step t. The environment calls an off-the-shelf solver. Assignments with better objective values are given MIP solver, in our case the state-of-the-art non-commercial larger weights so that the model better approximates the MIP solver SCIP 7.0.1 (Gamrath et al., 2020), to search target distribution. this neighborhood. The output of the solve is then com- Nair et al. (2020) represent the MIP as a bipartite graph (see, bined with the values of the already assigned variables to e.g., Gasse et al. (2019)) and use a Graph Convolutional construct a new feasible assignment x t+1 for M . If the Network (Battaglia et al., 2018; Gori et al., 2005; Scarselli solver outputs an optimal assignment for the sub-MIP, then et al., 2008; Hamilton et al., 2017; Kipf & Welling, 2016) cT x t+1 ‚â§ cT x t. The per-step reward can be defined using to parameterize a conditionally independent model of the a metric that measures progress towards an optimal assign- joint distribution over integer variable assignments. ment (Addanki et al., 2020), such as the negative of the primal gap (Berthold, 2006) (see equation 9) which is nor- Given a MIP at test time, the model‚Äôs predicted distribution malized to be numerically comparable across MIPs (unlike, is used to generate multiple partial assignments for the inte- e.g., the raw objective values). ger variables. For each such partial assignment, substituting the values of the assigned variables in M defines a sub-MIP An episode begins with an input MIP M and an initial with only the unassigned variables, which is then solved feasible assignment x 0. It proceeds by running the above by an off-the-shelf MIP solver to complete the assignment. MDP to perform large neighborhood search until the search Neural Diving outputs the best assignment among all such budget (e.g., time) is exhausted. complete assignments. Since each partial assignment can The size of the search neighborhood at the tth step typically be completed in parallel, Neural Diving is well-suited to increases exponentially with the number of unassigned inte- exploit parallel computation for faster runtimes. Results ger variables Œ∑ . Larger neighborhoods can make LNS less t in Nair et al. (2020) show that Neural Diving is effective susceptible to getting stuck at local optima, but it can also in producing high quality assignments quickly on several be computationally more expensive to search. We treat Œ∑ t datasets. See that paper for further details.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs as a hyperparameter to control this tradeoff. Gasse et al. (2019). For the Neural Neighborhood Selection policy network, we additionally use a fixed-size window of 3.2. Expert Neighborhood Selection Policy past variable assignments as variable node features. The window size is set to 3 in our experiments. We propose an expert policy that aims to compute the unas- signment decisions a‚àó for finding the optimal next assign- Network architecture: We use a Graph Convolutional Net- t ment x‚àó across all possible search neighborhoods around work to represent the policy. Let the input to the GCN be t+1 x given by unassigning any Œ∑ integer variables. It uses a graph G = (V, E, A) defined by the set of nodes V, the t t local branching (Fischetti & Lodi, 2003) to compute the set of edges E, and the graph adjacency matrix A. In the optimal next assignment x‚àó within a given Hamming ball case of MIP bipartite graphs, V is the union of n variable t+1 of radius Œ∑ centered around the current assignment x . The nodes and m constraint nodes, of size K := |V| = n + m. t t minimal set of unassignment decisions a‚àó t is then derived A is an K √ó K binary matrix with A ij = 1 if nodes in- by comparing the values of the integer variables between x dexed by i and j are connected by an edge, 0 otherwise, and t and x‚àó t+1 and labelling only those with different values as A ii = 1 for all i. Let U ‚àà RK√óD be the matrix containing unassigned. If the policy œÄ (a |x , M ) takes the action a‚àó D-dimensional feature vectors of all nodes as rows. Œ∏ t t t and the corresponding sub-MIP M (cid:48) = {A(cid:48) , b(cid:48) , c(cid:48) } is solved t t t t An L-layer GCN is defined as follows: optimally by the environment, then the next assignment will be x‚àó t+1. Z(0) = U (3) Local branching adds a constraint to the input MIP M such Z(l+1) = Ag (Z(l)), l = 0, . . . , L ‚àí 1, (4) œÜ(l) that only those assignments for x within a Hamming t+1 ball around x t are feasible. If all integer variables in M are where Z(l) ‚àà RK√óH(l) is the matrix of H(l)-dimensional binary, the constraint is: node embeddings for the K nodes as rows, and g () is œÜ(l) a Multi-Layer Perceptron (MLP) (Goodfellow et al., 2016) (cid:88) (cid:88) x t+1,i + (1 ‚àí x t+1,i) ‚â§ Œ∑ t, (2) with learnable parameters œÜ(l) ‚àà Œ∏ for the lth layer applied i‚ààI:xt,i=0 i‚ààI:xt,i=1 row-wise to Z(l). The Lth layer‚Äôs node embeddings can be used as input to another MLP that computes the outputs for where x t,i denotes the ith dimension of x t and Œ∑ t is the the final prediction task. desired Hamming radius. The case of general integers can The policy is a conditionally independent model also be handled (see, e.g., slide 23 of Lodi (2003)). The optimal solution of the MIP with the extra constraint will (cid:89) differ from x t only on at most Œ∑ t dimensions, so it is the best œÄ Œ∏(a t|x t, M ) = p Œ∏(a t,i|x t, M ), (5) assignment across all search neighborhoods for the desired i‚ààI number of unassigned integer variables. which predicts the probability of a , the ith dimension of t,i The expert itself is too slow to be directly useful for solving a , independently of its other dimensions conditioned on M t MIPs, especially when the number of variables and con- and x using the Bernoulli distribution p (a |x , M ). Its t Œ∏ t,i t straints are large. Instead it is used to generate episode success probability ¬µ is computed as t,i trajectories from a training set of MIPs for imitation learn- ing. As a one-time offline computation, the compute budget Œª = MLP(v ; Œ∏), (6) t,i t,i for data generation can be much higher than that of solving 1 ¬µ = p (a = 1|x , M ) = , (7) a MIP, which enables the use of a slow expert. t,i Œ∏ t,i t 1 + exp(‚àíŒª ) t,i 3.3. Policy Network where v ‚àà RH((L) is the Lth layer embedding computed t,i by a GCN for the node corresponding to x , and Œª ‚àà R. MIP representation: Following Nair et al. (2020) and ear- t,i t,i lier works (e.g., Gasse et al. (2019)), we use a bipartite graph representation of a MIP for both Neural Diving and Neural 3.4. Training Neighborhood Selection. Variables form one set of nodes Given a training set D = {(M (j), x(j) , a(j) ))}N of in the graph and constraints form the other set. A variable train 1:Tj 1:Tj j=1 N MIPs and corresponding expert trajectories, the model appearing in a constraint is indicated by an edge between parameters Œ∏ are learned by minimizing the negative log the two corresponding nodes. Coefficients in A, b, and c are likelihood of the expert unassignment decisions: encoded as features of the corresponding edges, constraint nodes, and variable nodes, respectively. Additional features N Tj can be included (e.g., the linear relaxation solution as vari- L(Œ∏) = ‚àí (cid:88) (cid:88) log œÄ (a(j)|x(j), M (j)), (8) Œ∏ t t able node features) ‚Äì we use the feature set proposed in j=1 t=1
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs where M (j) is the jth training MIP instance, {x(j)}Tj into training, validation, and test sets, each consisting of t t=1 are the feasible assignments for the variables in M (j), and 70%, 15%, and 15% of total instances, respectively. We {a(j)}Tj are the corresponding unassignment decisions by train a separate model on each dataset, and evaluate it on t t=1 the expert in a trajectory of T steps. the corresponding test set‚Äôs MIPs. We also report in section j A.7 preliminary results for datasets from the NeurIPS‚Äô21 Machine Learning for Combinatorial Optimization competi- 3.5. Using the Trained Model tion. Given an input MIP, first Neural Diving is applied to it to compute the initial feasible assignment. An episode then 4.2. Metrics proceeds as described in section 3.1, with actions sampled from the trained model. We follow the evaluation protocol of Nair et al. (2020) and report two metrics, the primal gap and the fraction of test Sampling actions: Directly sampling unassignment deci- instances with the primal gap below a threshold, both as sions from the Bernoulli distributions output by the model a function of time. The primal gap Œ≥(t) at time t is the often results in sets of unassigned variables that are much normalized difference between the objective value achieved smaller than a desired neighborhood size. This is due to by an algorithm under evaluation at t and a precomputed highly unbalanced data produced by the expert (typically best known objective value f (x‚àó) (Berthold, 2006): most of the variables remain assigned), which causes the Ô£± model to predict a low probability of unassigning each vari- Ô£¥Ô£≤1, if f (x t) ¬∑ f (x‚àó) < 0 able. Instead we construct the unassigned variable set U Œ≥(t) = or no solution at time t, sequentially, starting with an empty set, and at each step Ô£¥Ô£≥ |f(xt)‚àíf(x‚àó)| , otherwise. adding to it an integer variable x with probability pro- max{|f(xt)|,|f(x‚àó)|} t,i (9) portional to (p Œ∏(a t,i = 1|x t, M ) + (cid:15)) œÑ1 ¬∑ I[x t,i ‚àà/ U ] with We average primal gaps over all test instances at a given (cid:15) > 0 to assign nonzero selection probability for all vari- time and refer to this as average primal gap, and plot it as a ables. Here, œÑ is a temperature parameter. This ensures function of running time. that U contains exactly the desired number of unassigned variables. Applications typically specify a threshold on the gap be- tween an assignment‚Äôs objective value and a lower bound, Adaptive neighborhood size: The number of variables below which the assignment is deemed close enough to op- unassigned at each step is chosen in an adaptive manner (Lee timal to stop the solve. The dataset-specific gap thresholds & Stuckey, 2021). The initial number is set as a fraction of are given in table 3. We apply these thresholds to the primal the number of integer variables in the input MIP. At a given gap to decide when a MIP is considered solved. We plot LNS step, if the sub-MIP solve outputs a provably optimal the fraction of solved test instances as a function of running assignment, the fraction for the next step is increased by a time, which we refer to as a survival curve. factor Œ± > 1. If the sub-MIP solve times out without finding a provably optimal assignment, the fraction for the next step As in Nair et al. (2020), we use calibrated time to measure is divided by Œ±. This allows LNS to adapt the neighborhood running time. It reduces the variance of time measurements size according to difficulty of the sub-MIP solves. on a shared compute cluster needed for a large-scale evalua- tion. See the Technical Appendix for details. 4. Evaluation Setup 4.3. Baselines 4.1. Datasets We compare our approach to three baselines: We evaluate our approach on five datasets: Neural Network Verification, Electric Grid Optimization, Production Pack- 1. Random Neighborhood Selection (RNS), where the ing, Production Planning, and MIPLIB. The first four are integer variables to unassign are selected uniformly homogeneous datasets in which the instances are from a randomly (referred to as the Random Destroy method single application, while MIPLIB (Gleixner et al., 2019) is a in Pisinger & Ropke (2010)), with an adaptive neigh- heterogeneous public benchmark with instances from many, bourhood size as explained in section 3.5. We use often unrelated, applications. They contain large-scale MIPs Neural Diving to initialize the feasible assignment. with thousands to millions of variables and constraints (fig- 2. Neural Diving, as described in Nair et al. (2020) and ure 4 in Technical Appendix). In particular, Production section 2.2, which achieved the previous best primal Packing and Planning datasets are obtained from a large gap results on the datasets in section 4.1. technology company‚Äôs production systems. See Technical Appendix section A.6 for details. All five datasets were split 3. SCIP 7.0.1 with its hyperparameters (‚Äúmetaparameters‚Äù for the presolve, cuts, and heuristics components) tuned
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs for each dataset separately using grid search to achieve 5.1. Survival Curves the best validation set average primal gap curves. SCIP Figure 2a shows the performance of ND + NNS using sur- is a complete solver that uses state-of-the-art primal vival curves. Compared to SCIP, our method‚Äôs performance heuristics. By tuning SCIP‚Äôs hyperparameters to mini- is considerably stronger on Production Packing, Electric mize average primal gap quickly, we aim to make SCIP Grid Optimization, and MIPLIB. On the first two, NNS behave more like a primal heuristic. solves almost all test instances to within the specified tar- get gap, while SCIP only solves about 10% on Production Packing, and about 80% on Electric Grid Optimization. For Neural Network Verification, while SCIP eventually also solves all the instances, the survival curve for ND + NNS achieves the same fraction of solved instances faster. Even Use of parallel computation: Neural Diving can naturally on MIPLIB, ND + NNS achieves a final solve fraction of exploit parallel computation for faster performance. This roughly 80%, compared to SCIP‚Äôs 60%. Similarly, compar- advantage carries over to Neural Neighborhood Selection as ing ND + NNS to Neural Diving shows the former achieving well when combined with Neural Diving by using parallel higher final solve fractions on all datasets except Production LNS runs initialized with multiple feasible assignments. Planning, where the two methods perform roughly the same. We evaluate Neural Diving and combinations of Neural ND + NNS outperforms ND + RNS on Electric Grid Op- Diving with Random or Neural Neighborhood Selection timization, Neural Network Verification, and MIPLIB, by in the parallel setting. All of these primal heuristics are either achieving a better final solve fraction or the same given the same amount of parallel compute resources in solve fraction in less time. Note that survival curves need experiments. SCIP is evaluated only in the single core not fully reflect the improvements in average primal gaps setting, as the main focus of this work is to evaluate the achieved by ND + NNS shown in figure 2b because im- benefit of easily parallelizable primal heuristics. proving the gap beyond the threshold does not improve the survival curve. 5. Results Figure 2b shows that on all five datasets, combining Neural 5.2. Ablation Study Diving and Neural Neighbourhood Selection (ND + NNS) We evaluate how the two main components of our approach significantly outperforms SCIP on the test instances, in some contribute to its performance. We consider four variants in cases substantially. On Production Packing, the final average which the initial assignment is given by either SCIP or Neu- primal gap is almost two orders of magnitude smaller, while ral Diving, and neighborhood search is done using either on Neural Network Verification and Production Planning it Random Neighborhood Selection or Neural Neighborhood is more than 10√ó smaller. On all datasets except MIPLIB, Selection. Figure 2c shows that, on all datasets except Neu- the advantage of ND + NNS over SCIP is substantial even ral Network Verification and MIPLIB, the average primal at smaller running times. gap becomes worse without Neural Diving. This is true ND + NNS outperforms Neural Diving alone on all datasets, regardless of whether we use NNS or RNS. For MIPLIB, with 10‚àí100√ó smaller gap on Production Packing, Electric ND + NNS finishes with the best average primal gap, but is Grid Optimization, and Neural Network Verification. Neural worse at intermediate running times. For Neural Network Diving quickly reduces the average primal gap early on, but Verification, SCIP turns out to be better than Neural Diving plateaus at larger running times. ND + NNS overcomes for providing the initial assignment. NNS is crucial, achiev- this limitation, reducing the average primal gap significantly ing roughly a 100√ó lower gap than SCIP + RNS. While the with more running time. On MIPLIB, Neural Diving shows relative contribution of Neural Diving and Neural Neigh- a better gap curve initially, before being overtaken by ND + borhood Selection to our approach‚Äôs performance depends NNS after about 103 seconds. on the dataset, it is clear across all datasets that learning is necessary to achieve the best performance. Combining Neural Diving with Random Neighbourbood Selection (ND + RNS) is a strong baseline on all datasets 5.3. Approximating the Expert except Electric Grid Optimization. It is only slightly worse than ND + NNS on Neural Network Verification and MI- Figure 3 shows the average primal gap as a function of the PLIB. But on Production Planning, Production Packing, and number of LNS steps for the expert policy, Neural Neighbor- Electric Grid Optimization, ND + NNS achieves a final av- hood Selection, and Random Neighborhood Selection, all erage primal gap that is smaller by roughly 2.0√ó, 13.9√ó, initialized with the same assignment computed using Neural and 37.8√ó, respectively. Note that ND + RNS is not better Diving. This allows comparing the quality of the policies in- than Neural Diving alone on all datasets, but ND + NNS is.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs 1.0 0.5 0.0 101 103 Calibrated time (seconds) smelborp fo noitcarF 10.0 =< pag lamirp egareva htiw Production Packing SCIP Neural Diving ND + NNS ND + RNS 1.0 0.5 0.0 101 103 Calibrated time (seconds) smelborp fo noitcarF 1000.0 =< pag lamirp egareva htiw Electric Grid Optimization 1.0 0.5 0.0 101 103 Calibrated time (seconds) smelborp fo noitcarF 0.0 =< pag lamirp egareva htiw Neural Network Verification 1.0 0.5 0.0 101 103 Calibrated time (seconds) smelborp fo noitcarF 30.0 =< pag lamirp egareva htiw Production Planning 1.0 0.5 0.0 101 103 Calibrated time (seconds) smelborp fo noitcarF 0.0 =< pag lamirp egareva htiw 10 1 10 2 10 3 101 103 Calibrated time (seconds) MIPLIB (a) Fraction of test set instances with pri- mal gap below a dataset-specific thresh- old, as a function of running time for five datasets. (Note: For Production Planning, several curves closely overlap.) pag lamirp egarevA Production Packing SCIP Neural Diving ND + NNS ND + RNS 10 1 10 3 101 103 Calibrated time (seconds) pag lamirp egarevA Electric Grid Optimization 10 1 10 3 101 103 Calibrated time (seconds) pag lamirp egarevA Neural Network Verification 10 1 10 2 10 3 101 103 Calibrated time (seconds) pag lamirp egarevA Production Planning 10 1 101 103 Calibrated time (seconds) pag lamirp egarevA 10 1 10 2 10 3 101 103 Calibrated time (seconds) MIPLIB (b) Test set average primal gap (see sec- tion 4.2, lower is better) as a function of running time for five datasets. pag lamirp egarevA Production Packing SCIP + RNS SCIP + NNS ND + NNS ND + RNS 10 1 10 3 101 103 Calibrated time (seconds) pag lamirp egarevA Electric Grid Optimization 10 2 10 4 101 103 Calibrated time (seconds) pag lamirp egarevA Neural Network Verification 10 1 10 2 10 3 101 103 Calibrated time (seconds) pag lamirp egarevA Production Planning 10 1 10 2 101 103 Calibrated time (seconds) pag lamirp egarevA MIPLIB (c) Test set average primal gap as a func- tion of running time for five datasets, for four combinations of two approaches to find an initial assignment (SCIP vs. Neu- ral Diving), and two approaches to se- lect a neighborhood (Neural vs. Random Neighborhood Selection). Figure 2: Experimental results. 10 2 10 4 0 2 4 6 8 10 LNS steps pag lamirp egarevA Neural Network Verification ND + NNS Expert Policy ND + RNS 10 2 10 4 0 2 4 6 8 10 LNS steps pag lamirp egarevA Figure 3: Comparison of expert policy Electric Grid Optimization used as the target for imitation learning ND + NNS to random (ND + RNS) and learned (ND ND + RNS Expert Policy + NNS) policies for selecting a search neighborhood at each step of large neigh- borhood search, with the initial assign- ment computed using Neural Diving for all three cases.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs dependently of their speed. For brevity we include only two binary variables in the MIP. Both works are similar in spirit representative datasets. The average primal gap is computed to Neural Diving, and shares its weakness that the model is on a subset of the validation set. On both datasets the expert applied in a one-shot manner at test time without the ability reduces the gap in the fewest steps, confirming its effective- to iteratively improve the assignment. ND + NNS addresses ness as an imitation target. NNS learns to approximate it this weakness. well enough to outperform RNS, which shows that imitation Learning has also been used to choose among an ensemble learning is a viable approach for the neighborhood selection of existing primal heuristics in a complete solver. Khalil task. Figure 3 also shows that there is more room for the et al. (2017b) learn a binary classifier to predict whether ap- learned policy to approximate the expert better. Improving plying a primal heuristic at a search tree node will improve the learned policy‚Äôs approximation while maintaining its the current best assignment. (Hendel, 2018) formulate a speed can lead to even better average primal gap. multi-armed bandit approach to learn a switching policy on- line. This is complementary to our approach of constructing 6. Discussion neural primal heuristics for a given application and can be combined by adding the neural heuristics to the ensemble. Neural Diving and ND + NNS have complementary strengths. As shown in section 5, Neural Diving is often Other Learning Approaches for MIPs: Several works quicker than SCIP at achieving low average primal gaps have used learning to improve tree search in a complete in short running times, but its average primal gap tends to solver (He et al., 2014; Khalil et al., 2016; Alvarez et al., plateau at higher running times. One reason is that a single 2017; Gasse et al., 2019; Zarpellon et al., 2020; Gupta et al., run of Neural Diving applies the learned model on the input 2020). They are most relevant when both an assignment and MIP only once at the beginning, which has a fixed time its optimality gap are required. Here we consider the setting cost. Any additional running time available is not used to where only the former is required. Learning has been used apply the learned model again; instead it is allocated to the to predict hyperparameters for MIP solvers, either for Algo- sub-MIP solve with SCIP. ND + NNS on the other hand can rithm Configuration (Anso¬¥tegui et al., 2009; Hutter et al., use the available time to repeatedly apply the NNS policy 2009; 2011; Anso¬¥tegui et al., 2015) or Algorithm Selection with more LNS steps. So higher running time limits can (Kotthoff, 2016; Hutter et al., 2014). Such approaches can exploit the learned model better. As a result, ND + NNS is be combined with ours. able to improve on Neural Diving at higher running time Learning for Combinatorial Optimization: Our work is limits. an instance of learning for combinatorial optimization prob- Limitations: 1) Our approach does not currently train mod- lems. Some of the earliest works in this area are (Zhang els in an end-to-end fashion to directly optimize a final & Dietterich, 1995; Moll et al., 1999; Boyan & Moore, performance metric such as the average primal gap. Ap- 1997). More recently, deep learning has been applied to the proaches based on supervised learning (RL) and of- Travelling Salesman Problem (Vinyals et al., 2015; Bello fline RL may address this limitation. 2) The conditionally- et al., 2016), Vehicle Routing (Kool et al., 2019; Nazari independent model (section 3.3) does not approximate the et al., 2018), Boolean Satisfiability (Selsam et al., 2019; expert policy perfectly (figure 3). While this architecture Amizadeh et al., 2019; Yolcu & Poczos, 2019), and gen- supports efficient inference, the restrictive conditional inde- eral graph-structured combinatorial optimization problems pendence assumption also limits its capacity. More power- (Khalil et al., 2017a; Li et al., 2018). A survey of the topic ful architectures, e.g., autoregressive models combined with is available by Bengio et al. (2018). GCNs, may give better performance by approximating the expert better. 8. Summary & Conclusions We have proposed a learning-based LNS approach for MIPs. 7. Related Work It trains a Neural Diving model to generate an initial as- Learning and MIP Primal Heuristics: Ding et al. (2020) signment, and a Neural Neighborhood Selection policy to trains a neural network to predict values for a subset of a select a search neighborhood at each LNS step. The result- MIP‚Äôs binary variables, which are then used to significantly ing neighborhood can be searched by solving with SCIP a reduce the search space by defining an additional constraint smaller sub-MIP derived from the input MIP. Our approach that any assignment be within a pre-specified Hamming matches or significantly outperforms all baselines with re- distance from the predicted values. Similarly, Xavier et al. spect to average primal gap and survival curves on five (2020) learns to warm start a MIP solver specifically for the datasets containing diverse, large-scale, real-world MIPs. It electric grid unit commitment problem using a k-Nearest addresses a key limitation of Neural Diving as a standalone Neighbor binary classifier to predict values for a subset of primal heuristic by improving the average primal gap at
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs larger running times. Even larger performance gains can Berthold, T. Rens - relaxation enforced neighborhood search. potentially be achieved with end-to-end training of both Technical Report 07-28, ZIB, Takustr. 7, 14195 Berlin, models, and using more powerful network architectures. 2007. Berthold, T., Heinz, S., Pfetsch, M., and Vigerske, S. Large References neighborhood search beyond mip. 2012. Abbasi-Yadkori, Y. and Neu, G. Online learning in mdps Boyan, J. A. and Moore, A. W. Using prediction to improve with side information. arXiv preprint arXiv:1406.6812, combinatorial optimization search. In In Proc. of 6th Int‚Äôl 2014. Workshop on Artificial Intelligence and Statistics, 1997. Achterberg, T., Koch, T., and Martin, A. Miplib 2003. Operations Research Letters, 34(4):361‚Äì372, 2006. Cheng, C.-H., Nu¬®hrenberg, G., and Ruess, H. Maximum resilience of artificial neural networks. In D‚ÄôSouza, D. Addanki, R., Nair, V., and Alizadeh, M. Neural large neigh- and Narayan Kumar, K. (eds.), Automated Technology for borhood search. In Learning Meets Combinatorial Algo- Verification and Analysis, pp. 251‚Äì268. Springer, 2017. rithms NeurIPS Workshop, 2020. Danna, E., Rothberg, E., and Pape, C. L. Exploring relax- Alvarez, A., Louveaux, Q., and Wehenkel, L. A machine ation induced neighborhoods to improve mip solutions. learning-based approximation of strong branching. IN- Mathematical Programming, 102(1):71‚Äì90, Jan 2005. FORMS Journal on Computing, 29:185‚Äì195, 01 2017. doi: 10.1287/ijoc.2016.0723. Ding, J., Zhang, C., Shen, L., Li, S., Wang, B., Xu, Y., and Song, L. Accelerating primal solution findings for mixed Amizadeh, S., Matusevych, S., and Weimer, M. Learning integer programs based on solution prediction. In AAAI, to solve circuit-SAT: An unsupervised differentiable ap- 2020. URL https://www.aaai.org/Papers/ proach. In ICLR, 2019. URL https://openreview. AAAI/2020GB/AAAI-DingJ.6745.pdf. net/forum?id=BJxgz2R9t7. Fischetti, M. and Lodi, A. Local branching. Mathemat- Anso¬¥tegui, C., Sellmann, M., and Tierney, K. A gender- ical Programming, 98:23‚Äì47, 09 2003. doi: 10.1007/ based genetic algorithm for the automatic configuration of s10107-003-0395-5. algorithms. In Gent, I. P. (ed.), Principles and Practice of Constraint Programming - CP 2009, pp. 142‚Äì157, Berlin, Fischetti, M., Glover, F., and Lodi, A. The feasibility pump. Heidelberg, 2009. Springer Berlin Heidelberg. Mathematical Programming, 104:91‚Äì104, 09 2005. doi: 10.1007/s10107-004-0570-3. Anso¬¥tegui, C., Malitsky, Y., Samulowitz, H., Sellmann, M., and Tierney, K. Model-based genetic algorithms for Gamrath, G., Anderson, D., Bestuzheva, K., Chen, W.- algorithm configuration. In Proceedings of the 24th Inter- K., Eifler, L., Gasse, M., Gemander, P., Gleixner, A., national Conference on Artificial Intelligence, IJCAI‚Äô15, Gottwald, L., Halbig, K., et al. The SCIP optimization pp. 733‚Äì739. AAAI Press, 2015. ISBN 9781577357384. suite 7.0. 2020. Battaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez- Gasse, M., Che¬¥telat, D., Ferroni, N., Charlin, L., and Lodi, Gonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A. Exact combinatorial optimization with graph convolu- A., Raposo, D., Santoro, A., Faulkner, R., et al. Rela- tional neural networks. In Advances in Neural Informa- tional inductive biases, deep learning, and graph networks. tion Processing Systems, pp. 15554‚Äì15566, 2019. arXiv preprint arXiv:1806.01261, 2018. Ghosh, S. Dins, a mip improvement heuristic. In Interna- Bello, I., Pham, H., Le, Q. V., Norouzi, M., and Bengio, tional Conference on Integer Programming and Combi- S. Neural combinatorial optimization with reinforcement natorial Optimization, pp. 310‚Äì323. Springer, 2007. learning. arXiv preprint arXiv:1611.09940, 2016. Gleixner, A., Hendel, G., Gamrath, G., Achterberg, T., Bengio, Y., Lodi, A., and Prouvost, A. Machine learning Bastubbe, M., Berthold, T., Christophel, P. M., Jarck, for combinatorial optimization: a methodological tour K., Koch, T., Linderoth, J., Lu¬®bbecke, M., Mittelmann, d‚Äôhorizon, 2018. H. D., Ozyurt, D., Ralphs, T. K., Salvagnin, D., and Berthold, T. Primal heuristics for mixed integer Shinano, Y. MIPLIB 2017: Data-Driven Compilation programs. Master‚Äôs thesis, 2006. URL https: of the 6th Mixed-Integer Programming Library. Tech- //opus4.kobv.de/opus4-zib/files/1029/ nical report, Optimization Online, July 2019. URL Berthold_Primal_Heuristics_For_Mixed_ http://www.optimization-online.org/ Integer_Programs.pdf. DB_FILE/2019/07/7285.html.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Goodfellow, I., Bengio, Y., and Courville, A. Deep Khalil, E., Le Bodic, P., Song, L., Nemhauser, G., and Dilk- Learning. MIT Press, 2016. http://www. ina, B. Learning to branch in mixed integer programming. deeplearningbook.org. In Schuurmans, D. and Wellman, M. (eds.), Proceedings of the Thirtieth AAAI Conference on Artificial Intelli- Gori, M., Monfardini, G., and Scarselli, F. A new model gence, pp. 724‚Äì731, 2016. URL http://www.aaai. for learning in graph domains. In Proceedings. 2005 org/Conferences/AAAI/aaai16.php. IEEE International Joint Conference on Neural Networks, 2005., volume 2, pp. 729‚Äì734. IEEE, 2005. Khalil, E., Dai, H., Zhang, Y., Dilkina, B., and Song, L. Learning combinatorial optimization algorithms over Gupta, P., Gasse, M., Khalil, E., Mudigonda, P., Lodi, A., graphs. In Advances in Neural Information Processing and Bengio, Y. Hybrid models for learning to branch. Systems, pp. 6348‚Äì6358, 2017a. Advances in neural information processing systems, 33, 2020. Khalil, E. B., Dilkina, B., Nemhauser, G. L., Ahmed, S., and Shao, Y. Learning to run heuristics in tree Hallak, A., Di Castro, D., and Mannor, S. Con- search. In Proceedings of the Twenty-Sixth Interna- textual markov decision processes. arXiv preprint tional Joint Conference on Artificial Intelligence, IJCAI- arXiv:1502.02259, 2015. 17, 2017b. doi: 10.24963/ijcai.2017/92. URL https: //doi.org/10.24963/ijcai.2017/92. Hamilton, W., Ying, Z., and Leskovec, J. Inductive repre- sentation learning on large graphs. In Advances in neural Kipf, T. N. and Welling, M. Semi-supervised classifica- information processing systems, pp. 1024‚Äì1034, 2017. tion with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016. He, H., Daume III, H., and Eisner, J. M. Learning to search Knueven, B., Ostrowski, J., and Watson, J.-P. On mixed in- in branch and bound algorithms. In Ghahramani, Z., teger programming formulations for the unit commitment Welling, M., Cortes, C., Lawrence, N. D., and Weinberger, K. Q. (eds.), Advances in Neural Information Process- problem. Optimization Online Repository, 11 2018. URL http://www.optimization-online.org/ ing Systems 27, pp. 3293‚Äì3301. Curran Associates, Inc., DB_FILE/2018/11/6930.pdf. 2014. Kool, W., van Hoof, H., and Welling, M. Attention, learn Hendel, G. Adaptive large neighborhood search for mixed to solve routing problems! In International Conference integer programming. Mathematical Programming Com- on Learning Representations, 2019. URL https:// putation, 2018. under review. openreview.net/forum?id=ByxBFsRqYm. Hojabri, H., Gendreau, M., Potvin, J.-Y., and Rousseau, Kotthoff, L. Algorithm Selection for Combinatorial Search L.-M. Large neighborhood search with constraint pro- Problems: A Survey, pp. 149‚Äì190. Springer International gramming for a vehicle routing problem with synchro- Publishing, Cham, 2016. nization constraints. Computers & Operations Research, 92, 2018. Lee, J. and Stuckey, P. Course on solving al- gorithms for discrete optimization, lecture Hottung, A. and Tierney, K. Neural large neighborhood 3.4.7 large neighbourhood search, 2021. URL search for the capacitated vehicle routing problem. arXiv https://www.coursera.org/lecture/ preprint arXiv:1911.09539, 2019. solving-algorithms-discrete-optimization/ 3-4-7-large-neighbourhood-search-brB2N. Hutter, F., Hoos, H. H., Leyton-Brown, K., and Stu¬®tzle, T. Paramils: An automatic algorithm configuration frame- Li, Z., Chen, Q., and Koltun, V. Combinatorial optimization work. J. Artif. Int. Res., 36(1):267‚Äì306, September 2009. with graph convolutional networks and guided tree search. ISSN 1076-9757. In Advances in Neural Information Processing Systems, pp. 539‚Äì548, 2018. Hutter, F., Hoos, H. H., and Leyton-Brown, K. Sequential model-based optimization for general algorithm configu- Lodi, A. Local Branching: A Tutorial. In MIC, August ration. In Proceedings of the 5th International Conference 2003. URL http://www.or.deis.unibo.it/ on Learning and Intelligent Optimization, LION‚Äô05, pp. research_pages/ORinstances/mic2003-lb. 507‚Äì523. Springer-Verlag, 2011. ISBN 9783642255656. pdf. Hutter, F., Xu, L., Hoos, H. H., and Leyton-Brown, K. Al- Moll, R., Barto, A. G., Perkins, T. J., and Sutton, R. S. Learn- gorithm runtime prediction: Methods & evaluation. Arti- ing instance-independent value functions to enhance local ficial Intelligence, 206:79 ‚Äì 111, 2014. ISSN 0004-3702. search. In Kearns, M. J., Solla, S. A., and Cohn, D. A.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs (eds.), Advances in Neural Information Processing Sys- salesman problem. Computers & Operations Research, tems 11, pp. 1017‚Äì1023. MIT Press, 1999. 87, 2017. Nair, V., Bartunov, S., Gimeno, F., von Glehn, I., Lichocki, Song, J., Lanka, R., Yue, Y., and Dilkina, B. A general P., Lobov, I., O‚ÄôDonoghue, B., Sonnerat, N., Tjandraat- large neighborhood search framework for solving integer madja, C., Wang, P., Addanki, R., Hapuarachchi, T., Keck, programs. arXiv preprint arXiv:2004.00422, 2020. T., Keeling, J., Kohli, P., Ktena, I., Li, Y., Vinyals, O., and Tjeng, V., Xiao, K. Y., and Tedrake, R. Evaluating robust- Zwols, Y. Solving mixed integer programs using neural ness of neural networks with mixed integer programming. networks, 2020. URL https://arxiv.org/abs/ In ICLR, 2019. URL https://openreview.net/ 2012.13349. forum?id=HyGIdiRqtm. Nazari, M., Oroojlooy, A., Snyder, L., and Takac, M. Vinyals, O., Fortunato, M., and Jaitly, N. Pointer supervised learning for solving the vehicle routing networks. In Cortes, C., Lawrence, N., Lee, D., problem. In Bengio, S., Wallach, H., Larochelle, Sugiyama, M., and Garnett, R. (eds.), Advances in Neural H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. Information Processing Systems, volume 28, pp. 2692‚Äì (eds.), Advances in Neural Information Processing 2700, 2015. URL https://proceedings. Systems, volume 31, pp. 9839‚Äì9849. Curran Asso- neurips.cc/paper/2015/file/ ciates, Inc., 2018. URL https://proceedings. 29921001f2f04bd3baee84a12e98098f-Paper. neurips.cc/paper/2018/file/ pdf. 9fb4651c05b2ed70fba5afe0b039a550-Paper. pdf. Xavier, A. S., Qiu, F., and Ahmed, S. Learning to solve large-scale security-constrained unit commitment prob- Perron, L., Shaw, P., and Furnon, V. Propaga- lems. INFORMS Journal on Computing, 2020. tion guided large neighborhood search. In Proceed- ings of the 10th International Conference on Princi- Yolcu, E. and Poczos, B. Learning local search heuristics ples and Practice of Constraint Programming, CP‚Äô04, for boolean satisfiability. In Wallach, H., Larochelle, pp. 468‚Äì481, Berlin, Heidelberg, 2004. Springer- H., Beygelzimer, A., dAlche¬¥ Buc, F., Fox, E., and Verlag. ISBN 9783540232414. doi: 10.1007/ Garnett, R. (eds.), Advances in Neural Information Pro- 978-3-540-30201-8 35. URL https://doi.org/ cessing Systems, volume 32. Curran Associates, 10.1007/978-3-540-30201-8_35. Inc., 2019. URL https://proceedings. neurips.cc/paper/2019/file/ Pisinger, D. and Ropke, S. Large neighborhood search. 12e59a33dea1bf0630f46edfe13d6ea2-Paper. In Gendreau, M. and Potvin, J.-Y. (eds.), Handbook of pdf. Metaheuristics, pp. 399‚Äì419, Boston, MA, 2010. Zarpellon, G., Jo, J., Lodi, A., and Bengio, Y. Parameter- Rothberg, E. An evolutionary algorithm for polishing mixed izing branch-and-bound search trees to learn branching integer programming solutions. INFORMS Journal on policies. arXiv preprint arXiv:2002.05120, 2020. Computing, 19(4):534‚Äì541, 2007. Zhang, W. and Dietterich, T. G. A supervised learning ap- Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and proach to job-shop scheduling. In Proceedings of the 14th Monfardini, G. The graph neural network model. IEEE International Joint Conference on Artificial Intelligence - Transactions on Neural Networks, 20(1):61‚Äì80, 2008. Volume 2, IJCAI‚Äô95, pp. 1114‚Äì1120, San Francisco, CA, USA, 1995. Morgan Kaufmann Publishers Inc. Selsam, D., Lamm, M., Bu¬®nz, B., Liang, P., de Moura, L., and Dill, D. L. Learning a SAT solver from single-bit supervision. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, 2019. URL https://openreview. net/forum?id=HJMC_iA5tm. Shaw, P. Using constraint programming and local search methods to solve vehicle routing problems. In Interna- tional conference on principles and practice of constraint programming, pp. 417‚Äì431. Springer, 1998. Smith, S. L. and Imeson, F. Glns: An effective large neigh- borhood search heuristic for the generalized traveling
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Dataset N r n lr m l Prod. Planning 7189 0.05 5 5 √ó 10‚àí4 500 Prod. Packing 2924 0.01 20 10‚àí3 500 MIPLIB 553 0.05 5 10‚àí3 500 NN Verification 2554 0.4 7 10‚àí3 100 Electric Grid Opt. 11444 0.4 10 10‚àí3 500 Table 1: Hyperparameters for data generation and training. Dataset r œÑ t (sec) 0 Prod. Planning 0.05 2.0 300 Prod. Packing 0.15 1.0 300 MIPLIB 0.25 2.0 300 NN Verification 0.4 1.5 60 Electric Grid Opt. 0.4 1.5 300 Table 2: Hyperparameters for evaluation. A. Technical Appendix A.1. Expert data generation To generate trajectories of the expert policy, we computed 10 steps of the local branching procedure as described in Section 3.2 for each instance in the training datasets. The Hamming distance Œ∑ of the local branching step was picked as a fixed fraction of the number of variables n, i.e. Œ∑ = r ¬∑ n. For each step computation we used SCIP with default parameters, with a time limit of 3 hours. The parameter r was chosen using the validation set, and the results are shown in table 1. A.2. Training procedure A model was trained for each dataset on a single NVIDIA V100 GPU for up to 400k steps, taking up to 48 hours. We used grid-search to tune hyperparameters (number of GCN layers n , learning rate (lr) and its decay, where we decayed the l learning rate by 0.9 every m steps) on the validation set. The resulting choices, as well as the training set size N are shown in the table below. Node embeddings were of size 64 for each model, and were computed using a 2-layer MLP with 64 hidden units per layer. A.3. Evaluation procedure During evaluation, we used the trained model as described in Section 3.5. For all datasets, we performed 50 steps of LNS, and the adaptation factor for the neighbourhood size was fixed to Œ± = 1.5 and sampling probability bias to (cid:15) = 10‚àí3. Hyperparameters (initial fraction of unassigned variables r , sampling temperature œÑ , and search time limit per step t) were 0 optimized using the validation set to the values in table 2. A.4. Input representation We use input features from (Gasse et al., 2019) along with the incumbent solution. The code for computing the features from (Gasse et al., 2019) is available at https://github.com/ds4dm/learn2branch. A.5. Calibrated time The total evaluation workload across all datasets and comparisons requires a large amount of compute. To meet the compute requirements, we use a shared, heterogeneous compute cluster. Accurate running time measurement on such a cluster is difficult because the tasks may be scheduled on machines with different hardware, and interference from other unrelated tasks on the same machine increases the variance of solve times. To improve F1-score, for each solve task, we periodically solve a small calibration MIP on a different thread from the solve task on the same machine. We use an estimate of the number of calibration MIP solves during the solve task on the same machine to measure time, which is significantly less sensitive to hardware heterogeneity and interference. This quantity is then converted into a calibrated time value using the
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Table 3: Optimality gap thresholds used for plotting survival curves for the datasets in our evaluation. Dataset Target Optimality Gap Neural Network Verification 0.05 Production Packing 0.01 Production Planning 0.03 Electric Grid Optimization 0.0001 MIPLIB 0 calibration MIP‚Äôs solve time on a reference machine. We define the speed of a machine on which a MIP solving job runs to be 1 Speed = . (10) Wall clock time to solve calibration MIP For each periodic measurement of calibrated time, we estimate the speed K times and use the average. K is set to be the number of samples needed to estimate mean speed with 95% confidence, with a minimum of 3 samples and a maximum of 30. The elapsed calibrated time ‚àÜt since the last measurement is calibrated ‚àÜt = Speed √ó ‚àÜt , (11) calibrated wallclock where ‚àÜt is the elapsed wallclock time since the last measurement. We use the MIP named vpm2 from MIPLIB2003 wallclock (Achterberg et al., 2006) as the calibration MIP. Note that the above definition of calibrated time does not have a time unit. Instead it is (in effect) a count of the calibrated MIP solves during the evaluation solve task. To give it a unit of seconds, one can choose a reference machine with respect to which evaluation solve times will be reported, accurately measure the calibration MIP‚Äôs solve time on it (without other tasks interfering), and multiply the calibrated time in equation 11 by the reference machine‚Äôs estimated calibration MIP solve time. The resulting quantity has a unit of seconds. It can be interpreted as the time the evaluation solve task would have taken if it ran on the reference machine. We select Intel Xeon 3.50GHz CPU with 32GB RAM as the reference machine. All the calibrated time results in the paper are expressed with respect to the reference machine in seconds. A.6. Dataset Details The target optimality gap used for each dataset in our evaluation as SCIP‚Äôs stopping criterion for a MIP solve is given in table 3. In the case of Neural Network Verification, the actual criterion used in the application is to stop when the objective value becomes negative, but this is not expressible as a constant target gap across all instances. In order to treat all datasets consistently, we have selected a gap of 0.05. Additional information about the applications that the datasets are extracted from is provided in table 4. Figure 4 shows the MIP sizes for the datasets used in our evaluation after presolving using SCIP 7.0.1. Note that, among the application-specific datasets, the Production Planning dataset is the most heterogeneous (along with MIPLIB) in terms of instance sizes. Table 5 summarizes the characteristics of those datasets before and after presolving with the SCIP 7.0.1 solver. The number of constraints and variables ranges different orders of magnitude across the datasets. It is worth noting that during presolving some instances might be deemed infeasible and, hence, dropped from the dataset. A.7. Results on NeurIPS‚Äô21 Competition Datasets Figure 5 presents preliminary results based on limited data augmentation for Neural Diving and Neural Neighborhood Search on the three datasets (Item Placement, Anonymous, Load Balancing) from the NeurIPS‚Äô21 competition on Machine Learning for Combinatorial Optimization. The Anonymous dataset is very small, with only 98 training cases. Not surprisingly, Neural Diving does not perform well on this dataset, and Neural Neighborhood Search does not provide any benefit over Random Neighborhood Search. Item Placement is a challenging dataset for SCIP. We have observed that even with several hours of running time for SCIP during data collection, SCIP still frequently reports very high optimality gaps (often > 100%). This affects both the quality of the data collected to train the ND and NNS models, as well as the test time
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs Table 4: Description of the five datasets we use in the paper. Please see (Nair et al., 2020) for more details. Name Description Neural Network Verification Verifying whether a neural network is robust to input perturbations can be posed as a MIP (Cheng et al., 2017; Tjeng et al., 2019). Each input on which to verify the network gives rise to a different MIP. In this dataset, a random forest is verified on each image in the MNIST dataset, giving rise to a corresponding dataset of MIPs. Production Packing A packing optimization problem solved in a large-scale production system. Production Planning A planning optimization problem solved in a large-scale production system. Electric Grid Optimization Electric grid operators optimize the choice of power generators to use at different times of the day to meet electricity demand by solving a MIP. This dataset is constructed for one of the largest grid operators in the US, PJM, using publicly available data about generators and demand, and the MIP formulation in (Knueven et al., 2018). MIPLIB Heterogeneous dataset containing ‚Äòhard‚Äô instances of MIPs across many different application areas that is used as a long-standing standard benchmark for MIP solvers (Gleixner et al., 2019). We use instances from both the 2010 and 2017 versions of MIPLIB. Table 5: Statistics (median in the first row and maximum in the second row) of constraints and variables (per type) for the different datasets before / after presolving using SCIP 7.0.1. The total number of nodes in the bipartite graph representation corresponds to the sum of the number of constraints and variables. Dataset Constraints Variables Binary Integer (non-binary) Continuous Neural Network Verification 6531/1407 7142/1629 171/170 0/0 6972/1455 (max) 7123/2089 7535/2231 364/364 0/0 7171/1921 Production Packing 36905/24495 10046/8919 3773/3437 0/0 6231/5421 (max) 47414/33071 11233/10161 4120/3771 0/0 7113/6390 Production Planning 11910/478 9884/404 833/119 462/119 8337/136 (max) 1722678/338508 1548582/335783 117485/22626 58782/23628 1374182/335783 Electric Grid Optimization 61851/45834 60720/58389 42240/42147 0/0 18768/16623 (max) 67086/50908 117792/115098 98112/98021 0/0 21456/20184 MIPLIB 7706/4388 11090/9629 4450/3816 0/0 218/96 (max) 19912111/888363 38868107/6338552 20677405/6338552 549428/0 38335410/700426 performance of ND and NNS by using SCIP to solve the sub-MIPs, which explains the poor performance of all approaches on this dataset. On Load Balancing, ND significantly outperforms SCIP, which shows that learning is useful for this dataset. However, NNS and RNS both fail to provide any improvements over ND. We believe further tuning the hyperparameters can improve the results on Load Balancing.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs 107 106 105 104 103 102 10 11 01 103 105 107 Number of variables stniartsnoc fo rebmuN 107 Production Planning Neural Net Verification 106 Production Packing Electric Grid Optimization 105 104 103 102 10 11 01 102 103 104 105 106 107 Number of variables stniartsnoc fo rebmuN MIPLIB Figure 4: Number of variables versus number of constraints after presolving using SCIP 7.0.1 for the application-specific datasets (left) and MIPLIB (right) used in our evaluation. Presolving significantly reduces the problem size compared to that of the raw input MIP.
Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs 100 10 1 101 103 Real time (seconds) pag lamirp egarevA Neurips21 Item Placement ND + NNS ND + RNS SCIP Neural Diving 100 10 1 10 2 101 103 Real time (seconds) pag lamirp egarevA Neurips21 Anonymous 10 1 10 3 101 103 Real time (seconds) pag lamirp egarevA 1.0 0.5 0.0 101 103 Real time (seconds) Neurips21 Load Balancing (a) Fraction of test set instances with primal gap below a dataset-specific threshold, as a function of running time for five datasets. (Note: For Production Planning, several curves closely overlap.) smelborp fo noitcarF 0.0 =< pag lamirp egareva htiw Neurips21 Item Placement ND + NNS ND + RNS SCIP Neural Diving 1.0 0.5 0.0 101 103 Real time (seconds) smelborp fo noitcarF 0.0 =< pag lamirp egareva htiw Neurips21 Anonymous 1.0 0.5 0.0 101 103 Real time (seconds) smelborp fo noitcarF 0.0 =< pag lamirp egareva htiw Neurips21 Load Balancing (b) Test set average primal gap (see section 4.2, lower is better) as a function of running time for five datasets. Figure 5: Results for the NeurIPS‚Äô21 Machine Learning for Combinatorial Optimization competition datasets.
