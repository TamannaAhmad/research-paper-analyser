Learning Neural Causal Models with Active Interventions Nino Scherrer 1 Olexa Bilaniuk 2 Yashas Annadani 1 Anirudh Goyal 2 Patrick Schwab 3 Bernhard Scho¨lkopf 4 Michael C. Mozer 5 Yoshua Bengio 2 Stefan Bauer 6 3 Nan Rosemary Ke 7 Abstract Fused Data Neural Causal Model N Structural Functional Obs. Data Int. Data Discovering causal structures from data is a chal- X0 lenging inference problem of fundamental impor- Pθ(X0|Xpa(0)) AIT X1 X2 tance in all areas of science. The appealing prop- (cid:34) (cid:35) Pθ(X1|Xpa(1)) erties of neural networks have recently led to a Neural 0 0 0. . .0 9 9 0 0 0. . .1 0 9 0 0 0. . .1 1 0 Pθ(X2|Xpa(2)) surge of interest in differentiable neural network- Causal Discovery based methods for learning causal structures from data. So far, differentiable causal discovery has Figure 1. AIT is an active intervention targeting technique which focused on static datasets of observational or fixed is applicable to all neural causal discovery frameworks of fused interventional origin. In this work, we introduce data. Based on the state of a learned neural causal model N up to an active intervention targeting (AIT) method a given timepoint, AIT selects the next informative intervention target for the causal discovery. which enables a quick identification of the un- derlying causal structure of the data-generating optimization problem with smoothly differentiable parame- process. Our method significantly reduces the re- ters. The set of neural parameters embodies a neural causal quired number of interactions compared with ran- model N that represents parameters of both structural and dom intervention targeting and is applicable for functional nature. Structural parameters express the belief both discrete and continuous optimization formu- about the graph structure through a distribution over graphs, lations of learning the underlying directed acyclic for example with a soft-adjacency matrix. On the other graph (DAG) from data. We examine the pro- hand, functional parameters characterize the conditional posed method across multiple frameworks in a probability distributions of the factorized joint distribution wide range of settings and demonstrate superior of a directed graphical model. Overall, such models offer performance on multiple benchmarks from simu- promising abilities with respect to generalization and fast lated to real-world data. adaptation (Bengio et al., 2019). Existing neural causal discovery methods focus on fixed datasets of either observational (Zheng et al., 2018; Yu et al., 1. Introduction 2019; Zheng et al., 2020; Bengio et al., 2019; Lorch et al., Inferring causal structure from data is a challenging but im- 2021; Annadani et al., 2021; Cundy et al., 2021) or fused portant task that lies at the heart of scientific reasoning and (observational and interventional) nature (Ke et al., 2019; accompanying progress (Lauritzen & Spiegelhalter, 1988; Brouillard et al., 2020; Lippe et al., 2021). While hav- Friedman et al., 2000; Robins et al., 2000; Sachs et al., 2005; ing access to interventional data can significantly improve Korb & Nicholson, 2010; Hill et al., 2016; Vandenbroucke the identification of the underlying causal structure, the et al., 2016; de Castro et al., 2019). Recently, there has improvement critically depends on the nature of the experi- been a surge in interest in differentiable causal structure ments and the number of interventional samples available learning with neural networks, also known as neural causal to the learner (Heckerman et al., 1995; Eberhardt et al., discovery (Ke et al., 2019; Scho¨lkopf et al., 2021; Xia et al., 2012). However, interventions tend to be costly and can 2021). These methods propose to recast the discrete search be technically impossible or even unethical (Peters et al., over the combinatorial solution space by treating it as an 2011). Hence it is desirable for an agent to conduct active interventions to recover the underlying causal structure in 1ETH Zurich 2Mila, Universite de Montre´al 3GlaxoSmithKline an adaptive and efficient manner. While a large body of 4Max Planck Institute for Intelligent Systems 5Google Research, work has addressed this need based on non-differentiable Brain Team 6KTH Stockholm 7DeepMind. Correspondence to: frameworks (He & Geng, 2008; Eberhardt, 2012; Hyttinen Nino Scherrer <nino.scherrer@gmail.com>. et al., 2013; Hauser & Bu¨hlmann, 2014; Shanmugam et al., Preprint. 2015; Kocaoglu et al., 2017b;a; Lindgren et al., 2018; Ghas- 2202 raM 5 ]LM.tats[ 2v92420.9012:viXra
Learning Neural Causal Models with Active Interventions Neural Causal Model N Unobserved Nature Structural Parameters γ Functional Parameters θ Obs. Data 0 1 2   MLP0(θ) ← pθ(X0|...) 0.0 0.1 0.0 σ(γ) = 0.9 0.0 0.5 MLP1(θ) ← pθ(X2|...) 0.0 0.5 0.0 Int. Data 0 1 2 MLP2(θ) ← pθ(X2|...) AIT G0,0: 0 1 2 S0,0 G1,0: 0 1 2 S1,0 D0 T Sw aDo m- A pP G lh inas ge G G0 1: : 0 0 1 1 2 2 A Inp tp el ry . G G0 1, ,1 1: : 0 0 1 1 2 2 SA an mce ps lt ir na gl S S0 1, ,1 1 CS oc mor pe . D1 arg Dkm kax G0,2: 0 1 2 S0,1 G1,2: 0 1 2 S1,1 D2 Figure 2. AIT decides where to intervene by computing a score for all possible intervention targets. Given a neural causal model N , AIT starts by sampling a set of hypothesis DAGs G from the structural parameters. It proceeds by applying an intervention I to all k G ∈ G. Based on the topological orderings of the post-interventional DAGs G and the functional parameters, it generates a set i i,k of post-interventional samples S . AIT proceeds by comparing statistics of the post-interventional sample distributions across the i,k hypothesis graphs to compute the discrepancy score D . k sami et al., 2018; 2019; Greenewald et al., 2019; Squires the proposed intervention-targeting method across multiple et al., 2020; Murphy, 2001; Tong & Koller, 2001; Masegosa differentiable causal discovery frameworks in a wide range & Moral, 2013; Cho et al., 2016; Ness et al., 2017; Agrawal of settings and demonstrate superior performance against et al., 2019; Zemplenyi & Miller, 2021; Gamella & Heinze- established competitive baselines on multiple benchmarks Deml, 2020), existing work in neural causal discovery has from simulated to real-world data. We provide empirical not yet focused on incorporating active interventions. insights on the distribution of selected intervention targets and its connection to the topological order of the variables In this work, we propose to augment neural causal discovery in the underlying data-generating distribution. methods with the ability to actively intervene. Therefore, we introduce Active Intervention Targeting (AIT), an adaptive 2. Preliminaries intervention design technique for the batch-wise acquisition of interventional samples. AIT can be easily incorporated Structural Causal Model (SCM). An SCM (Peters et al., into any neural causal discovery method which provides 2017) is defined over a set of random variables X 1, . . . , X M access to structural and functional parameters (see Figure 1). or just X for short, associated with a directed acyclic graph In AIT, we decide where to intervene by computing a score (DAG) G = (V, E) over variable nodes V = {1, . . . M }. for all possible intervention targets (over a single or multiple The random variables are connected by edges in E via func- variables). This score provides us with an estimate how in- tions f i and jointly independent noise variables U i through formative an intervention at that target would be with respect X i = f i(X pa(i), U i) where X pa(i) are X i’s parents in G, to the current evidence. For a set of hypothesis graphs sam- and directed edges in the graph represent direct causation. pled from the structural belief and a fixed intervention target, The conditionals P (X i|X pa(i)) define the conditional distri- we apply the intervention on all hypothesis graphs and gen- bution of X i given its parents. This characterization entails erate hypothetical samples through an ancestral sampling a factorization of the joint observational distribution: process based on the functional parameters. This allows us N (cid:89) P (X , . . . , X ) = P (X |X ) to compare statistics of the post-interventional sample dis- 1 N i pa(i) tributions across the hypothesis graphs (see Figure 2). We i=1 conjecture (and empirically show) that interventions that do Interventions. Interventions on X i change the conditional not agree across different hypothesis graphs contain more distribution of P (X i|X pa(i)) to a different distribution, information about the causal structure and hence enable hence affecting the outcome of X i. Interventions can be per- more efficient learning. fect (hard) or imperfect (soft). Hard interventions entirely remove the dependencies of a variable X on its parents i Summary of Empirical Results. We propose an interven- X , hence defining the conditional probability distribu- pa(i) tion design method (single and multi-target) which iden- tion of X by some P˜(X ) rather than P (X |X ). A tifies the underlying graph efficiently and can be used for i i i pa(i) more general form of intervention is the soft intervention, any differentiable causal discovery method. We examine where the intervention changes the effect of the parents of
Learning Neural Causal Models with Active Interventions X on itself by modifying the conditional distribution from i P (X |X ) to an alternative, denoted P˜ (X |X ). i i pa(i) i i pa(i) Neural Causal Discovery from Fused Data. Neural causal discovery from fused data aims at fitting fused data with a neural causal model N , an SCM with smoothly dif- ferentiable parameters of functional and structural nature, using a score-based objective. Structural parameters γ en- Figure 3. SDI learns a neural causal model from fused data using alternating phases of functional and structural fitting. code our belief in the underlying graph structure G, usually in form of a learned soft-adjacency matrix representing a dis- functional parameters. In addition, we present a scalable tribution over graphs. Functional parameters θ encode the two-stage DAG sampling technique for the efficient genera- conditional probability distributions (CPDs) P (X i|X pa(i) tion of hypothesis DAGs based on a soft-adjacency matrix, through neural networks that either learn parameters of a which is a common parametrization of the structural belief. distributional family (e.g. Gaussians or normalizing flows Finally, we show how our proposed method can be easily (Rezende & Mohamed, 2015)) or approximate the function plugged into recent differentiable causal discovery frame- itself. This is usually realized by a stack of MLPs, i.e. one works for guided exploration using interventional data. MLP per variable, to represent its conditional distribution. Assumptions. The proposed method does not have to as- We evaluate our proposed intervention design method un- sume causal sufficiency per se. However, it inherits the der two frameworks that can handle fused data. While we assumptions of the selected base framework, and this may focus on Structure Discovery from Interventions (SDI) (Ke include causal sufficiency depending on the base algorithm et al., 2019) in the main text, we provide futher context and of choice. In case the underlying framework can handle demonstrate AIT’s ability based on Differentiable Causal unobserved variables and offers a generative method for Discovery from Interventional Data (DCDI) (Brouillard interventional samples, then our method is also applicable et al., 2020) in §A.7. 3.1. A score for intervention targeting Structure Discovery from Interventions (SDI). The SDI approach reformulates the problem of causal discovery from Given a structural belief state γ with its corresponding func- discrete data as a discrete optimization problem using neural tional parameters θ, and a possible set of intervention targets networks. The framework proposes to learn the parameters I (single and multi-node intervention targets), we wish to of a neural causal model using a two-stage training proce- select the most informative intervention target(s) I k∗ ∈ I to dure with alternating phases of optimization (see Figure 3). identify as quickly as possible the underlying structure. In Under a fixed structural belief, the functional fitting stage AIT, we decide where to intervene by computing a score for fits the functional parameters θ (representing the observa- all possible intervention targets. This score provides us with tional CPDs) to observational data. In order to account for an estimate how informative an intervention at that target the stochastic nature of the structural belief, the method would be with respect to the current evidence. We claim that samples different hypothesized graphs in this stage and uses such informative interventions would yield relatively high them in a dropout-like fashion to mask out all variables ex- discrepancies between post-interventional samples drawn cept the direct causal parents according to the graph while under different hypothesis graphs, making it possible to fitting the functional parameters. This enforces the CPDs discriminate better among these candidate graphs and in- to be trained on different sets of parents and will converge dicating larger uncertainty about the intervention target’s to the set of true parents as the structure converges. On relation to its parents and/or children. the other hand, the structural fitting freezes the functional We thus construct an F-test-inspired score to seek the tar- parameters and evaluates the fit to interventional data of dif- get I exhibiting the highest discrepancies between post- k∗ ferent hypothesized graphs. The adaptation scores are then interventional sample distributions generated by likely graph used to update the belief in the graph structure by propagat- structures under fixed functional parameters θ. In order to ing them to update the structural parameters. The method compare sample distributions over different graphs, we dis- performs competitively to many other methods. However, tinguish between two sources of variation: variance between it processes all interventions in a random and independent graphs (VBG) and variance within graphs (VWG). While manner, a strategy that scales poorly to larger graphs. VBG characterizes the variance of sample means over mul- tiple graphs, VWG accounts for the sample variance when 3. Active Intervention Targeting (AIT) a specific graph is fixed. We mask the contribution of the We present a score-based, adaptive intervention design strat- intervened variables I k to VBG and VWG, and construct our egy, called AIT, which is applicable to any neural causal discrepancy score D as a ratio D = VBG . VWG discovery method which provides access to structural and This discrepancy score attains high values for intervention
Learning Neural Causal Models with Active Interventions targets of particular interest. While VBG itself indicates Algorithm 1 Active Intervention Targeting (AIT) for which intervention targets the model is unsettled about, Input: Functional Parameters θ, Structural Parameters γ, an extension to the proposed variance ratio enables more Interventional Target Space I control over the region of interest. Given a fixed set of Output: Intervention Target I k∗ graphs G and a fixed interventional sample size across all G ← Sample a set of hypothesis graphs from γ for each intervention target I in I do graphs, let us assume a scenario where multiple intervention k θ ← Perform intervention I on θ targets attain high VBG. Assessing VWG allows us to distin- fok r each graph G in G do k i guish between two extreme cases: (a) targets with sample G ← Apply intervention I to G i,k k i,k populations that exhibit large VWG (b) targets with sample S i,k ← Draw samples from G i,k using θ k populations that exhibit low VWG. While high VBG in (a) S i,k ← Set variables in I k to 0 end for might be induced by an insufficient sample size due to high (cid:0) (cid:1) (cid:0) (cid:1) v ina dri ia cn ac tee sin hit gh he din ist ce rr ev pen anti co yna bl ed twis etr ei nbu gt rio an phi sts ae nlf d, ( sb h) oc ul le dar bly e D k ← (cid:80) i (cid:80) j(cid:80) <(cid:0)i (cid:2)< Siµ ,ki, (cid:3)k j− −µ¯ µk i,k, (cid:1) ,µ (cid:0)i (cid:2),k S− i,kµ¯ (cid:3)k j−> µi,k(cid:1) > end for preferentially studied. Target Intervention I k∗ ← arg max k(D k) Computational Details. We begin by sampling a set of (e.g. partially undirected graphs or cyclic directed graphs) graphs G = {G }, i = 1, 2, 3, . . . from our structural param- i is an expensive multi-pass process. Here, we thus constrain eters γ. This G will remain fixed for all considered interven- our graph sampling space to DAGs. Since most differen- tions for the current experimental round. Then, we fix an tiable causal structure learning algorithms learn edge beliefs intervention target I and apply the corresponding interven- k in the form of a soft-adjacency matrix, we present a scal- tion to θ, resulting in partially altered functional parameters able, two-stage DAG sampling procedure which exploits θ where some conditionals have been temporarily changed k structural information of the soft-adjacency matrix beyond to be overriden by the intervention. Next, we draw inter- independent edge confidences (see Figure 4 for a visual il- ventional samples S from θ on the post-interventional i,k k lustration). More precisely, we start by sampling topological graphs G (i.e. intervention on target I applied to graph i,k k node orderings from an iterative refined score and construct G ). In the variance calculation, we set the variables of the i DAGs in the constrained space by independent Bernoulli intervention targets I to zero to mask off their contribu- k draws over possible edges. We can thus guarantee DAG- tion to the variance. Having collected all samples over the ness by construction and do not have to rely on expensive, considered graphs for the specific intervention target I , we k non-scalable techniques such as rejection sampling or Gibbs compute VBG and VWG as follows: k k sampling. The overall method is inspired by topological (cid:88) (cid:0) (cid:1) (cid:0) (cid:1) sorting algorithms of DAGs where we iteratively identify VBG = < µ − µ¯ , µ − µ¯ > k i,k k i,k k nodes with no incoming edges, remove them from the graph i (cid:88) (cid:88) (cid:0)(cid:2) (cid:3) (cid:1) (cid:0)(cid:2) (cid:3) (cid:1) and repeat until all nodes are processed. VWG = < S − µ , S − µ > k i,k j i,k i,k j i,k Soft-Adjacency. Given a learnable graph structure γ ∈ i j RN×N of a graph over N variables, the soft-adjacency ma- where µ¯ k is a vector of the same dimension as any sample trix is given as σ(γ) ∈ [0, 1]N×N such that σ(γ ) ∈ [0, 1] in S and denotes the overall sample-mean over all graphs in ij encodes the probabilistic belief in random variable X be- the interventional setting I . Further, µ denotes the mean j of samples drawn from grk aph G andi,k (cid:2) S (cid:3) is the j-th ing a direct cause of X i, where σ(x) = (1 + exp(−x))−1 i,k i,k j denotes the sigmoid function. For the ease of notation, sample of the i-th graph configuration under intervention I . k we define A = σ(γ) and A denotes the considered soft- Finally, we construct the discrepancy score D of I as: l k k adjacency σ(γ) at iteration l. Note that the shape of A l D ← VBG k . changes through the iterations. k VWG k Sample node orderings. For the iterative root sampling procedure, we start at iteration l = 0 with an initial soft- In contrast to the original definition of the F-Score, we adjacency A = A and apply the following routine for N can ignore the normalization constants due to equal group l iterations. We take the maximum over rows of A , result- size and degree-of-freedoms. An outline of the method is l ing in a vector of independent probabilities pchild, where provided in Algorithm 1. l pchild(i) denotes the maximal probability of variable X l i being a child of any other variable at the current belief state. 3.2. Two-Phase DAG sampling After taking the complement proot = 1−pchild, we arrive at l l Embedding AIT into recent differentiable causal discovery proot where proot(i) denotes the approximated probability l l frameworks requires a graph sampler that generates a set of of variable X being a root node in the current round. In i likely graph configurations under the current graph belief order to arrive at a normalized distribution to sample a root state. However, drawing samples from unconstrained graphs
Learning Neural Causal Models with Active Interventions Figure 4. Two-Stage DAG Sampling: Based on a soft-adjacency σ(γ), we sample a topological node ordering from an iterative refined score which is repeatedly computed until we have processed all nodes of the graph. We proceed by permuting σ(γ) according to the drawn node ordering and constrain the upper triangular part to ensure DAGness. Finally, we take independent Bernoulli draws of the unconstrained edge beliefs and arrive at a sampled DAG. node, we apply a temperature-scaled softmax: graphs are evaluated using interventional data to update the structural belief. See §2 for a compact description of the exp (cid:2)proot(i)/t(cid:3) p (i) = softmax(proot/t) = l base framework. l l i (cid:80) exp (cid:2)proot(j)/t(cid:3) j l 4. Experiments where t denotes the temperature. The introduction of We evaluate AIT on single-target interventions under two temperature-scaling allows to control the distribution over different settings: SDI (Ke et al., 2019) and DCDI (Brouil- nodes and account for the entropy of the structural be- lard et al., 2020). We investigate the impact of AIT under lief. We proceed by sampling a (root) node as r ∼ l both settings with respect to identifiability, sample complex- Categorical(p ) and delete all corresponding rows and l ity, and convergence behaviour compared to random target- columns from A and arrive at a shrinked soft-adjacency l ing where the next intervention target is chosen independent A ∈ [0, 1](N−l−1)×(N−l−1) over the remaining vari- l+1 of the current evidence. In a further line of experiments, we ables. We repeat the procedure until we have processed all analyze the targeting dynamics with respect to convergence nodes and have a resulting topological node ordering ≺ of behaviour and the distribution of target node selections. This [r , ..., r ]. 0 N−1 section will highlight our results on SDI while also pointing Sample DAGs based on node orderings. Given a node to key findings with respect to DCDI (structural discovery ordering ≺, we permute the soft-adjacency A accordingly and identifiability). However, the results and analysis of and constrain the upper triangular part by setting values to 0 DCDI results have been shifted to the appendix. to ensure DAGness by construction (as shown in Figure 4). Evaluation Setup. A huge variety of SCMs and their in- Finally, we sample a DAG by independent Bernoulli draws duced DAGs exist, each of which can stress causal struc- of the edge beliefs, as proposed in Ke et al. (2019). ture discovery algorithms in different ways. We perform a systematic evaluation over a selected set of synthetic and 3.3. Applicability to SDI non-synthetic SCMs (and datasets). We distinguish between Before integrating our method into the SDI framework, we synthetic structured graphs and random graphs, the latter must choose/design a graph sampler based on SDI’s graph generated from the Erdo˝s–Re´nyi (ER) model with varying belief characterization and define a sampling routine to gen- edge densities (see §A.3 for a detailed description of the erate interventional samples under a given state of the struc- setup). For conciseness, we only report results on 15-node tural and functional parameters. SDI offers a learnable graphs in this section for the noise-free synthetic setting for graph structure over N variables with γ ∈ RN×N such AIT on SDI and on 10-node graphs for the noisy setting for that σ(γ) ∈ [0, 1]N×N encodes the soft-adjacency matrix. AIT on SDI (discrete data). In addition, we point to key This formulation naturally suggests the application of the results on 10-node graphs for AIT on DCDI (continuous introduced two-phase DAG sampling to generate hypotheti- data) in the main text and provide further results and abla- cal DAGs under current beliefs. Under these acyclic graph tion studies in Appendix. We complete the setup with the configurations, one may then apply an intervention to SDI Sachs flow cytometry dataset (Sachs et al., 2005) and the functional parameters γ and sample data using ancestral Asia network (Lauritzen & Spiegelhalter, 1988) to evaluate sampling. SDI’s architectural choices allow a seamless inte- the proposed method on well-known real-world datasets for gration of AIT into the structural fitting stage of SDI, where causal structure discovery.
Learning Neural Causal Models with Active Interventions 75 50 25 0 0 10000 20000 30000 40000 50000 Steps DHS 75 50 25 0 0 10000 20000 30000 40000 50000 Steps (a) ER-1: DHS 75 50 25 0 0 10000 20000 30000 40000 50000 Steps (b) ER-2: DHS (c) ER-4: Figure 5. SDI with active intervention targeting (green) leads to superior performance over random intervention targeting (red) on random graphs of size 15. The performance gap becomes more significant with increasing edges density. The plot shows average performance in terms of SHD. Error bands were estimated using 10 random ER graphs per setting. Key Findings. (a) We report strong results for active- strengths and weaknesses of causal structure discovery targeted structure discovery on both discrete and continuous- methods, we further evaluate their capabilities on the real- valued datasets, outperforming random targeting in all ex- world flow cytometry dataset (also known as Sachs net- periments. (b) The proposed intervention targeting mecha- work)(Sachs et al., 2005) and the Asia network (Lauritzen nism significantly reduces sample complexity with strong & Spiegelhalter, 1988) from the BnLearn Repository. SDI benefits for graphs of increasing size and density. (c) The with active intervention targeting outperforms all measured distribution of target selections during graph exploration is baselines and achieves the same result as random targeting strongly connected to the topology of the underlying graph. in terms of SHD, but with reduced sample complexity. De- (d) Our method is capable of identifying informative tar- spite AIT deviating only by 6 undirected edges from the gets. (e) Undesirable interventions are drastically reduced. (concensus) ground truth structure of Sachs et al. (Sachs (f) When monitoring structured Hamming distance (SHD) et al., 2005), there is some concern about the correctness throughout the procedure, an “elbow” point appears approxi- of this graph and the different assumptions associated with mately when the Markov equivalence class (MEC) has been the dataset (Mooij et al., 2020; Zemplenyi & Miller, 2021). isolated. (g) AIT introduces desirable properties such as Therefore, perfect identification may not be achievable by improved recovery of erroneously converging edges. (h) any method in practice in the Sachs setting. AIT significantly improves robustness in noise-perturbed Effect of intervention targeting on sample complexity. environments. Aside from the significantly improved identification of un- Structure discovery: Synthetic datasets. We evaluate ac- derlying causal structures, our method allows for a substan- curacy in terms of Structural Hamming Distance (SHD) tial reduction in interventional sample complexity. After (Acid & de Campos, 2003) on a diverse set of synthetic non- reaching the “elbow” point in terms of structural Hamming linear datasets under both SDI and DCDI, adopting their distance, random intervention targeting requires a fairly respective evaluation setups. SDI with AIT outperforms all long time to converge to a solution within the MEC. In baselines and SDI with random intervention targeting over contrast, our proposed technique continues to select infor- all presented datasets (see results in Table 1). It enables mative intervention targets beyond the elbow point and more almost perfect identifiability on all structured graphs of size quickly converges to the correct graph within the MEC. The 15 except for the full15 graph, and significantly improves continued effectiveness of our method directly translates to structure discovery of random graphs with varying densi- increased sample-efficiency and convergence speed, and is ties. As the size or density of the underlying causal graphs apparent for all examined datasets (see Figure 5). increases, the benefit of the selection policy becomes more Distribution of intervention targets. The careful study of apparent (see Figure 5). We also examine the effectiveness the behaviour of the proposed method under our chosen of our proposed method for DCDI (Brouillard et al., 2020) synthetic graphs enable us to reason about the method’s on non-linear data from random graphs of size 10. Active underlying dynamics. Analysing the dynamics of interven- Intervention Targeting improves the identification in terms tion targeting reveals that the distribution of target node of sample complexity and structural identifiability compared selections is linked to the topology of the underlying graph. with random exploration (see §A.7 for results and analysis). More specifically, the number of selections of a given target We observe a clear impact of the targeting mechanisms on node strongly correlates with its out-degree and number of the order and frequency of selected interventional targets by descendants in the underlying ground-truth graph structure the learner. (see Figure 7). That our method prefers interventions on Structure discovery: flow cytometry and asia dataset. nodes with greater (downstream) impact on the overall sys- While the synthetic datasets systematically explore the tem can be most clearly observed in the distribution of target
Learning Neural Causal Models with Active Interventions Table 1. SHD (lower is better) on various datasets of synthetic or real-world origin. Structured graphs are sorted in ascending order according to their edge density. Notation: (∗) denotes average SHD over 10 different random graphs / O: Uses observational data / I: Uses interventional data / A: Active approach / ∂: Differentiable approach Method SYNTHETIC (N=15) REAL Classification Structured Graphs Random Graphs BnLearn O I A ∂ Chain Collider Tree Bidiag Jungle Full ER-1(∗) ER-2(∗) ER-4(∗) Sachs Asia GES (Chickering, 2002) (cid:88) 13 1 12 14 14 69 8.3 (±1.9) 17.6 (±4.6) 39.4 (±6.7) 19 4 NOTEARS (Zheng et al., 2018) (cid:88) (cid:88) 22 21 26 33 35 93 23.7 (±4.0) 35.8 (±5.2) 59.5 (±3.7) 22 14 DAG-GNN (Yu et al., 2019) (cid:88) (cid:88) 11 14 15 27 25 97 16.0 (±3.7) 30.6 (±3.4) 59.7 (±4.1) 19 10 GIES (Hauser & Bu¨hlmann, 2012) (cid:88) (cid:88) 13 6 10 17 23 60 10.9 (±4.2) 18.1 (±4.3) 39.3 (±5.6) 16 11 ICP (Peters et al., 2016) (cid:88) 14 14 14 27 26 105 16.2 (±3.6) 31.1 (±3.4) 60.1 (±3.9) 17 8 A-ICP (Gamella & Heinze-Deml, 2020) (cid:88) (cid:88) 14 14 14 27 26 105 16.2 (±3.6) 31.1 (±3.4) 60.1 (±3.9) 17 8 SDI (Random) (Ke et al., 2019) (cid:88) (cid:88) (cid:88) 0 0 2 3 7 24 1.4 (±1.6) 2.1 (±2.3) 7.2 (±2.7) 6 0 SDI (AIT) (cid:88) (cid:88) (cid:88) (cid:88) 0 0 0 0 0 7 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) 6 0 Figure 6. SDI: Dynamics and target distribution of AIT for a structured jungle graph of size 15. The graphs’ nodes are sorted in topological order, root node first. The graph is binary-tree-like with 4 levels. For the dense jungle15, the multi-level structure characteristic of the tree-like graph is readily apparent even before the elbow point. Nodes without children are very rarely chosen. selection on the example of the synthetic jungle graph in experiments that phase 1 tends to quickly discover the un- Figure 6. derlying skeleton (removing superfluous connections while keeping some edges undirected), until a belief state γ Selection of informative targets. Apart our strong results elbow is reached representing a MEC, or a class of graphs very in the discovery of the underlying causal graph, we demon- close to a MEC. Phase 2 is predominantly operating on the strate AIT’s general ability of detecting informative interven- partially directed skeleton and directs the remaining edges. tion targets. In a careful designed empirical, we preinitalize the structural parameters to the ground truth graph but keep Recovery of erroneously converging edges. Recovery of one or multiple edges within the skeleton undirected. Over incorrectly-converging edges critically depends on adapt- all evaluated settings, AIT rapidly detects the informative ing the order of interventions, which a random intervention intervention targets in order to direct the undirected edges. policy does not. In sharp contrast, intervention targeting Detailed results are shown in §A.6.7. significantly promotes early recovery from incorrect assign- ment of an edge. In contrast, the observed edge dynamics Reduction of undesirable interventions. An interven- and the corresponding graph belief states indicate that the tion destroys the original causal influence of other variables random policy can lock itself into unfavorable belief states on the intervened target variable I , so its samples cannot k from which recovery is extremely difficult, while AIT pro- be used to determine the causal parents of I in the undis- k vides an escape hatch throughout learning. turbed system. Therefore, if a variable without children is detected, interventions upon it should be avoided since Improved robustness in noise-perturbed environments. they effectively result in redundant observational samples Considering that noise significantly impairs the performance of the remaining variables that are of no benefit for causal of causal discovery, we examine the performance of active structure discovery. Active intervention targeting leads to intervention targeting in noise-perturbed environments with the desirable property that interventions on such variables respect to SHD and convergence speed and compare it with are drastically reduced (see Figure 6). random intervention targeting. We conduct experiments under different noise levels in the setting of binary data Identification of Markov equivalence class. Investigating generated from structured and random graphs of varying the evolution of the intervention target distribution over time density. A noise level η denotes the probability of flipping a reveals that the causal discovery seems to be divided into random variable and applying it to all measured variables two phases of exploration: Phase 1 lasts until the elbow of observational and interventional samples. Through all point in terms of SHD, and Phase 2 from the elbow point examined settings, we observe that active intervention tar- until convergence (see Figure 5). We observed over multiple geting significantly improves identifiability in contrast to
Learning Neural Causal Models with Active Interventions CHAIN15 0.15 0.37 -0.48 -0.37 -0.37 CHAIN15 0.56 0.96 -0.50 -0.96 -0.96 COLLIDER15 0.14 0.14 -0.14 -0.14 -0.14 COLLIDER15 0.80 0.80 -0.80 -0.80 -0.80 TREE15 0.09 0.53 -0.43 -0.43 -0.43 TREE15 0.91 0.84 -0.48 -0.96 -0.96 BIDIAG15 0.18 0.39 -0.52 -0.39 -0.39 BIDIAG15 0.80 0.93 -0.48 -0.93 -0.93 JUNGLE15 0.50 0.56 -0.66 -0.46 -0.46 JUNGLE15 0.98 0.89 -0.87 -0.96 -0.96 FULL15 0.39 0.39 -0.39 -0.39 -0.39 FULL15 0.93 0.93 -0.93 -0.93 -0.93 ER-1(*) 0.24 0.22 -0.17 -0.19 -0.20 ER-1(*) 0.85 0.82 -0.59 -0.66 -0.72 ER-2(*) 0.29 0.30 -0.23 -0.31 -0.33 ER-2(*) 0.96 0.89 -0.54 -0.70 -0.74 ER-4(*) 0.30 0.36 -0.31 -0.33 -0.35 ER-4(*) 0.96 0.90 -0.73 -0.83 -0.84 O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l- O r d e r O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l- O r d e r (a) Random Targeting (b) Active Intervention Targeting Figure 7. Correlation scores between the number of individual target selections and different topological properties of those targets. AIT shows strong correlations with the measured properties over all graphs, which indicates a controlled discovery of the underlying structure through preferential targeting of nodes with greater (downstream) impact on the overall system. (a) η = 0 (b) η = 0.01 (c) η = 0.02 (d) η = 0.05 Figure 8. Convergence Behaviour in terms of SHD for random ER-4 graphs over 10 variables under different noise levels η, where AIT (green) clearly outperforms Random Targeting (red) over all noise levels. The performance gap becomes of larger magnitude as the noise level increases. Error bands were estimated using 3 random ER graphs per setting. random targeting (see §A.6.6 for detailed results). Active in- underlying causal structures compared to random interven- tervention targeting perfectly identifies all structured graphs, tion targeting. Our results indicate that the guided selection except for the collider and full graph, up to a noise level of intervention targets leads to a more controlled discovery of η = 0.05, i.e. where every 20th variable is flipped. The with favourable properties with respect to the optimization. observed performance boost is even more noticeable in the The increased performance boost for larger graphs is in line convergence speed, as shown in Fig. 8 for ER-4 graphs with our expectation as random intervention targeting scales spanning over 10 variables. While the convergence-gap poorly to graphs of larger size. gets more significant with an increasing noise level, random While our method shows significant improvements with targeting does not converge to the ground-truth graphs for respect to sample efficiency and graph recovery over exist- a noise level higher than η = 0.02. In contrast, AIT still ing methods across multiple noise-free and noise-perturbed converges to the correct graph and shows even a conver- datasets, the number of interventions is not yet optimal gence tendency for η = 0.05. These findings support our (Atkinson & Fedorov, 1975; Eberhardt et al., 2012) and observation from different experiments that active interven- can potentially be reduced in future work. Further, in this tion targeting leads to a more controlled and robust graph work, the interventional samples were presented to the eval- discovery. Further experimental results in noise-perturbed uated frameworks according to a fixed learning schema (e.g. environments can be found in §A.6.6. fixed number of samples for evaluated interventions in graph scoring). It would be interesting to see if the information dis- 5. Conclusion covered by AIT could be used for a more adaptive learning Promising results have driven the recent surge of interest procedure to further improve sample efficiency. in differentiable methods for causal structure learning from observational and interventional data. In this work, we augment existing neural causal discovery methods with the ability to actively intervene and propose an active learning method to choose interventions. We show in a system- atic empirical study across multiple noise-free and noise- perturbed datasets that active intervention targeting not only improves sample efficiency but also the identification of the
Learning Neural Causal Models with Active Interventions References Friedman, N., Linial, M., Nachman, I., and Pe’er, D. Using bayesian networks to analyze expression data. Journal of Acid, S. and de Campos, L. M. Searching for bayesian computational biology, 7(3-4):601–620, 2000. network structures in the space of restricted acyclic par- tially directed graphs. Journal of Artificial Intelligence Gamella, J. L. and Heinze-Deml, C. Active invariant causal Research, 18:445–490, 2003. prediction: Experiment selection through stability. arXiv preprint arXiv:2006.05690, 2020. Agrawal, R., Squires, C., Yang, K., Shanmugam, K., and Uhler, C. Abcd-strategy: Budgeted experimental de- Ghassami, A., Salehkaleybar, S., Kiyavash, N., and Barein- sign for targeted causal structure discovery. In The 22nd boim, E. Budgeted experiment design for causal structure International Conference on Artificial Intelligence and learning. In International Conference on Machine Learn- Statistics, pp. 3400–3409. PMLR, 2019. ing, pp. 1724–1733. PMLR, 2018. Annadani, Y., Rothfuss, J., Lacoste, A., Scherrer, N., Goyal, Ghassami, A., Salehkaleybar, S., and Kiyavash, N. Inter- A., Bengio, Y., and Bauer, S. Variational causal networks: ventional experiment design for causal structure learning. Approximate bayesian inference over causal structures. arXiv preprint arXiv:1910.05651, 2019. arXiv preprint arXiv:2106.07635, 2021. Atkinson, A. C. and Fedorov, V. V. Optimal design: Ex- Greenewald, K., Katz, D., Shanmugam, K., Magliacane, S., periments for discriminating between several models. Kocaoglu, M., Adsera, E. B., and Bresler, G. Sample Biometrika, 62(2):289–303, 1975. efficient active learning of causal trees. 2019. Bengio, Y., Deleu, T., Rahaman, N., Ke, R., Lachapelle, Hauser, A. and Bu¨hlmann, P. Characterization and greedy S., Bilaniuk, O., Goyal, A., and Pal, C. A meta-transfer learning of interventional markov equivalence classes of objective for learning to disentangle causal mechanisms. directed acyclic graphs. The Journal of Machine Learning arXiv preprint arXiv:1901.10912, 2019. Research, 13(1):2409–2464, 2012. Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, Hauser, A. and Bu¨hlmann, P. Two optimal strategies for S., and Drouin, A. Differentiable causal discovery from active learning of causal models from interventional data. interventional data. In Larochelle, H., Ranzato, M., Had- International Journal of Approximate Reasoning, 55(4): sell, R., Balcan, M. F., and Lin, H. (eds.), Advances in 926–939, 2014. Neural Information Processing Systems, volume 33, pp. 21865–21877. Curran Associates, Inc., 2020. He, Y.-B. and Geng, Z. Active learning of causal networks with intervention experiments and optimal designs. Jour- Chickering, D. M. Optimal structure identification with nal of Machine Learning Research, 9(Nov):2523–2547, greedy search. Journal of machine learning research, 3 2008. (Nov):507–554, 2002. Heckerman, D., Geiger, D., and Chickering, D. M. Learning Cho, H., Berger, B., and Peng, J. Reconstructing causal biological networks through active learning. PloS one, 11 bayesian networks: The combination of knowledge and statistical data. Machine learning, 20(3):197–243, 1995. (3):e0150611, 2016. Cundy, C., Grover, A., and Ermon, S. Bcd nets: Scalable Heinze-Deml, C., Maathuis, M. H., and Meinshausen, N. variational approaches for bayesian causal discovery. Ad- Causal structure learning. Annual Review of Statistics vances in Neural Information Processing Systems, 34, and Its Application, 5:371–391, 2018. 2021. Hill, S. M., Heiser, L. M., Cokelaer, T., Unger, M., Nesser, de Castro, D. C., Walker, I., and Glocker, B. Causality N. K., Carlin, D. E., Zhang, Y., Sokolov, A., Paull, E. O., matters in medical imaging. 2019. Wong, C. K., et al. Inferring causal molecular networks: empirical assessment through a community-based effort. Eberhardt, F. Almost optimal intervention sets for causal Nature methods, 13(4):310–318, 2016. discovery. arXiv preprint arXiv:1206.3250, 2012. Eberhardt, F. and Scheines, R. Interventions and causal Hyttinen, A., Eberhardt, F., and Hoyer, P. O. Experiment se- inference. Philosophy of Science, 74(5):981–995, 2007. lection for causal discovery. Journal of Machine Learning Research, 14:3041–3071, 2013. Eberhardt, F., Glymour, C., and Scheines, R. On the number of experiments sufficient and in the worst case necessary Kalainathan, D. and Goudet, O. Causal discovery toolbox: to identify all causal relations among n variables. arXiv Uncover causal relationships in python. arXiv preprint preprint arXiv:1207.1389, 2012. arXiv:1903.02278, 2019.
Learning Neural Causal Models with Active Interventions Kalainathan, D., Goudet, O., Guyon, I., Lopez-Paz, D., and Murphy, K. P. Active learning of causal bayes net structure. Sebag, M. Sam: Structural agnostic model, causal dis- 2001. covery and penalized adversarial learning. arXiv preprint arXiv:1803.04929, 2018. Ness, R. O., Sachs, K., Mallick, P., and Vitek, O. A bayesian active learning experimental design for infer- Ke, N. R., Bilaniuk, O., Goyal, A., Bauer, S., Larochelle, ring signaling networks. In International Conference H., Scho¨lkopf, B., Mozer, M. C., Pal, C., and Bengio, Y. on Research in Computational Molecular Biology, pp. Learning neural causal models from unknown interven- 134–156. Springer, 2017. tions. arXiv preprint arXiv:1910.01075, 2019. Ng, I., Zhu, S., Chen, Z., and Fang, Z. A graph autoencoder Kocaoglu, M., Dimakis, A., and Vishwanath, S. Cost- approach to causal structure learning. arXiv preprint optimal learning of causal graphs. In International Con- arXiv:1911.07420, 2019. ference on Machine Learning, pp. 1875–1884. PMLR, 2017a. Peters, J., Mooij, J. M., Janzing, D., and Scho¨lkopf, B. Iden- tifiability of causal graphs using functional models. In Kocaoglu, M., Shanmugam, K., and Bareinboim, E. Ex- Proceedings of the 27th Annual Conference on Uncer- perimental design for learning causal graphs with latent tainty in Artificial Intelligence (UAI), pp. 589–598, 2011. variables. In Advances in Neural Information Processing Systems, pp. 7018–7028, 2017b. Peters, J., Bu¨hlmann, P., and Meinshausen, N. Causal in- ference by using invariant prediction: identification and Korb, K. B. and Nicholson, A. E. Bayesian artificial intelli- confidence intervals. Journal of the Royal Statistical Soci- gence. CRC press, 2010. ety: Series B (Statistical Methodology), 78(5):947–1012, 2016. Lachapelle, S., Brouillard, P., Deleu, T., and Lacoste-Julien, S. Gradient-based neural dag learning. In International Peters, J., Janzing, D., and Scho¨lkopf, B. Elements of causal Conference on Learning Representations, 2020. inference: foundations and learning algorithms. The MIT Press, 2017. Lauritzen, S. L. and Spiegelhalter, D. J. Local computa- tions with probabilities on graphical structures and their Plackett, R. L. The analysis of permutations. Journal of the application to expert systems. Journal of the Royal Statis- Royal Statistical Society: Series C (Applied Statistics), tical Society: Series B (Methodological), 50(2):157–194, 24(2):193–202, 1975. 1988. Rezende, D. J. and Mohamed, S. Variational inference with Lindgren, E. M., Kocaoglu, M., Dimakis, A. G., and Vish- normalizing flows. arXiv preprint arXiv:1505.05770, wanath, S. Experimental design for cost-aware learning 2015. of causal graphs. arXiv preprint arXiv:1810.11867, 2018. Robins, J. M., Hernan, M. A., and Brumback, B. Marginal Lippe, P., Cohen, T., and Gavves, E. Efficient neural causal structural models and causal inference in epidemiology, discovery without acyclicity constraints. arXiv preprint 2000. arXiv:2107.10483, 2021. Sachs, K., Perez, O., Pe’er, D., Lauffenburger, D. A., and Lorch, L., Rothfuss, J., Scho¨lkopf, B., and Krause, A. Dibs: Nolan, G. P. Causal protein-signaling networks derived Differentiable bayesian structure learning. arXiv preprint from multiparameter single-cell data. Science, 308(5721): arXiv:2105.11839, 2021. 523–529, 2005. Luce, R. D. Individual Choice Behavior: A Theoretical Scho¨lkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalch- analysis. Wiley, New York, NY, USA, 1959. brenner, N., Goyal, A., and Bengio, Y. Toward causal representation learning. Proceedings of the IEEE, 109(5): Masegosa, A. R. and Moral, S. An interactive approach for 612–634, 2021. bayesian network learning using domain/expert knowl- edge. International Journal of Approximate Reasoning, Shanmugam, K., Kocaoglu, M., Dimakis, A. G., and Vish- 54(8):1168–1181, 2013. wanath, S. Learning causal graphs with small interven- tions. In NIPS, pp. 3195–3203, 2015. Mooij, J. M., Magliacane, S., and Claassen, T. Joint causal inference from multiple contexts. Journal of Machine Spirtes, P., Glymour, C. N., Scheines, R., Heckerman, D., Learning Research, 21(99):1–108, 2020. URL http: Meek, C., Cooper, G., and Richardson, T. Causation, //jmlr.org/papers/v21/17-123.html. prediction, and search. MIT press, 2000.
Learning Neural Causal Models with Active Interventions Squires, C., Magliacane, S., Greenewald, K., Katz, D., Ko- caoglu, M., and Shanmugam, K. Active structure learning of causal dags via directed clique tree. arXiv preprint arXiv:2011.00641, 2020. Tong, S. and Koller, D. Active learning for structure in bayesian networks. In International joint conference on artificial intelligence, volume 17, pp. 863–869. Citeseer, 2001. Vandenbroucke, J. P., Broadbent, A., and Pearce, N. Causal- ity and causal inference in epidemiology: the need for a pluralistic approach. International journal of epidemiol- ogy, 45(6):1776–1786, 2016. Vowels, M. J., Camgoz, N. C., and Bowden, R. D’ya like dags? a survey on structure learning and causal discovery. arXiv preprint arXiv:2103.02582, 2021. Xia, K., Lee, K.-Z., Bengio, Y., and Bareinboim, E. The causal-neural connection: Expressiveness, learnability, and inference. 2021. Yu, Y., Chen, J., Gao, T., and Yu, M. Dag-gnn: Dag struc- ture learning with graph neural networks. In Interna- tional Conference on Machine Learning, pp. 7154–7163. PMLR, 2019. Zemplenyi, M. and Miller, J. W. Bayesian optimal ex- perimental design for inferring causal structure. arXiv preprint arXiv:2103.15229, 2021. Zheng, X., Aragam, B., Ravikumar, P. K., and Xing, E. P. DAGs with NO TEARS: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems, volume 31, pp. 9472–9483, 2018. Zheng, X., Dan, C., Aragam, B., Ravikumar, P., and Xing, E. Learning sparse nonparametric dags. In International Conference on Artificial Intelligence and Statistics, pp. 3414–3425. PMLR, 2020. Zhu, S., Ng, I., and Chen, Z. Causal discovery with re- inforcement learning. In International Conference on Learning Representations, 2020.
Learning Neural Causal Models with Active Interventions A. Appendix A.1. Related Work Causal induction can use either observational and (or) interventional data. With purely observational data, the causal graph is only identifiable up to a Markov equivalence class (MEC) (Spirtes et al., 2000), interventions are needed in order to identify the underlying causal graph (Eberhardt & Scheines, 2007). Our work focuses on causal induction from fused data (observational and interventional data). Causal Structure Learning. There exists several approaches for causal induction from interventional data: score-based, constraint-based, conditional independence test based and continuous optimization. We refer to (Heinze-Deml et al., 2018; Vowels et al., 2021) for recent overviews. While most algorithms perform heuristic, guided searches through the discrete space of DAGs, Zheng et al. (2018) reformulates it as a continuous optimization problem constrained to the zero level set of the adjacency matrix exponential. This important result has driven recent work in the field and showed promising results (Kalainathan et al., 2018; Yu et al., 2019; Ng et al., 2019; Lachapelle et al., 2020; Zheng et al., 2020; Zhu et al., 2020). Due to the limitations of purely observational data, Ke et al. (2019) and Brouillard et al. (2020) extend the continuous optimization framework to make use of interventional data. Lippe et al. (2021) scales in a concurrent work with ours the work of (Ke et al., 2019) to higher dimensions by splitting structural edge parameters in separate orientation and likelihood parameters and leveraging it in an adapted gradient formulation with lower variance. In contrast to (Brouillard et al., 2020; Ke et al., 2019) and our work, they require interventional data on every variable. Active Causal Structure Learning. Interventions are usually hard to perform and in some cases even impossible (Peters et al., 2017). Minimizing the number of interventions performed is desirable. Active causal structure learning addresses this problem, and a number of approaches have been proposed in the literature. These approaches can be divided into those that select intervention targets using graph-theoretic frameworks, and those using Bayesian methods and information gain. Graph-theoretic frameworks usually proceed from a pre-specified MEC or CPDAG (completed partially directed acyclic graph) and either investigate special graph substructures (He & Geng, 2008) such as cliques (Eberhardt, 2012; Squires et al., 2020), trees (Greenewald et al., 2019), or they prune and orient edges until a satisfactory solution is reached (Ghassami et al., 2018; 2019; Hyttinen et al., 2013), perhaps under a cost budget (Kocaoglu et al., 2017a; Lindgren et al., 2018). Their chief limitation is that an incorrect starting CPDAG can prevent reaching the correct graph structure even with an optimal choice of interventions. The other popular set of techniques involve sampling graphs from the posterior distribution in a Bayesian framework using MCMC and then selecting the interventions which maximize the information gain on discrete (Murphy, 2001; Tong & Koller, 2001) or Gaussian (Cho et al., 2016) variables. The drawbacks of these techniques is the difficulty of integrating them with non-Bayesian methods, except perhaps by bootstrapping (Agrawal et al., 2019). In contrast to existing work, our base frameworks do not start from a pre-specified MEC or CPDAG and existing graph- theoretical approaches are hence not directly applicable unless we pre-initalize them with a known skeleton. However, in the case we offer access to a predefined structure in the form of a MEC or CPDAG, a previously directed edge is likely to be inverted during the ongoing process which contradicts with the underlying assumptions of existing approaches. Further, we build atop non-Bayesian frameworks and are therefore limited in applying methods based on information gain which require access to a posterior distribution over graph structures. While bootstrapping would allow us to approximate the posterior distribution over graph structures in our non-Bayesian setting, it is not guaranteed to achieve full support over all graphs since the support is limited to graphs estimated in the bootstrap procedure (Agrawal et al., 2019). Furthermore, the computational burden of bootstrap would limit us in scaling to graphs of larger size.
Learning Neural Causal Models with Active Interventions A.2. Two-Stage DAG Sampling A.2.1. ALGORITHM OUTLINE We present an outline of the proposed two-stage DAG sampling procedure which exploits structural information of the soft-adjacency beyond independent edge confidences. The routine is based on a graph belief state γ where σ(γ) denotes a soft-adjacency characterization. We start by sampling topological node orderings from an iterative refined score and construct DAGs in the constrained space by independent Bernoulli draws over possible edges. We can therefore guarantee DAGness by construction. The temperature parameter t > 0 of the temperature-scaled softmax can be used to account for the entropy of the graph belief state. However, in the general setting we suggest to initialize the parameter to t = 0.1. Note that initializing t → 0 results in always picking the maximizing argument and t → ∞ results in an uniform distribution. Algorithm 2 Two-Stage DAG Sampling Input: Graph Belief State σ(γ) in the form of a soft-adjacency matrix Output: DAG Adjacency Matrix A Dag (cid:46) Phase 1: Sample Node Ordering ≺ 1: A 0 ← σ(γ) 2: nodes ← [0, ..., N − 1] 3: for k = 0 to N − 1 do 4: pc khild(i) ← max A k[i, :] 5: proot(i) ← 1 − pchild(i) k k 6: p k(i) ← (cid:80)ex ep x[ pp [r k po ro ot o( ti) (/ j)t] /t] j k 7: r k ← nodes[idx k] where idx k ∼ Categorical(p k) 8: Remove r k from nodes 9: A k+1 ← A k[nodes, nodes] 10: end for 11: ≺= [r 0, ..., r N−1] (cid:46) Phase 2: Sample DAG based on node ordering ≺ 12: A P erm ← Permute σ(γ) according to ≺ 13: A P erm ← Constrain upper diagonal part by setting values to 0 14: A Ber ← Bernoulli(A P erm) 15: A Dag ← Apply inverse permutation of ≺ to A Ber A.2.2. CONNECTION TO PLACKETT-LUCE DISTRIBUTION (LUCE, 1959; PLACKETT, 1975) Our proposed node ordering sampling routine can be regarded as an extension of the Placket-Luce distribution over node permutations. In contrast, we refine scores in an iterative fashion rather than setting them apriori as we account for previously drawn nodes to estimate the probability of a node being the root node in the current iteration.
Learning Neural Causal Models with Active Interventions A.3. Experimental Setup A huge variety of SCMs and their induced DAGs exist, each of which can stress causal structure discovery algorithms in different ways. In this work, We perform a systematic evaluation over a selected set of synthetic and non-synthetic SCMs. We distinguish between discrete (based on DSDI (Ke et al., 2019)) or continuous (based on DCDI (Brouillard et al., 2020)) valued random variables. Through all experiment, we limit us to 1000 samples per intervention. A.3.1. SYNTHETIC DATASETS Graph Structure. We adopt the structured graphs (see Fig. 9) proposed in the work of DSDI (Ke et al., 2019) as they adequately represent topological diversity of possible DAGs in a compact fashion. They can be split up in a set of graphs without cycles in the undirected skeletons, and one group with cycles. Extending the setup with random graphs with varying edge densities, generated from the Erdo˝s–Re´nyi (ER) model, allows us to assess the generalized performance of the proposed method from sparse to dense DAGs. Discrete Data Generation. We adopt the generative setup of DSDI (Ke et al., 2019) and model the SCMs using two-layer MLPs with Leaky ReLU activations between layers. For every variable X , a seperate MLP models the conditional i relationship P (X |X ). The MLP parameters are initialized orthogonally within the range of [−2.5, 2.5] and biases i pa(i) uniformly in the range of [−1.1, 1.1]. Continuous Data Generation. For the evaluation of the adapted DCDI framework, we adopt their generative setup as described in (Brouillard et al., 2020) and use the existing non-linear datasets. Graphs with acyclic skeletons: (a) Chain (b) Collider (c) Tree Graphs with cyclic skeletons: (d) Bidiag (e) Jungle (f) Full Figure 9. Visualization of Structured Graphs as proposed in Ke et al. (2019) - adapted illustration
Learning Neural Causal Models with Active Interventions A.3.2. REAL-WORLD DATASETS Besides the many synthetic graphs, we evaluate our method on real-world datasets provided by the BnLearn data repository. Namely on the Asia (Lauritzen & Spiegelhalter, 1988) and the Sachs (Sachs et al., 2005) datasets (see Fig. 10 for a visualization of their underlying ground-truth structure). Sachs (Sachs et al., 2005) represents a systems biology dataset which exhibits non-linearity, confounding and complex structure. (b) Sachs (a) Asia Figure 10. Ground-truth structure of the evaluated real-world datasets provided by the BnLearn data repository - Illustration from: https://www.bnlearn.com/bnrepository/discrete-small.html A.4. Availability of Used (Existing) Assets Base Frameworks. • DSDI (Ke et al., 2019): https://github.com/nke001/causal_learning_unknown_interventions • DCDI (Brouillard et al., 2020): https://github.com/slachapelle/dcdi Baseline Methods. • GES (Chickering, 2002) and GIES (Hauser & Bu¨hlmann, 2012): www.github.com/FenTechSolutions/ CausalDiscoveryToolbox (Kalainathan & Goudet, 2019) • ICP (Peters et al., 2016): https://github.com/juangamella/aicp • A-ICP (Gamella & Heinze-Deml, 2020): https://github.com/juangamella/aicp • NOTEARS (Zheng et al., 2018): https://github.com/xunzheng/notears • DAG-GNN (Yu et al., 2019): https://github.com/fishmoon1234/DAG-GNN Datasets. • BnLearn Data Repository: https://www.bnlearn.com/bnrepository/
Learning Neural Causal Models with Active Interventions A.5. Hyper-Parameters We used a similar set of hyperparameters for our AIT + DSDI and AIT + DCDI models as those used in the original paper (Ke et al., 2019; Brouillard et al., 2020). The specific hyperparamters we used are stated as follows. DSDI. Table 2. Hyperparameters for DSDI including the corresponding AIT parameters Number of iterations 1000 Batch size 256 Sparsity Regularizer 0.1 DAG Regularizer 0.5 Functional parameter training iterations 10000 Number of interventions per phase 2 25 Number of data batches for scoring 10 Number of graph configurations for scoring - Graph Size 5: 10 - Graph Size 10: 20 - Graph Size 15 40 AIT: - Number of graph configurations 100 - Number of interventional samples per graph & target 256 DCDI. Table 3. Hyperparameters for DCDI including the corresponding AIT parameters µ 10−8 0 γ 0 0 η 2 δ 0.9 Augmented Lagrangian Thresh 10−8 Learning rate 10−3 Nr. of hidden units 16 Nr. of hidden layers 2 AIT: - Number of graph configurations 100 - Number of interventional samples per graph & target 256
Learning Neural Causal Models with Active Interventions A.6. Discrete Setting: Additional Experiments / Results In this section, we show further results and visualizations of experiments on discrete data and single-target interventions in various settings (such as graphs of varying size, noise-free vs. noise-perturbed, limited intervention targets). All experiments are based on the framework DSDI. A.6.1. EVALUATION (SHD) ON GRAPHS OF VARYING SIZE AND DENSITY Table 4. SHD (lower is better) on various 5-variable synthetic datasets. Structured graphs are sorted in ascending order according to their edge density. (∗) denotes average SHD over 10 random graphs., †ER-2 graphs on 5 results in the full5 graph and ER-4 graphs on 5 node graphs are non-existing Structured Graphs Random Graphs Chain Collider Tree Bidiag Jungle Full ER-1(∗) ER-2(∗) ER-4(∗) GES (Chickering, 2002) 3 0 4 6 4 9 4.3 (±1.0) † † NOTEARS (Zheng et al., 2018) 5 3 6 5 7 9 6.1 (±1.7) † † DAG-GNN (Yu et al., 2019) 4 4 3 4 6 9 5.1 (±1.4) † † GIES (Hauser & Bu¨hlmann, 2012) 3 4 2 6 5 10 4.7 (±1.6) † † ICP (Peters et al., 2016) 4 4 4 7 6 10 5.4 (±1.4) † † A-ICP (Gamella & Heinze-Deml, 2020) 4 4 4 7 6 10 5.4 (±1.4) † † DSDI (Random) (Ke et al., 2019) 0 0 0 0 0 0 0.0 (±0.0) † † DSDI (AIT) 0 0 0 0 0 0 0.0 (±0.0) † † Table 5. SHD (lower is better) on various 10-variable synthetic datasets. Structured graphs are sorted in ascending order according to their edge density. (∗) denotes average SHD over 10 random graphs. Structured Graphs Random Graphs Chain Collider Tree Bidiag Jungle Full ER-1(∗) ER-2(∗) ER-4(∗) GES (Chickering, 2002) 9 2 6 8 10 35 7.0 (±1.6) 10.7 (±3.8) 26.7 (±2.9) NOTEARS (Zheng et al., 2018) 13 16 12 21 21 42 16.4 (±3.4) 22.9 (±2.9) 36.6 (±2.6) DAG-GNN (Yu et al., 2019) 8 7 6 15 13 38 10.3 (±2.8) 20.1 (±3.5) 38.4 (±1.9) GIES (Hauser & Bu¨hlmann, 2012) 12 6 13 16 9 20 12.2 (±5.1) 14.1 (±4.7) 26.1 (±4.4) ICP (Peters et al., 2016) 9 9 9 17 16 45 10.6 (±2.5) 20.7 (±3.3) 39.8 (±1.9) A-ICP (Gamella & Heinze-Deml, 2020) 9 9 9 17 16 45 10.6 (±2.5) 20.7 (±3.3) 39.8 (±1.9) DSDI (Random) (Ke et al., 2019) 0 0 0 0 0 0 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) DSDI (AIT) 0 0 0 0 0 0 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) Table 6. SHD (lower is better) on various 15-variable synthetic datasets. Structured graphs are sorted in ascending order according to their edge density. (∗) denotes average SHD over 10 random graphs. Structured Graphs Random Graphs Chain Collider Tree Bidiag Jungle Full ER-1(∗) ER-2(∗) ER-4(∗) GES (Chickering, 2002) 13 1 12 14 14 69 8.3 (±1.9) 17.6 (±4.6) 39.4 (±6.7) NOTEARS (Zheng et al., 2018) 22 21 26 33 35 93 23.7 (±4.0) 35.8 (±5.2) 59.5 (±3.7) DAG-GNN (Yu et al., 2019) 11 14 15 27 25 97 16.0 (±3.7) 30.6 (±3.4) 59.7 (±4.1) GIES (Hauser & Bu¨hlmann, 2012) 13 6 10 17 23 60 10.9 (±4.2) 18.1 (±4.3) 39.3 (±5.6) ICP (Peters et al., 2016) 14 14 14 27 26 105 16.2 (±3.6) 31.1 (±3.4) 60.1 (±3.9) A-ICP (Gamella & Heinze-Deml, 2020) 14 14 14 27 26 105 16.2 (±3.6) 31.1 (±3.4) 60.1 (±3.9) DSDI (Random) (Ke et al., 2019) 0 0 2 3 7 24 1.4 (±1.6) 2.1 (±2.3) 7.2 (±2.7) DSDI (AIT) 0 0 0 0 0 7 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0)
Learning Neural Causal Models with Active Interventions A.6.2. EVALUATION OF CONVERGENCE SPEED ON GRAPHS OF VARYING SIZE AND DENSITY While we have shown the effectiveness of AIT on random ER graphs of size 15 in §4, we observe similar effects on ER graphs of size 10 (see Figure 11). Overall, the results indicate a greater impact of our proposed targeting mechanisms on graphs of bigger size compared to random intervention targeting which poorly scales to graphs of larger size. 40 20 0 0 10000 20000 30000 Steps DHS 40 20 0 0 10000 20000 30000 Steps (a) ER-1: DHS 40 20 0 0 10000 20000 30000 Steps (b) ER-2: DHS (c) ER-4: Figure 11. DSDI with AIT (green) leads to superior performance over random intervention targeting (red) on random graphs of size 10 of varying edge densities. Error bands were estimated using 10 random ER graphs per setting. 75 50 25 0 0 10000 20000 30000 40000 50000 Steps DHS 75 50 25 0 0 10000 20000 30000 40000 50000 Steps (a) ER-1: DHS 75 50 25 0 0 10000 20000 30000 40000 50000 Steps (b) ER-2: DHS (c) ER-4: Figure 12. DSDI with AIT (green) leads to superior performance over random intervention targeting (red) on random graphs of size 15 of varying edge densities. Error bands were estimated using 10 random ER graphs per setting.
Learning Neural Causal Models with Active Interventions A.6.3. TARGET SELECTION ANALYSIS FOR GRAPHS OF VARYING SIZE AND DENSITY We evaluate the distribution of target node selections over multiple DAGs of varying size to investigate the behaviour of our proposed method. Over all performed experiments, our method prefers interventions on nodes with greater (downstream) impact on the overall system, i.e. nodes of higher topological rank in the underlying DAG. CHAIN5 0.83 0.34 0.31 -0.34 -0.34 CHAIN5 0.99 0.78 -0.30 -0.78 -0.78 BIDIAG5 0.65 0.34 0.06 -0.34 -0.34 BIDIAG5 0.99 0.90 -0.60 -0.90 -0.90 COLLIDER5 0.82 0.82 -0.82 -0.82 -0.82 COLLIDER5 1.00 1.00 -1.00 -1.00 -1.00 TREE5 0.10 -0.13 0.37 -0.02 -0.02 TREE5 1.00 0.90 -0.58 -0.79 -0.79 JUNGLE5 -0.09 -0.09 -0.07 -0.07 -0.07 JUNGLE5 0.98 0.98 -0.86 -0.86 -0.86 FULL5 0.32 0.32 -0.32 -0.32 -0.32 FULL5 0.99 0.99 -0.99 -0.99 -0.99 ER-1(*) 0.33 0.23 -0.24 -0.28 -0.22 ER-1(*) 0.99 0.94 -0.73 -0.74 -0.77 O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r CHAIN10 -0.27 0.37 -0.27 -0.37 -0.37 CHAIN10 0.76 0.95 -0.46 -0.95 -0.95 COLLIDER10 -0.28 -0.28 0.28 0.28 0.28 COLLIDER10 0.98 0.98 -0.98 -0.98 -0.98 TREE10 0.53 0.38 -0.28 -0.41 -0.41 TREE10 0.98 0.84 -0.49 -0.82 -0.82 BIDIAG10 -0.03 0.38 -0.24 -0.38 -0.38 BIDIAG10 0.92 0.90 -0.42 -0.90 -0.90 JUNGLE10 0.38 0.37 -0.48 -0.41 -0.41 JUNGLE10 0.99 0.94 -0.89 -0.91 -0.91 FULL10 0.37 0.37 -0.37 -0.37 -0.37 FULL10 0.96 0.96 -0.96 -0.96 -0.96 ER-1(*) 0.11 0.15 -0.27 -0.22 -0.21 ER-1(*) 0.95 0.92 -0.64 -0.72 -0.74 ER-2(*) 0.21 0.30 -0.24 -0.26 -0.27 ER-2(*) 0.98 0.93 -0.72 -0.82 -0.83 ER-4(*) 0.39 0.38 -0.42 -0.38 -0.37 ER-4(*) 0.96 0.95 -0.91 -0.94 -0.95 O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r CHAIN15 0.15 0.37 -0.48 -0.37 -0.37 CHAIN15 0.56 0.96 -0.50 -0.96 -0.96 COLLIDER15 0.14 0.14 -0.14 -0.14 -0.14 COLLIDER15 0.80 0.80 -0.80 -0.80 -0.80 TREE15 0.09 0.53 -0.43 -0.43 -0.43 TREE15 0.91 0.84 -0.48 -0.96 -0.96 BIDIAG15 0.18 0.39 -0.52 -0.39 -0.39 BIDIAG15 0.80 0.93 -0.48 -0.93 -0.93 JUNGLE15 0.50 0.56 -0.66 -0.46 -0.46 JUNGLE15 0.98 0.89 -0.87 -0.96 -0.96 FULL15 0.39 0.39 -0.39 -0.39 -0.39 FULL15 0.93 0.93 -0.93 -0.93 -0.93 ER-1(*) 0.24 0.22 -0.17 -0.19 -0.20 ER-1(*) 0.85 0.82 -0.59 -0.66 -0.72 ER-2(*) 0.29 0.30 -0.23 -0.31 -0.33 ER-2(*) 0.96 0.89 -0.54 -0.70 -0.74 ER-4(*) 0.30 0.36 -0.31 -0.33 -0.35 ER-4(*) 0.96 0.90 -0.73 -0.83 -0.84 O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r O u t - D e g r e e D e s c e n d a n t s I n - D e g r e e A n c e s t o r s T o p o l o g i c a l - O r d e r (a) Random Targeting (a) Active Intervention Targeting Figure 13. Correlation scores over graphs of varying size and density between the number of individual target selections and different topological properties of those targets. AIT shows strong correlations with the measured properties over all graphs, which indicates a controlled discovery of the underlying structure through preferential targeting of nodes with greater (downstream) impact on the overall system.
Learning Neural Causal Models with Active Interventions A.6.4. VISUALIZATION OF TARGET DISTRIBUTION ON STRUCTURED GRAPHS OF SIZE 5 (a) Random Targeting (b) Active Intervention Targeting Figure 14. Visualization of target selection on structured graphs of size 5 - bigger node size denotes more selection of the node. While Random Targeting acts as we expect and selects every node an uniform amount, AIT prefers targeting of nodes with greater (downstream) impact on the overall system, i.e. nodes of higher topological order.
Learning Neural Causal Models with Active Interventions A.6.5. EXTENDED ANALYSIS OF EDGE DYNAMICS We show all edge dynamics of all structured graphs over 15 variables and compare the dynamics of random targeting to active intervention targeting in a noise-free setting where we have access to all possible single-target interventions. (a) Graph: Chain (b) Graph: Tree (c) Graph: Collider Figure 15. Edge Dynamics of the examined structured graphs spanning over 15 variables - Part 1: The upper part shows the dynamics of random targeting and the lower of active intervention targeting.
Learning Neural Causal Models with Active Interventions (d) Graph: Bidiag (e) Graph: Jungle (f) Graph: Full Figure 16. Edge Dynamics of the examined structured graphs spanning over 15 variables - Part 2: The upper part shows the dynamics of random targeting and the lower of active intervention targeting.
Learning Neural Causal Models with Active Interventions A.6.6. IMPROVED ROBUSTNESS WITH DSDI+AIT IN NOISE PERTURBED ENVIRONMENTS While section §4 highlights our key findings in noise-perturbed systems, we examine the impact of AIT in noise perturbed environments more thoroughly in this section. Therefore, we systematically analyze experiments under different noise levels in the setting of binary data generated from random graphs of varying densities. A noise level η denotes the probability of flipping a random variable and apply it to all measured variables of observational and interventional samples. Evaluating convergence on various ER graphs of varying densities over 10 variables under different noise levels reveals that the impact of AIT becomes of larger magnitude as the density of the graph and the noise level increases. Table 7. Performance evaluation (SHD) under different noise level η for structured and random graphs (∗) denotes average SHD over 3 random graphs. Chain10 Collider10 Tree10 Bidiag10 Jungle10 Full10 ER-1(∗) ER-2(∗) ER-4(∗) Random 0 0 0 0 0 0 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) η = 0.0 AIT 0 0 0 0 0 0 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) Random 0 0 0 0 0 3 0.0 (±0.0) 0.0 (±0.0) 0.6 (±0.5) η = 0.01 AIT 0 0 0 0 0 0 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) Random 0 4 0 0 0 12 0.0 (±0.0) 0.0 (±0.0) 6.0 (±1.6) η = 0.02 AIT 0 0 0 0 0 3 0.0 (±0.0) 0.0 (±0.0) 0.0 (±0.0) Random 1 9 0 2 1 33 1.3 (±0.5) 8.0 (±2.2) 27.0 (±0.5) η = 0.05 AIT 0 7 0 0 0 23 0.0 (±0.0) 1.3 (±0.5) 18.7 (±1.2) Random 9 9 9 16 16 45 11.0 (±0.8) 20.7 (±0.5) 40.0 (±0.8) η = 0.1 AIT 7 9 6 16 15 44 10.3 (±0.5) 20.0 (±0.8) 39.3 (±1.2) (i) ER-1: (ii) ER-2: (iii) ER-4: (a) η = 0 (b) η = 0.01 (c) η = 0.02 (d) η = 0.05 Figure 17. Convergence behaviour in terms of SHD for random ER graphs of various densities over 10 variables under different noise levels η. Overall, Active Intervention Targeting (orange) clearly outperforms Random Targeting (blue) over all densities under all noise levels. The performance gap becomes of larger magnitude as density of the graph and the noise level increases. Error bands were estimated using 3 random ER graphs per setting.
Learning Neural Causal Models with Active Interventions A.6.7. IDENTIFICATION OF INFORMATIVE INTERVENTION TARGETS Our proposed method aims to select most informative intervention target(s) I ∈ I with respect to identifiability of the k∗ underlying structure. We conjecture that such targets yield relatively high discrepancy between samples drawn under different hypothesis graphs, indicating larger uncertainty about the target node’s relation to its parents and/or children. In order to evaluate our methods capability of detecting informative intervention targets, we perform multiple experiments on structured graph structures (chain5, tree5 and full5) where we preinitalize the structural belief to the ground-truth structure structure but keeping one edge between a pair of nodes (i,j) undirected, i.e. σ(γ ) = σ(γ ) = 0.5. Throughout i,j j,i the experiments, we vary the position of the undirected edge and analyze which nodes are targeted by our method. Over all evaluated settings, we can observe how AIT preferentially targets the pair of nodes corresponding to the undirected edge, with small preferences towards the source nodes of the correct directed edge (see in Figure 18 and Figure 19). This observation is in line with our conjecture that AIT preferentially targets nodes with larger uncertainty about the target node’s relation to its parents and/or children. Figure 18. AIT chooses informative intervention targets by preferentially identifying and targeting the pair of nodes corresponding to the undirected edge (nodes are marked red in the distribution of selected target nodes and edges is visualized red in the graph on the right). - First set of experiments based on the structured graphs chain5 and tree5.
Learning Neural Causal Models with Active Interventions Figure 19. AIT chooses informative intervention targets by preferentially identifying and targeting the pair of nodes corresponding to the undirected edge (nodes are marked red in the distribution of selected target nodes and edges is visualized red in the graph on the right). - Second set of experiments based on the structured graph full5. A.6.8. LIMITED INTERVENTION TARGETS While we allow access to all possible single-target interventions in all other experiments, real world settings are usually more restrictive. Specific interventions might be either technically impossible or even unethical, or the experiments might want to prevent interventions upon specific target nodes due to increased experiment costs. In order to test the capability of AIT, we limit the set of possible intervention targets in the following experiments and analyze the resulting behaviour based on DSDI. We examine speed of convergence and the effect on the target distribution under different scenarios on structured graphs using DSDI with AIT based on single-target interventions. Scenario 1: We perform experiments on a Chain5 graph where we restrict us on intervening upon a different node in five experiment and once allow access to all targets as a comparison. Throughout the experiments, we observe that blocking interventions on nodes of a higher topological level results in greater degradation of the convergence speed compared to blocked intervention on lower levels (see Figure 20). Furthermore, the distribution of selected targets indicates that our method preferentially chooses neighboring nodes of a blocked target node in the restricted setting.
Learning Neural Causal Models with Active Interventions Figure 20. Limited intervention targets on Chain5: The impact of the restricted target node (red circled node) is clearly observable in the convergence speed (left) and distribution of target selections (middle). The speed of convergence indicates a dependence on the topological characteristic of the restricted intervention target.
Learning Neural Causal Models with Active Interventions Scenario 2: We perform multiple experiments on a Tree5 graph where we restrict access to different subsets of nodes (e.g. root node, set of all sink nodes) for single-target interventions. Similar to the experiments on Chain5, we observe a clear impact of the available intervention targets on the convergence speed and identifiability of the underlying structure (see Figure 21). While preventing interventions on all sink nodes (node 2, 3 and 4) results in improved convergence towards the underlying structure, restricted access to the set of nodes which act as causes of other nodes (node 0 and 1) prevents us from identifying the correct underlying structure. Figure 21. Limited intervention targets on Tree5: The impact of the restricted target nodes (red circled nodes) is clearly observable in the convergence speed (left) and distribution of target selections (middle).
Learning Neural Causal Models with Active Interventions A.7. Continuous Setting: Technical Details and Results While the original framework of DCDI (Brouillard et al., 2020) proposes a joint-optimization over the observational and interventional sample space by selecting samples at random, we adapt their framework to the setting of active causal discovery where we acquire interventional sample in an adaptive manner. We hypothesize that a controlled selection of informative intervention targets allows a more rapid and controlled discovery of the underlying causal structure. A.7.1. DIFFERENTIABLE CAUSAL DISCOVERY FROM INTERVENTIONS (DCDI) The work of DCDI (Brouillard et al., 2020) addresses causal discovery from continuous data as a continuous-constrained optimization problem using neural networks to model parameters of Gaussian distributions or normalizing flows (Rezende & Mohamed, 2015) which represent conditional distributions. Unlike SDI’s iterative training of the structural and functional parameters, DCDI optimizes the causal adjacency matrix and functional parameters jointly over the fused data space. But like SDI, DCDI uses random and independent interventions. A.7.2. INTEGRATION OF AIT INTO DCDI Instead of demanding the full interventional target space during the complete optimization as in the original approach, we split the optimization procedure into different episodes, where AIT is used to estimate a target space I of size K for each episode. This is done by computing the discrepancy scores over all possible intervention targets and selecting the K highest scoring targets. During an episode, we continue by performing L gradient steps using the fixed target space I and reevaluate it afterwards for the next episode. We visualize the adaption in the following high-level outline of the individual methodologies. Algorithm 4 DCDI + AIT Algorithm 3 DCDI 1: for episode e = 0 until convergence do 1: I ← Full target space of size K = N ⇒ 2: I ← Estimate target space of size K using AIT 2: Run DCDI on I until convergence 3: Run L gradient steps of DCDI on I 4: end for A.7.3. EVALUATION We evaluate the effectiveness of AIT in the base framework of DCDI in the setting of non-linear, continuous data generated from random graphs over N = 10 variables and show the potential of our proposed method. Structural Identification / Convergence: Despite their joint optimization formulation is not apriori designed for the setting of experimental design, an AIT guided version shows superior/competitive performance in terms of structural identification and sample complexity over the original formulation (see Figure 22). Distribution of Intervention Targets: As in DSDI, we observe strong correlation of the number of target selections with the measured topological properties of the specific nodes. This indicates a controlled discovery of the underlying causal structure through preferential targeting of nodes with greater (downstream) impact on the overall system. In addition, interventions on variables without children are drastically reduced (see also §4 for equivalent observations in DSDI). Effect of Target Space Size K: While the original formulation assumes K = N for the complete optimization procedure (i.e. L = 1) and relies on random samples out of the full target space, our adapted AIT-guided version of DCDI constrains the target space to a subset of targets for each episode. An ablation study on the size of the target space shows that for all choices of K ∈ {2, 4, 6, 8}, our approach outperforms the original formulation in terms of sample complexity while achieving same or better performance in terms of SHD.
Learning Neural Causal Models with Active Interventions Figure 22. While DCDI Vanilla assumes access to the full interventional target space through the complete optimization, the AIT guided DCDI approach reevaluates its interventional target space of size K = 6 every L = 1000 gradient steps. Among the above evaluated graphs (ground-truth on the left), DCDI+AIT demonstrates a more rapid identification of the underlying causal structure while achieving same or better performance in terms of SHD. The distribution of selected single-node intervention targets reveals again its connection to the topological properties of the corresponding nodes. (a) K = 2 (b) K = 4 (d) K = 6 (d) K = 8 Figure 23. All evaluated target space sizes K ∈ {2, 4, 6, 8} show that DCDI+AIT (orange) outperforms DCDI (blue) in terms of sample complexity while achieving similar performance. Error bands were estimated using 10 random ER graphs per setting.
