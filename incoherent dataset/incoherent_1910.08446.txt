9102 tcO 81 ]GL.sc[ 1v64480.0191:viXra Autonomous exploration for navigating in non-stationary CMPs Pratik Gajane1 Ronald Ortner1 Peter Auer1 Csaba Szepesv´ari2,3 1Montanuniversit¨at Leoben 2DeepMind 3University of Alberta Abstract with a controlled Markov process (CMP) equipped with finitely many actions and at most countably many states, the state is observable after every transition and We consider a setting in which the objective a reset action is available which brings the agent back is to learn to navigate in a controlled Markov to some initial state. The problem then is to mini- process (CMP) where transition probabili- mize the number of steps where the agent lacks the ties may abruptly change. For this setting, ability to reliably navigate to safely reachable states. we propose a performance measure called ex- Since the number of states is unbounded, the agent ploration steps which counts the time steps is given as input a ‘radius’ L such that it needs to at which the learner lacks sufficient knowl- consider all states that are reachable within L steps edge to navigate its environment efficiently. (precise definitions will be given in the next section). We devise a learning meta-algorithm, MNM, Lim and Auer (2012) gave an algorithm that with high and prove an upper bound on the exploration probability finishes the discovery task in time that is steps in terms of the number of changes. proportional to the product of L3 and the number of states to be discovered. Unlike this previous work, we consider the case when the transition probabilities can 1 Introduction (abruptly) change. This setting is important as agents with a long “lifespan” may expect their environment The ability to quickly learn to reliably control one’s to change: “moving parts” can suddenly break down environment is core to the functionality of intelligent as commonly experienced in robotics or more generally agents. Throughout the last decades, much work has in automation (Kober et al., 2013), or the environment been devoted to the design and testing of various al- may change abruptly due to the appearance or disap- gorithms targeted at this task, under various names pearance of other agents, or objects, such as in rescue such as learning using intrinsic motivation, intrinsic robots in urban search and rescue missions in unknown reward, curiosity-driven learning, etc. A necessar- environments (Niroui et al., 2019). The time when the ily incomplete sample of prior works in the area in- changes happen or the nature of the changes are un- cludes that of Schmidhuber (1991); Singh et al. (2004); known. In this new setting, we consider the problem Oudeyer and Kaplan (2007); Oudeyer et al. (2007); of minimizing the number of exploration steps: A time Baranes and Oudeyer (2009); Schmidhuber (2010); step is considered an exploration step if at that time Singh et al. (2010); Lopes et al. (2012); Gottlieb et al. step the agent lacks sufficient knowledge to navigate (2013); Stadie et al. (2015); Houthooft et al. (2016); its current environment efficiently. The challenge is Achiam and Sastry (2017); Ostrovski et al. (2017); of course that the agent may not be aware of when Pathak et al. (2017); Haber et al. (2018); Burda et al. it does not have this sufficient knowledge. For this (2019); Azar et al. (2019); Hazan et al. (2019). Con- problem we give a meta-algorithm MNM which can ceptually, the problem can be thought of as learning utilize any base algorithm designed for the stationary to reliably navigate an unknown environment. In this version of the problem and which keeps the number article we focus on this problem, and in particular, of exploration steps below O(F 2) when the number of on learning to navigate in the face of a changing, or environment changes is F . nonstationary environment. Following Lim and Auer Changing environments have been studied in the con- (2012), we consider the case when an agent interacts text of supervised learning (see e.g., Even-dar et al. (2005); Abbasi et al. (2013); Ortner et al. (2019)). However, our problem setting fundamentally differs from these works as the external rewards are absent and as such our performance metric is incomparable.
2 Problem Setting The set → of states reachable in L steps in respect SL to some partial order is given by → := ≺, where SL ≺ SL We consider a discrete-time controlled Markov process the union is over all possible partial orders. S – a Markov decision process where rewards are absent. Back to the nonstationary case, we define the number We assume a countable, possibly infinite state space of changes in the environment as and a finite action space with A = actions. S A |A| Upon executing an action a in state s at ∈ A ∈ S F := # 1 t s′, s, a : P (s′ s, a) = P (s′ s, a) . time t, the environment transitions into the next state { ≤ |∃ t−1 | 6 t | } s′ selected randomly according to the unknown ∈ S For notational convenience, we assume that transition probabilities P (s′ s, a). In order to define t | P 0(s′ s, a) = P 1(s′ s, a) for some (s, a), thereby the performance measure for our problem, we make | 6 | always counting the first change at t = 1. Therefore, use of some of the preliminary definitions and an as- sumption from Lim and Auer (2012) (Definitions 1–3 #changes = # different CMP settings = F. (1) and Assumption 1 below), which assume P = P . We t assume that the reader is familiar with terminology of Next we define the performance measure we propose Markov decision processes which we borrow from. for the considered problem setting. The learning agent is expected to solve the au- Definition 4 (Exploration steps). The (L, ǫ)- tonomous exploration problem in which the goal is to exploration steps are the complement of the set , find a policy for each reachable state from a starting T where contains the time steps t at which the learner state s , which we will fix for the rest of the article, T 0 and hence will be omitted from any notation. has identified a set → for the CMP with tran- Definition 1 (Navigation time). For any (possibly s• ition probabilities P ,K an⊇ dSL t non-stationary) policy π, let τ (s π) be the expected | number of steps before reaching s for the first time has a policy π s for every state s with τ (s π s) • ∈ K | ≤ when executing policy π starting from s 0. (1 + ǫ)L for the transition probabilities P t. The learner will be given a number L > 0 and we may The set of exploration steps contains the time steps naively demand that it finds all states reachable in at for which the learner doesn’t have sufficient knowledge most L steps: about the current CMP structure in order to navigate Definition 2 (S ). We let S denote S := s : to reachable states from s 0 efficiently. The learner’s L L L min τ (s π) L . { ∈ S aim is to be able to efficiently navigate the current π | ≤ } CMP structure at most of the time steps, or equiva- Since the state space might be infinite, a learner could lently to minimize the number of exploration steps. wander off in some direction or get stuck without being Introduction to UcbExplore(Lim and Auer, able to return to the starting state. To exclude this 2012): Before we illustrate our meta-algorithm using possibility, we make the following assumption. UcbExplore as a subroutine, let us take a look at a Assumption 1. In every state, there is a designated few relevant details. UcbExplore alternates between RESET action available, that will transition back to two phases: state discovery and policy evaluation. In the starting state s with probability 1. a state discovery phase, new candidate states are dis- 0 covered as potential members of the set of reachable We define a policy π on ′ to be a policy states. In a policy evaluation phase, the optimistic S ⊂ S with π(s) = RESET for any s ′. As it turns out, policy π for reaching one of the candidate states s 6∈ S s in general it is too much to ask for learners to discover is evaluated to verify if π is acceptable1. A policy s all the states in S L. Rather, following Lim and Auer evaluation phase for any π s lasts for a certain num- (2012) we require learners to discover only the so-called ber of episodes. Each episode begins at s and ends 0 incrementally discoverable states, →. either when π successfully reaches s or 1 + 1 L SL s ǫ Definition 3 ( →). Let be some partial order on . steps have been executed. If s is not reached in a suit- The set ≺ of S stL ates reac≺ hable in L steps with respeS ct ably high number of episodes, policy evalu(cid:6) a(cid:0) tion fo(cid:1) r π(cid:7) s SL is said to have failed. A successful policy evaluation to , is defined inductively as follows: ≺ means a new reachable state and an acceptable policy have been discovered. A failed policy evaluation leads s ≺, • 0 ∈ SL to selecting another candidate state-optimistic policy • if there is a policy π on {s′ ∈ SL≺ : s′ ≺ s } with 1 By an acceptable policy, we mean any policy π s such τ (s |π) ≤ L, then s ∈ SL≺. that τ (s|π s) ≤ (1 + ǫ)L.
pair for evaluating while a successful policy evalua- the algorithm terminates the checking phase and pro- tion leads to a state discovery phase which in turn ceeds to the next round. In the checking phase, our adds more candidate states for the subsequent pol- algorithm employs the subroutine as a black-box using icy evaluation phases. We restate the main result of the upper bound on the exploration steps required by Lim and Auer (2012) below for reference. the subroutine for a stationary CMP problem. Using Theorem 1, the upper bound is O( SAL3 log SAL 3 ) Theorem 1. [Lim and Auer (2012, Theorem 8)] ǫ3 ǫδ When algorithm UcbExplore is run on a stationary for UcbExplore. We use this bound to compute W r (cid:0) (cid:1) CMP problem (i.e t, P ( s, a) = P ( s, a)) with inputs for each round r with suitable constants C 1 and C 2. t ∀ ·| ·| s 0, , L 1, ε > 0, and δ, then with probability 1 δ At any time step t, our algorithm’s knowledge of the A ≥ − current CMP structure is represented by and r−1 K • it discovers a set of states K ⊇ SL→; Pr−1 where r the current round at t. When the cur- rent round r = 1, the algorithm is yet to learn the for each s , it outputs a policy π with τ (s π ) present CMP structure. s s • ∈ K | ≤ (1 + ε)L, and MNM can use any algorithm designed for autonomous exploration in a stationary CMP as a subroutine if it it terminates after O SAL3 log SAL 3 exploration • ε3 εδ is provided with two values: steps, where S = |K| ≤(cid:16) |S(→ 1+ε)(cid:0)L|. (cid:1) (cid:17) the length of the quantum i.e. the number of con- • 3 Meta-algorithm for autonomous tiguous time steps for which a copy of the subroutine exploration in non-stationary CMPs (i.e., a stream) must be active, and a high-probability upper bound on the number of • Our meta-algorithm (Meta-algorithm for autonomous exploration steps required by the subroutine for a sta- exploration in non-stationary CMPs or MNM) can use tionary CMP problem. any algorithm designed for autonomous exploration in a stationary CMP as a subroutine. In Figure 1, for These two values are used in Step 2(c) and the com- the sake of specificity, we describe the algorithm using putation of W at the beginning of a checking phase UcbExplore (Lim and Auer, 2012) as a subroutine. r respectively (see Figure 1). Using another algorithm The algorithm proceeds in rounds and each round con- as a subroutine instead of UcbExplore would only sists of two phases: a building phase and a checking cause these two changes with the rest of MNM re- phase. In a building phase, we build a hypothesis maining the same. which consists of a set of states and an acceptable pol- Our main result, stated in Theorem 2, upper-bounds icy for each of them. In a checking phase, we check the number of exploration steps required by MNM if the hypothesis we built in this round is still valid. using UcbExplore as a subroutine. The correspond- In any building phase, the algorithm initiates several ing result while using other subroutines could simply copies of the subroutine at different time steps (see be obtained by replacing the upper bound of explo- 2(a) in Figure 1) and switches back and forth between ration steps required by UcbExplore for a station- them (see 2(b) in Figure 1). Once it switches to a copy ary CMP with the analogous bound of the subroutine of the subroutine, that subroutine is said to be to ac- being used. tive and it remains so until the next switch. To simu- Theorem 2. With probability 1 δ, the total number late this approach, our algorithm proceeds in streams. of exploration steps for MNM − using UcbExplore A stream is a single run of the subroutine acting only as a subroutine and with inputs s , L 1, ǫ, δ, C = according to the previous time-steps for which the said 0 1 ≥ 216 (15)2 + 61 and C = 225 is upper bounded by stream is active. At any time step, only a single stream 2 · is active. Once a stream is active it stays so for a quan- 2 tum of time steps, the length of which is determined F C S AL3 4π2C F 2S AL 3 1 f 2 f log dynamically (see 2(c) in Figure 1). When a hypoth-  ǫ3 3ǫδ  esis is formed in the building phase of a round r, it f X=1 (cid:18) (cid:19) i as lgs ot ro ir te hd min mK ovr esan od n P tor t( hse ee ch2( ed ck) inin g F pi hg au sr ee . 1) and the  + F max 2C 1S f AL3 log 4π2C 2F 2S f AL 6 , f∈{1,...,F } " ǫ3 (cid:18) 3ǫδ (cid:19) # In the checking phase, recent history is examined, by employing a sliding window, to detect various kinds where S f = |S (→ 1+ǫ)L(f ) | is the number of incremen- of changes in the hypothesis. When the hypothesis tally discoverable states reachable in (1+ǫ)L time steps th is found to be valid no more on account of a change, in the f CMP setting, and #changes = F .
Input: A confidence parameter δ, an error thresh- = π , s respectively. Terminate r s r P { ∀ ∈ K } old ε > 0, L 1, , s , constants C > 0 and all the other initiated streams in STM and 0 1 ≥ A C > 0. proceed to the checking phase. Otherwise pro- 2 For round r = 1, 2, . . . ceed to next q . r Building phase: Checking phase: 1: Initialize STM = {}. The set STM is used to store Compute W = C1|Kr|AL3 log C2|Kr|AL 3 and the set of initiated streams in round r so far. r ǫ3 ǫδ′ r 2: S qutr ae na tum m h oa f n tid mli en sg t: epL s e wt itq hr inin td hic ea bte uilt dh ie ngcu pr hr aen set α r = 2(log(l |o Kg r( |1 A/δ Lr′ /) ǫδ r′ ))3 . Le(cid:16) t a single ch(cid:17) eck-run consistqof the following two parts in the given or- of round r. The length of q r is determined dynam- der: a new copy of UcbExplore(δ′ , ǫ, L, , s ) ically (explained below in step (c)) but is at most r A 0 running for up to W time steps and a policy eval- 1 + 1 ǫ L . Let δ r′ = 4π3 2δ r2 . uation phase of Ucbr Explore for each of the poli- For q = 1, 2, . . . (cid:6)(cid:0) r (cid:1) (cid:7) cies in r. If the first part of any check-run doesn’t (a) Initiation rule: For any integer p 1, if terminaP te within W time steps, then terminate it ≥ r q r = (p 1)2+1, then add p to STM. Initiate a manually and proceed to the second part of the new cop− y of UcbExplore(δ′ , ǫ, L, , s ) and 3 associate it with stream p. Tr his copA y of0 Ucb- check-run. Set n r = log |K ǫr δ|A ′ L . Execute n r r Explore acts only according to the samples check-runs. Then: (cid:16) (cid:17) taken from the time steps at which p is active. 3: Let b be the number of times UcbExplore has failed to terminate within W time steps in the (b) Allocation rules: r first part during the last n check-runs. If (i) If q = 1, activate the only initiated r r stream in STM so far i.e. p qr = 1. b > α + δ′ , (2) (ii) Otherwise if all the initiated streams in n r r r STM have been active for equal number of quantums previously, then p = least then stop the checking phase, set r r + 1 and qr ← recently active stream in STM. start a new round, otherwise proceed to next step. (iii) Otherwise p qr = the stream in STM which 4: F tio mr ee sv per oy lics ytat ee vas lui an tiK onr, fale it ls b f′ s orbe π the num ib ner tho ef has been active for the least number of s r ∈ P second part of the last n check-runs. If quantums previously. r (c) If the copy of UcbExplore associated with b′ t rh ue n s ittr fe oa rm p 1qr +is 1 in La ts it mat ee sd teis pc so .ve Ory thp erh was ise e, ns r > α r + δ r′ , (3) ǫ the copy of UcbExplore associated with the delete s and π from and respectively. Pro- s r r (cid:6)(cid:0) (cid:1) (cid:7) K P stream p is in a policy evaluation phase, and ceed to next step. qr then run it for an episode which is always 5: Let s be any state which was absent in r, but has K 1 + 1 L time steps of policy evalua- appeared in the output of at least one of the first ≤ tion of Ucǫ bExplore i.e., (cid:0) part of the last n r check-runs. For every such state (cid:6)(cid:0) (cid:1) (cid:7) (cid:1) s, let v be the number of times s was present in s 1 + 1 L , if p in state discovery the output of the first part of the last n check- q = ǫ qr r | r | ( |(cid:6)e (cid:0)pisode (cid:1)of (cid:7)policy evaluation of p qr | runs. If δ′ 1 v s > α , (4) r − − n r (d) Check for the end of building phase: If (cid:18) r (cid:19) during q , the copy of UcbExplore associ- add s and the last found policy for s to and r r r K P ated with the active stream terminates and respectively. Proceed to next step. provides a set of reachable states and accept- 6: Execute a check-run one more time. Go back to able policies for them, record them in and step 3 of checking phase. r K Figure 1: Meta-algorithm for autonomous exploration in non-stationary CMPs or MNM
Note that a change in this context affects the set of 4 Analysis and Proof of Theorem 2 reachable states in (1 + ǫ)L steps from s and/or the 0 acceptable policies for reaching them. The reason, as First, we bound the number of exploration steps in a noted by Lim and Auer (2012), is that the learner can- single building phase. Then we prove that the number not distinguish between the states reachable in L steps of rounds is upper-bounded by #changes F . Combin- and those reachable in (1 + ǫ)L steps (given a reason- ing these two, we prove an upper bound on the number able amount of exploration). of exploration steps for all the building phases. Next, we prove an upper bound on the number of exploration Motivating factors for the construction of our steps in a checking phase caused by a single change. algorithm Summing this over all the changes in all the rounds gives us an upper bound on the number of exploration Before an algorithm forms a hypothesis i.e., it de- steps in all the checking phases. Finally, we add the re- • termines a set of reachable states and acceptable poli- spective upper bounds for all the building phases and cies, it might not be possible to detect a change. Con- all the checking phases to arrive at the bound given by sider an algorithm still in the process of building a Theorem 2. hypothesis. During this process, the algorithm must proceed and inspect states in some order. Suppose 4.1 Bounding the exploration steps in a that it has found acceptable polices for some reachable single building phase states. When it finds a new reachable state, there are First, we state a couple of preliminary lemmas about two plausible scenarios: a) this state was not reachable stream handling to be used later. when the algorithm was in the process of inspecting other states earlier i.e., there was a change, or b) this Lemma 1. At the end of any quantum q in a building state was reachable when the algorithm was in the pro- phase, the number of initiated streams is equal to √q . ⌈ ⌉ cess of inspecting other states earlier i.e., there was no The proof for Lemma 1 is given in Appendix I. Here, change. It is not possible to distinguish between these we provide a brief overview. We use the fact that two scenarios. the #initiated streams is equal to the highest stream number initiated so far and the stream initiation rule Since it might not be possible to detect a change (2(a) in Figure 1) to arrive at this claim. • during the hypothesis building phase and a change can Lemma 2. At the end of a quantum q = b2 for some occur at any time, the algorithm needs to start sev- integer b 1, ≥ eral processes during the hypothesis building phase. Each process aims to form a hypothesis for a particu- 1. b streams have been initiated, and lar CMP setting and to be able to do that, it needs to act only on the time steps for which that CMP setting 2. each initiated stream has been active for exactly b is in effect. On one hand, since a change can occur quantums. at any time step, the algorithm needs to start these processes at several time steps along the way. On the The proof for Lemma 2 is given in Appendix II. We other hand, if too many processes are started, each only provide a proof sketch here. Claim 1 is a direct process will not get enough time to form its hypoth- result of Lemma 1. Claim 2 can be proved by induction esis. Therefore sufficient time should be allocated to on b and considering the initiation rule and allocation each process. Both of these diverging requirements can rules (ii) and (iii) (see 2(a), 2(b)(ii) and 2(b)(iii) in be balanced, if both the number of processes and the Figure 1 respectively). time allocated to each process grow asymptotically as Lemma 3. In a round r, with probability at least 1 the square-root of time, as done in MNM. δ′ , − r 1. the length of the building phase is at most Using a sliding window in the building phase • is not possible: Using a sliding window in the check- 2 C S AL3 C S AL 3 ing phase is possible as each check-run is verifying the 1 (m) log 2 (m) ,  ǫ3 ǫδ′  same hypothesis (the one found in the preceding build- mX∈Mb r (cid:18) r (cid:19) ing phase) and hence findings from successive check-   runs can be shared. In the building phase however, 2. the building phase discovers a set of states r K ⊇ each stream with its own copy of the subroutine might →(m¯ ) for some CMP setting m¯ b (the set SL r r ∈ Mr be attempting to build different hypotheses and hence of underlying CMP settings during the building findings from two different streams cannot be shared. phase of round r),
3. and for each s , contains a policy π with Proof. There is always at least one change in the build- r r s ∈ K P τ (s π ) (1 + ε)L for the CMP setting m¯ b, ing phase of the first round as the first change is | s ≤ r ∈ Mr counted at t = 1 by default (see Section 2). For where S = S→ (m) is the number of incremen- 1 < r < R, we consider the following two mutually (m) | (1+ǫ)L | exclusive cases. tally discoverable states reachable in (1+ǫ)L time steps in the CMP m, C 1 = 216 (15)2 + 61 and C 2 = 225. Case 1: There exists no round 1 < r < R which has · no change in its building phase. Proof. Consider the CMP setting m at the start of In this case, every round contains at least one change r,1 the building phase in round r. Assume that UcbEx- and the total number of rounds is immediately upper- plore requires at most x quantums as exploration bounded by F 1. r,1 − steps for m (without any change) with high prob- r,1 Case 2: There exists at least one round 1 < r < R ability. Theorem 1 shows that the exploration steps which has no change in its building phase. for the CMP setting m required by UcbExplore r,1 Let r be a round such that there is no change during are at most C1S(mr,1)AL3 log C2S(mr,1)AL 3 with high its building phase. For all such rounds r which contain ǫ3 ǫδ′ r no change in the building phase, with probability at probability. There are tw(cid:16)o possible cases:(cid:17) least 1 δ/4, we prove that the checking phase of r Case 1: The problem doesn’t change for the duration contain− s at least one change. of x2 quantums. r,1 Recall from Lemma 3 that the sole CMP setting during Our meta-algorithm initiates stream 1 at q = 1 and the building phase of round r is denoted as m¯ and this stream will have been active for x quantums r r,1 at the end of quantum x2 (using Lemma 2). Since the building phase discovers the reachable states for r,1 m¯ with probability at least 1 δ′ . Theorem 1 shows t th he e p cor pob yle om f Udo ce bs En’ xt pc lh oa rn ege fof ror stt rh ei as men 1tir he asdu sara mt pio len s, thr at for the CMP setting m¯ r,− if r UcbExplore with only of m . Thus, stream 1 terminates at the end of run for W = C1|Kr|AL3 log C2|Kr|AL 3 steps, then r,1 r ǫ3 ǫδ′ x2 quantums of our meta-algorithm with probability r r,1 the failure probability (i.e.(cid:16), the probabil(cid:17)ity with which 1 − δ r′ and the building phase of round r ends. The UcbExplore doesn’t terminate at the end of at most three claims of the lemma follow from the respective W time steps) is at most δ′ where C = 216 (15)2+61 claims2 of Theorem 1 with b = m . r r 1 · Mr { r,1 } and C 2 = 225. Case 2: The problem changes at any point before the The only condition to trigger the next round is given end of x2 quantums. r,1 by Eq. (2). Therefore, when round r ends, Let m , m , . . . be the successive CMP settings. r,1 r,2 b Let x r,i be the required number of quantums needed > α + δ′ , by UcbExplore for each m r,i. Let m r,k be the first n r r r problem setting which doesn’t change from quantum where b is the number of times UcbExplore has (x r,1 + + x r,k−1)2 + 1 to quantum (x r,1 + + x r,k)2. failed to stop and return a set of reachable states · · · · · · The stream x r,1+ · · ·+x r,k−1+1 starting at (x r,1+ · · ·+ within W r time steps during the first part of the last x r,k−1)2 + 1 will have been active for x r,k quantums at n r check-runs. If the CMP setting was indeed m¯ r (i.e. the end of quantum (x r,1+ · · ·+x r,k)2 (using Lemma 2). there was no change) in the last n r check-runs, then That stream will therefore terminate and output the by Hoeffding’s inequality, set of reachable states and acceptable policies for m r,k b bat ilit th ye 1e −nd δ r′ o af nq du ta hn etu bm uil( dx inr, g1 + ph· a· s· e+ wx ilr l,k te)2 rmw ii nt ah tep .ro Tb ha e- P (cid:26) n r > α r + δ r′ (cid:27) ≤ exp( −2α2 rn r) = δ r′ . three claims of the lemma follow from the respective claims of Theorem 1 with b = m , . . . , m . Therefore when the round r stops, there has been a Mr { r,1 r,k } change in its checking phase with probability at least (1 (δ′ +δ′ )). Below we use that ∞ 1 = π2 . With − r r r=1 r2 6 a union bound and using R−1 2δ′ < 3δ ∞ 1 = r=1 Pr 2π2 r=1 r2 4.2 Bounding the number of rounds δ , we can claim that for all rounds r < R which do 4 P P not contain a change in the building phase, there is at Lemma 4. With probability at least 1 δ/4, the total − least one change in each of their respective checking number of rounds R F . ≤ phases with probability at least 1 δ . 2 − 4 The referred theorem only mentions the upper bound in terms of big-O notation. However, the constants C 1 and Considering both the cases, we get that the total num- C 2 can be computed from its proof in Lim and Auer (2012, ber of rounds is upper-bounded by the total number Section 4.6). of changes F with probability at least 1 δ . − 4
4.3 Bounding the exploration steps in all the as m¯ . Below we use that the number of time steps r building phases in a single check-run of round r is upper-bounded by 2 C1S(m¯ r)AL3 log C2S(m¯ r)AL 3 as S from L nue mm bm era of5. exW ploit rh atp ior noba stb ei pli sty inat alle l a ts ht e 1 bu− ild2δ i, ngthe pht ao st ea sl T× heoremǫ3 1. Till(cid:16)the CMǫ Pδ r′ setti(cid:17)ng is m| ¯K rr i| n≤ the(m c¯ hr e) cking is at most phase, the algorithm does not incur any exploration steps. For a change to m′ = m¯ , the following mutu- r 2 6 F C S AL3 4π2C F 2S AL 3 ally exclusive and exhaustive cases are possible:  f=1 1 ǫf 3 (cid:18)log 2 3ǫδ f (cid:19)  , Case 1: m′ doesn’t last for log |K ǫr δ| r′AL 3 check-runs. X Then all the time steps for w(cid:16)hich m′ is a(cid:17)ctive are con-   where S = S→ (m) is the number of incremen- sidered as exploration steps and they are are upper f | (1+ǫ)L | tally discoverable states reachable in (1+ǫ)L time steps bounded by th in the f CMP setting and #changes = F . 2C1S(m¯ r)AL3 log C2S(m¯ r)AL 3 log S(m¯ r)AL 3 . ǫ3 ǫδ r′ × ǫδ r′ Proof. We count all the steps in each building phase as (cid:16) (cid:17) (cid:16) (cid:17) 3 exploration steps. Lemma 3 provides an upper bound Case 2: m′ lasts for at least log |Kr|AL check-runs. on the number of exploration steps in the building ǫδ r′ There are three possible sub(cid:16)cases. (cid:17) phase of a single round r with the error probability limited to δ′ . Therefore, the total number of explo- r (a) W time steps are insufficient for m′. ration steps in all the building phases is at most r By insufficient we mean that 2 R  C 1S (m ǫ3)AL3 log C 2S ǫ( δm ′)AL 3  C1S(m¯ ǫ3r)AL3 log C2S( ǫm¯ δ r′r)AL 3 Xr=1 mX∈Mb r (cid:18) r (cid:19) < C1S (m′)AL(cid:16)3 log C2S (m′)A(cid:17) L 3   2 ǫ3 ǫδ′ R C 1S (m)AL3 4π2C 2r2S (m)AL 3 (cid:16) r (cid:17) =  ǫ3 log 3ǫδ  i.e. S (m¯ r) < S (m′). Xr=1 mX∈Mb r (cid:18) (cid:19) Eq.(2) verifies if change to a m′ such that S <  2  (m¯ r) F C S AL3 4π2C F 2S AL 3 S (m′) has occurred. Our algorithm keeps a count 1 f 2 f log of the empirical failures in the last n check-runs ≤  ǫ3 ǫδ  r f=1 (cid:18) (cid:19) where a failure means that the first part of a X   check-run has failed to terminate within W time r with error probability limited to δ + R δ′ < δ . steps (and thus had to be manually terminated at 4 r=1 r 2 W ). From Theorem 1, we know that that if no In the last inequality, we use tha(cid:16)t r R F(cid:17) with r probability 1 δ (Lemma 4) and the n≤ uP mbe≤ r of differ- change has occurred then the true failure proba- − 4 bility is δ′ . By Hoeffding’s inequality, ent CMP settings in all the rounds is F (Eq. (1)). r P b > α + δ′ , exp( 2α2n ) = δ′ . 4.4 Analyzing the checking phase nr r r ≤ − r r r n o We first bound the number of exploration steps in a Therefore, with probability 1 − δ r′ , we detect a checking phase caused due to a single change. change to m′ such that S (m¯ r) < S (m′) and the number of exploration steps added are at most Lemma 6. With probability 1 δ′ , the total number − r of exploration steps in the checking phase of a round r 2C S(m¯ r)AL3 log C2S(m¯ r)AL 3 log S(m¯ r)AL 3 . due to a single change is at most 1 ǫ3 ǫδ r′ × ǫδ r′ (cid:16) (cid:17) (cid:16) (cid:17) 2C 1S (m¯ r)AL3 log C 2S (m¯ r)AL 6 (b) {W r time steps are sufficient for m′ } and {a previ- ǫ3 ǫδ′ ously reachable state becomes unreachable in m′ (cid:18) r (cid:19) or the previously acceptable policy π to a s r where S (m¯ r) = |S (→ 1+ǫ)L(m¯ r) | is the number of incre- reachable state is not acceptable in m′ }∈ . P mentally discoverable states reachable in (1 + ǫ)L time Eq.(3) checks for such scenarios. As it keeps veri- steps in the CMP setting m¯ r. fying if the policy evaluation of π r succeeds { ∈ P } in the last n check-runs, it checks for both - i) if r Proof. Recall from Lemma 3 that the CMP setting a previously reachable state is still reachable and for which the building phase in round r has found ii) if the previously acceptable policy is still ac- the reachable states and acceptable policies is denoted ceptable. Proceeding in a similar manner to the
previous subcase, we can show that, with prob- round r due to a single change with error probability ability 1 δ′ , the number of exploration steps limited to δ′ . Due to the construction of our algo- − r r added is at most rithm, only the changes in round r can lead to explo- ration steps in the checking phase of round r. Let F 2C S(m¯ r)AL3 log C2S(m¯ r)AL 3 log S(m¯ r)AL 3 . be the number of changes in round r. Then, the totar l 1 ǫ3 ǫδ r′ × ǫδ r′ number of exploration steps are at most (cid:16) (cid:17) (cid:16) (cid:17) (c) W time steps are sufficient for m′ and a previ- r R ously unreachable state becomes reachable in m′. 2FrC1S(m¯ r)AL3 log C2S(m¯ r)AL 6 ǫ3 ǫδ′ Let’s assume that a previously unreachable state s r is reachable in m′. Either s or s / . In the Xr=1 (cid:16) (cid:17) r r R former case, policy evaluati∈ onK (i.e. 2∈ ndK part of a max 2C1Sf AL3 log 4π2C2F 2Sf AL 6 F check-run) continues to check if π s ∈ Pr is still ac- ≤ f (cid:20) ǫ3 (cid:16) 3ǫδ (cid:17) (cid:21) · Xr=1 r c me op rt ea ,b tl he. enIf thπ es c∈ heP cr k i gs ivfo eu nn bd y t Eo qb . e (3a )c wce ip llt bab el te rin go - ≤ F · m fax 2C1S ǫf 3AL3 log 4π2C2 3F ǫδ2Sf AL 6 gered, the change will be detected and the number (cid:20) (cid:16) (cid:17) (cid:21) of exploration steps added are given by the previ- with error probability limited to δ + F δ′ < δ . ous subcase. If π is still acceptable, it leads 4 r=1 r 2 s r ∈ P In the first inequality, we use tha(cid:16)t r R F(cid:17) with to no additional exploration steps (see Definition ≤P ≤ probability 1 δ (Lemma 4) and S max S . 4). Eq. (4) checks for scenarios where s / r. − 4 (m¯ r) ≤ f f ∈ K Theorem 1 guarantees that if a state is in S→(m′), L 4.5 Proof of Theorem 2 the probability that it fails to appear in the out- put of UcbExplore(δ′ , ǫ, L, , s ) is at most δ′ . r A 0 r Proof. The total number of exploration steps in all the For every state s / , but which has appeared ∈ Kr rounds is simply the sum of the exploration steps in all in the output of the first part in one of the last n r the building phases and all the checking phases given check-runs, we can compute the empirical failures by Lemma 5 and Lemma 7 respectively. Therefore the as n v . Then, by Hoeffding’s inequality r − s number of total exploration steps for all the rounds is P δ′ 1 vs > α exp( 2α2n ) = δ′ . at most r − − nr r ≤ − r r r 2 n (cid:16) (cid:17) o F tT eh cter se ufo chre a, w chit ah ngp ero ab na dbi tl hit ey na ut mle ba es rt o1 f− exδ pr′ l, ow rae td ioe n-  C1S ǫf 3AL3 log 4π2C2 3F ǫδ2Sf AL 3  steps added is at most f X=1 (cid:16) (cid:17)  + F max 2C1Sf AL3 log 4π2C 2F 2Sf AL 6 2C 1 S(m¯ r ǫ) 3AL3 log C2S( ǫm¯ δ r′r)AL 3 × log S(m¯ ǫr δ) r′AL 3 . · f∈{1,...,F } (cid:20) ǫ3 (cid:16) 3ǫδ (cid:17) (cid:21) (cid:16) (cid:17) (cid:16) (cid:17) with probability at least 1 δ + δ using a union − 2 2 Considering all the cases, the number of exploration bound. steps added is at most 2C S(m¯ r)AL3 log C2S(m¯ r)AL 6 (cid:0) (cid:0) (cid:1)(cid:1) 1 ǫ3 ǫδ′ with probability at least 1 δ′ . (cid:16) r (cid:17) 5 Concluding remarks − r Now we can bound the number of exploration steps for We considered the problem of learning to explore au- all the checking phases. tonomously in a non-stationary environment and pro- posed a pertinent performance measure. We gave Lemma 7. With probability at least 1 δ , the total − 2 a natural algorithm for the considered problem and number of exploration steps in all the checking phases proved an upper bound on the performance measure is upper-bounded by that scales with the square of the number of changes. 2C 1S f AL3 4π2C 2F 2S f AL 6 Proving a lower bound for this problem setting remains F max log · f∈{1,...,F } " ǫ3 (cid:18) 3ǫδ (cid:19) # for future work. The solution strategy of first having a building phase (with multiple processes trying to build where S = S→ (f ) is the number of incremen- a hypothesis) and then a checking phase (where it is f | (1+ǫ)L | tally discoverable states reachable in (1+ǫ)L time steps verified if the last built hypothesis is still true) could in the f th CMP setting and # changes = F . be used for other non-stationary learning problems. In particular, this strategy could be useful for the learn- Proof. Lemma 6 provides an upper bound on the num- ing problems where each hypothesis building-process ber of exploration steps in the checking phase of a needs to act independently and cannot share findings.
References of the 25th Annual Conference on Learning Theory, volume 23 of Proceedings of Machine Learning Re- Yasin Abbasi, Peter L Bartlett, Varun Kanade, search, pages 40.1–40.24, 2012. Yevgeny Seldin, and Csaba Szepesvari. Online learn- ing in Markov decision processes with adversarially Manuel Lopes, Tobias Lang, Marc Toussaint, and chosen transition probability distributions. In Ad- Pierre-Yves Oudeyer. Exploration in model-based vances in Neural Information Processing Systems supervised learning by empirically estimating 26, pages 2508–2516, 2013. learning progress. In Advances in neural informa- tion processing systems, pages 206–214, 2012. Joshua Achiam and Shankar Sastry. Surprise-based intrinsic motivation for deep supervised learning. F. Niroui, K. Zhang, Z. Kashino, and G. Nejat. Deep CoRR, abs/1703.01732, 2017. supervised learning robot for search and rescue applications: Exploration in unknown cluttered en- Mohammad Gheshlaghi Azar, Bilal Piot, Bernardo A. vironments. IEEE Robotics and Automation Letters, Pires, Jean-Bastien Grill, Florent Altch´e, and 4(2):610–617, 2019. R´emi Munos. World discovery models. CoRR, abs/1902.07685, 2019. Ronald Ortner, Pratik Gajane, , and Peter Auer. Vari- ational regret bounds for supervised learning. In A. Baranes and P.-Y. Oudeyer. R-IAC: Robust intrin- Proceedings of the 35th Conference on Uncertainty sically motivated exploration and active learning. in Artificial Intelligence, 2019. IEEE Transactions on Autonomous Mental Devel- opment, 1:155–169, 2009. Georg Ostrovski, Marc G Bellemare, Aa¨ron van den Oord, and R´emi Munos. Count-based exploration Yuri Burda, Harrison Edwards, Deepak Pathak, with neural density models. In Proceedings of the Amos J. Storkey, Trevor Darrell, and Alexei A. 34th International Conference on Machine Learn- Efros. Large-scale study of curiosity- ing, pages 2721–2730, 2017. driven learning. In ICLR, 2019. URL https://openreview.net/forum?id=rJNwDjAqYX. P-Y. Oudeyer, F. Kaplan, and V.V. Hafner. Intrinsic motivation systems for autonomous mental develop- Eyal Even-dar, Sham M Kakade, and Yishay Man- ment. IEEE Transactions on Evolutionary Compu- sour. Experts in a Markov decision process. In Ad- tation, 11:265–286, 2007. vances in Neural Information Processing Systems, pages 401–408, 2005. Pierre-Yves Oudeyer and Frederic Kaplan. What is Jacqueline Gottlieb, Pierre-Yves Oudeyer, Manuel intrinsic motivation? a typology of computational Lopes, and Adrien Baranes. Information-seeking, approaches. Frontiers in neurorobotics, 1, 2007. curiosity, and attention: computational and neural Deepak Pathak, Pulkit Agrawal, Alexei A Efros, and mechanisms. Trends in cognitive sciences, 17(11): Trevor Darrell. Curiosity-driven exploration by self- 585–593, 2013. supervised prediction. In Proceedings of the IEEE Nick Haber, Damian Mrowca, Stephanie Wang, Li F Conference on Computer Vision and Pattern Recog- Fei-Fei, and Daniel L Yamins. Learning to play with nition Workshops, pages 16–17, 2017. intrinsically-motivated, self-aware agents. In Ad- J. Schmidhuber. Formal theory of creativity, fun, and vances in Neural Information Processing Systems, intrinsic motivation (19902010). Autonomous Men- pages 8388–8399, 2018. tal Development, IEEE Transactions on, 2:230–247, Elad Hazan, Sham Kakade, Karan Singh, and Abby 2010. Van Soest. Provably efficient maximum entropy Ju¨rgen Schmidhuber. A possibility for implement- exploration. In Kamalika Chaudhuri and Ruslan ing curiosity and boredom in model-building neu- Salakhutdinov, editors, ICML, volume 97, pages ral controllers. In Proceedings of the first interna- 2681–2691, 2019. tional conference on simulation of adaptive behavior Rein Houthooft, Xi Chen, Yan Duan, John Schulman, on From animals to animats, pages 222–227. MIT Filip De Turck, and Pieter Abbeel. Variational in- Press, 1991. formation maximizing exploration. In NIPS 2016 Satinder P. Singh, Andrew G. Barto, and Nuttapong Deep Learning Symposium, 2016. Chentanez. Intrinsically motivated reinforcement Jens Kober, J. Andrew Bagnell, and Jan Peters. Rein- learning. In NIPS, 2004. forcement learning in robotics: A survey. The Inter- Satinder P. Singh, Richard L. Lewis, Andrew G. Barto, national Journal of Robotics Research, 32(11):1238– and Jonathan Sorg. Intrinsically motivated rein- 1274, 2013. forcement learning: An evolutionary perspective. Shiau Hong Lim and Peter Auer. Autonomous ex- IEEE T. Autonomous Mental Development, 2:70– ploration for navigating in MDPs. In Proceedings 82, 2010.
Bradly C. Stadie, Sergey Levine, and Pieter I Proof of Lemma 1 Abbeel. Incentivizing exploration in reinforce- ment learning with deep predictive models. CoRR, Proof. The number of initiated streams is equal to the abs/1507.00814, 2015. highest stream number initiated so far. Let that be pˆ. Since pˆ is initiated on or before q, (pˆ 1)2 + 1 q (see − ≤ 2(a) in Figure 1) which is equivalent to, pˆ < √q + 1. (5) Since pˆ + 1 has not been initiated yet, q (pˆ + 1 1)2 ≤ − which translates to, pˆ √q. (6) ≥ Recall that both pˆ and q are integers 1. If q is a ≥ perfect square, the only integer satisfying both Eq. (5) and (6) is √q = √q . If q is not a perfect square, ⌈ ⌉ then Eq. (6) reduces to pˆ > √q. And the only integer satisfying √q < p < √q + 1 is √q . ⌈ ⌉ II Proof of Lemma 2 Proof. Claim 1 is a direct result of Lemma 1. We prove claim 2 by induction on b. Base case: b = 1. At the end of q = b2 = 1, only 1 stream has been initiated and it has been active for 1 quantum. Inductive case: Let’s assume that the claim is true for b = ˆb i.e at the end of quantum q = ˆb2, exactly ˆb streams have been initiated and each of them has been active for ˆb quantums. At the next quantum i.e ˆb2 + 1, stream ˆb + 1 will be initiated by the initiation rule and it will be active for the next b quantums due to the allocation rule (ii). At this point, we are at the end of quantum (ˆb + 1) ˆb and all the ˆb + 1 initiated streams · have each been active for ˆb quantums. Next, by virtue of the allocation rule (iii), each of the (b + 1) streams will be allocated 1 quantum each till we are the end of quantum ((ˆb + 1) ˆb) + (ˆb + 1) = (ˆb + 1)2. ·
