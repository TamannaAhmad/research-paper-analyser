Entropy-based adaptive Hamiltonian Monte Carlo Marcel Hirt Michalis K. Titsias Department of Statistical Science DeepMind University College London, UK London, UK marcel.hirt.16@ucl.ac.uk mtitsias@google.com Petros Dellaportas Department of Statistical Science University College London, UK Department of Statistics Athens Univ. of Economics and Business, Greece and The Alan Turing Institute, UK Abstract Hamiltonian Monte Carlo (HMC) is a popular Markov Chain Monte Carlo (MCMC) algorithm to sample from an unnormalized probability distribution. A leapfrog integrator is commonly used to implement HMC in practice, but its per- formance can be sensitive to the choice of mass matrix used therein. We develop a gradient-based algorithm that allows for the adaptation of the mass matrix by encouraging the leapfrog integrator to have high acceptance rates while also ex- ploring all dimensions jointly. In contrast to previous work that adapt the hyper- parameters of HMC using some form of expected squared jumping distance, the adaptation strategy suggested here aims to increase sampling efficiency by maxi- mizing an approximation of the proposal entropy. We illustrate that using multiple gradients in the HMC proposal can be beneficial compared to a single gradient- step in Metropolis-adjusted Langevin proposals. Empirical evidence suggests that the adaptation method can outperform different versions of HMC schemes by ad- justing the mass matrix to the geometry of the target distribution and by providing some control on the integration time. 1 Introduction Consider the problem of sampling from a target density π on Rd of the form π(q) ∝ e−U(q), with a potential energy U : Rd → R being twice continuously differentiable. HMC methods [20, 46, 9] sample from a Boltzmann-Gibbs distribution µ(q, p) ∝ e−H(q,p) on the phase-space R2d based on the (separable) Hamiltonian function 1 H(q, p) = U (q) + K(p) with K(p) = p(cid:62)M −1p. 2 The Hamiltonian represents the total energy that is split into a potential energy term U and a ki- netic energy K which we assume is Gaussian for some symmetric positive definite mass matrix M . Suppose that (q(t), p(t)) t∈R evolve according to the differential equations dq(t) ∂H(q(t), p(t)) dp(t) ∂H(q(t), p(t)) = = M −1p(t) and = − = −∇U (q(t)). (1) dt ∂p dt ∂q Let (ϕ t) t(cid:62)0 denote the flow of the Hamiltonian system, that is for fixed t, ϕ t maps each (q, p) to the solution of (1) that takes value (q, p) at time t = 0. The exact HMC flow ϕ preserves 35th Conference on Neural Information Processing Systems (NeurIPS 2021). 1202 tcO 72 ]OC.tats[ 1v52641.0112:viXra
volume and conserves the total energy i.e. H ◦ ϕ = H. Consequently, the Boltzmann-Gibbs t distribution µ is invariant under the Hamiltonian flow, that is µ(ϕ (E)) = µ(E) for any Borel t set E ⊂ R2d. Furthermore, the flow satisfies the generalized reversibility condition F ◦ ϕ = t ϕ ◦ F with the flip operator F(q, p) = (q, −p). Put differently, the Hamiltonian dynamics go −t backward in time by negating the velocity. If an analytical expression for the exact flow were available, one could sample from µ using the invariant Markov chain that at state (q, p) first draws a new velocity p(cid:48) ∼ N (0, M ) with the next state set to ϕ (q, p(cid:48)) for some integration time T > 0. T Such a velocity refreshment is necessary as the HMC dynamics preserve the energy and so cannot be ergodic. However, the Hamiltonian flow cannot be computed exactly, except for very special potential functions. Numerical approximations to the exact solution of Hamiltonian’s equations are thus routinely used, most commonly the leapfrog method, also known as (velocity) Verlet integrator [28, 10]. For a step size h > 0 and L steps, such an algorithm updates the previous state q and a 0 new velocity p ∼ N (0, M ) by setting, for 0 (cid:54) (cid:96) (cid:54) L − 1, 0 h h p = p − ∇U (q ); q = q + hM −1p ; p = p − ∇U (q ). (2) (cid:96)+ 21 (cid:96) 2 (cid:96) (cid:96)+1 (cid:96) (cid:96)+ 1 2 (cid:96)+1 (cid:96)+ 1 2 2 (cid:96)+1 This scheme can be motivated by splitting the Hamiltonian wherein the kick mappings in the first and third step update only the momentum, while the drift mapping in the second step advances only the position q with constant speed. For T = Lh, the leapfrog integrator approximates ϕ (q , p ) T 0 0 by (q , p ) while also preserving some geometric properties of ϕ, namely volume preservation and L L generalized reversibility. The leapfrog method is a second-order integrator, making an O(h2) energy error H(q , p ) − H(q , p ). A µ-invariant Markov chain can be constructed using a Metropolis- L L 0 0 Hastings acceptance step. More concretely, the proposed state (q , p ) is accepted with the ac- L L ceptance rate a(q , p ) = min{1, exp [− (H(q , p ) − H(q , p ))]}, while the next state is set 0 0 L L 0 0 to F(q , p ) in case of rejection, although the velocity flip is inconsequential for full refreshment 0 0 strategies. We want to explore here further the generalised speed measure introduced in [54] for adapting RWM or MALA that aim to achieve fast convergence by constructing proposals that (i) have a high average log-acceptance rate and (ii) have a high entropy. Whereas the entropy of the proposal in RWM or MALA algorithms can be evaluated efficiently, the multi-step nature of the HMC trajectories makes this computation less tractable. The recent work in [41] consider the same adaptation objective by learning a normalising flow that is inspired by a leapfrog proposal with a more tractable entropy by masking components in a leapfrog-style update via an affine coupling layer as used for RealNVPs [19]. [60] sets the integration time by maximizing the proposal entropy for the exact HMC flow in Gaussian targets, while choosing the mass matrix to be the inverse of the sample covariance matrix. 2 Related work The choice of the hyperparameters h, L and M can have a large impact on the efficiency of the sampler. For fixed L and M , a popular approach for adapting h is to target an acceptance rate of around 0.65 which is optimal for iid Gaussian targets in the limit d → ∞ [8] for a given integration time. HMC hyperparameters have been tuned using some form of expected squared jumping dis- tance (ESJD) [49], using for instance Bayesian optimization [56] or a gradient-based approach [40]. A popular approach suggested in [32] tunes L based on the ESJD by doubling L until the path makes a U-turn and retraces back towards the starting point, that is by stopping to increase L when the dis- tance to the proposed state reaches a stationary point [4]; see also [57] for a variation and [48] for a version using sequential proposals. Modern probabilistic programming languages such as Stan [12], PyMC3 [51], Turing [23, 58] or TFP [39] furthermore allow for an adaptation of a diagonal or dense mass-matrix within NUTS based on the sample covariance matrix. The Riemann manifold HMC algorithm from [25] has been suggested that uses a position dependent mass matrix M (x) based on a non-separable Hamiltonian, but can be computationally expensive, requiring O(d3) operations in general. An alternative to choose M or more generally the kinetic energy K was proposed in [43] by analysing the behaviour of x (cid:55)→ ∇K(∇U (x)). Different pre-conditioning approaches have been compared for Gaussian targets in [38]. A popular route has also been to first transform the target using tools from variational inference as in [31] and then run a HMC sampler with unit mass matrix on the transformed density with a more favourable geometry. 2
A common setting to study the convergence of HMC assumes a log-concave target. In the case that U is m -strongly convex and m -smooth, [45, 15] analyse the ideal HMC algorithm with unit mass 1 2 matrix where a higher condition number κ = m /m implies slower mixing: The relaxation time, 2 1 i.e. the inverse of the spectral gap, grows linear in κ, assuming the integration time is set to T = √1 . [14] establish non-asymptotic upper bounds on the mixing time using a leap-frog integrator 2 m2 where the step size h and the number L of steps depends explicitly on m and m . Convergence 1 2 guarantees are established using conductance profiles by obtaining (i) a high probability lower bound on the acceptance rate and (ii) an overlap bound, that is a lower bound on the KL-divergence between the HMC proposal densities at the starting positions q and q(cid:48) , whenever q is close to q(cid:48) . While 0 0 0 0 such bounds for controlling the mixing time might share some similarity with the generalised speed measure (GSM) considered here, they do not lend themselves easily to a gradient-based adaptation. 3 Entropy-based adaptation scheme We derive a novel method to approximate the entropy of the proposed position after L leapfrog steps. Our approximation is based on the assumption that the Hessian of the target is locally con- stant around the mid-point of the HMC trajectory, which allows for a stochastic trace estimator of the marginal proposal entropy. We develop a penalised loss function that can be minimized using stochastic gradient descent while sampling from the Markov chain in order to optimize a GSM. 3.1 Marginal proposal entropy Suppose that CC(cid:62) = M −1, where C is defined by some parameters θ and can be a diagonal matrix, a full Cholesky factor, etc. Without loss of generality, the step size h > 0 can be fixed. We can reparameterize the momentum resampling step p ∼ N (0, M ) by sampling v ∼ N (0, I) and 0 setting p = C−(cid:62)v. One can show by induction, cf. Appendix E for details, that the L-th step 0 position q and momentum p of the leapfrog integrator can be represented as a function of v via L L Lh2 q = T (v) = q − M −1∇U (q ) + LhCv − h2M −1Ξ (v), (3) L L 0 2 0 L and L−1 h (cid:88) p = W (v) = C−(cid:62)v − [∇U (q ) + ∇U ◦ T (v)] − h ∇U ◦ T (v) (4) L L 2 0 L i i=1 where L−1 (cid:88) Ξ (v) = (L − i)∇U ◦ T (v), (5) L i i=1 see also [42, 21, 14] for the special case with an identity mass matrix. Observe that for L = 1 leap-frog steps, this reduces to a MALA proposal with preconditioning matrix M −1. Under regularity conditions, see for instance [21], the transformation T : Rd → Rd is a C1- L diffeomorphism. With ν denoting the standard Gaussian density, the density r of the HMC proposal L for the position q after L leapfrog steps is the pushforward density of ν via the map T so that1 L L log r (T (v)) = log ν(v) − log | det DT (v)|. (6) L L L Observe that the density depends on the Jacobian of the transformation T : v (cid:55)→ q . We would like L L to avoid computing log | det DT (v)| exactly. Define the residual transformation L 1 S : Rd → Rd, v (cid:55)→ C−1T (v) − v. (7) L Lh L Then DT (v) = LhC(I +DS (v)) and consequently L L log | det DT (v)| = d log(Lh) + log | det C| + log | det(I +DS (v))|. (8) L L Combining (6) and (8) yields the log-probability of the HMC proposal log r (T (v)) = log ν(v) − d log(Lh) − log | det C| − log | det(I +DS (v))|. (9) L L L 1We denote the Jacobian matrix of a function f : Rd → Rd at the point x as Df(x). 3
Comparing the equations (3) and (7), one sees that S (v) = c − h C(cid:62)Ξ (v) for some constant L L L c ∈ Rd that depends on θ but is independent of v and consequently, DS (v) = − h C(cid:62)DΞ (v). We L L L next show a recursive expression for DS with a proof given in Appendix B. L Lemma 1 (Jacobian representation). It holds that DS = 0 and for any (cid:96) ∈ {2, . . . , L}, v ∈ Rd, 1 (cid:96)−1 (cid:88) i DS (v) = −h2 ((cid:96) − i) C(cid:62)∇2U (T (v)) C (I +DS (v)) . (10) (cid:96) (cid:96) i i i=1 In particular, DS (v) is a symmetric matrix. Suppose further that L2h2 < sup 1 . (cid:96) q∈Rd 4(cid:107)C(cid:62)∇2U(q)C(cid:107) 2 Then for any (cid:96) ∈ {1, . . . , L} and v ∈ Rd, we have (cid:107)DS (v)(cid:107) < 1 . (cid:96) 2 8 Notice that the recursive formula (10) requires computing 1 L(L − 1) terms, each involving the Hes- 2 sian, in order to compute the Jacobian after L leapfrog steps. Consider for the moment a Gaussian target with potential function U (q) = 1 (q − q )(cid:62)Σ−1(q − q ) for q ∈ Rd and positive definite 2 (cid:63) (cid:63) (cid:63) Σ ∈ Rd×d. Then, due to (10), for any q ∈ Rd, v ∈ Rd, L−1 (cid:88) i DS (v) = −h2 (L − i) C(cid:62)Σ−1C(I +DS (v)) = D + R (v), L L i L L i=1 where (cid:32)L (cid:88)−1 i (cid:33) L2 − 1 D = −h2C(cid:62)Σ−1C (L − i) = −h2 C(cid:62)Σ−1C (11) L L 6 i=1 (cid:16) (cid:17) and a remainder term R (v) = −h2C(cid:62)Σ−1C (cid:80)L−1(L − i) i DS (v) . From Lemma 1, we see L i=1 L i that if (cid:13) (cid:13)C(cid:62)Σ−1C(cid:13) (cid:13) 2 (cid:54) 4h21 L2 , then I +DS L(v) and −DS L(v) are positive definite. Then R L is also positive definite and log det(I +D ) (cid:54) log | det(I +DS (v))| and we can maximize the lower L L bound instead. Put differently, for Gaussian targets, DS can be decomposed into a component D L L that contains all terms that are linear in h2C(cid:62)Σ−1C and that does not require a recursion; plus a component R that contains terms that are higher than linear in h2C(cid:62)Σ−1C and that needs to be L solved recursively. Our suggestion is to ignore this second term. Note that R = 0 and an extension 2 can be to include higher order terms O (cid:16)(cid:2) h2C(cid:62)Σ−1C(cid:3)k(cid:17) , k > 1, in the approximation D . L For an arbitrary potential energy U , equation (10) shows that evaluating DS leads to a non-linear L function of the Hessians evaluated along the different points of the leapfrog-trajectory. We suggest to replace it with a first order term with one Hessian evaluation which is however scaled accordingly. Concretely, we maximize L2 − 1 L(θ) = log | det(I +D )| with D = −h2 C(cid:62)∇2U (q )C (12) L L 6 (cid:98)L/2(cid:99) as an approximation of log | det(I +DS )|. The intuition is that we assume that the target density L can be approximated locally by a Gaussian one with precision matrix Σ−1 in (11) given by the Hes- sian of U at the mid-point q of the trajectory. We want to optimize L(θ) given in (12) even (cid:98)L/2(cid:99) if we do not have access to the Hessian ∇2U explicitly, but only through Hessian-vector products ∇2U (q)w for some vector w ∈ Rd. Vector-Jacobian products vjp(f, x, w) = w(cid:62)Df (x) for dif- ferentiable f : Rd → Rd can be computed efficiently via reverse-mode automatic differentiation, so that ∇2U (q)w = vjp(∇U, q, w)(cid:62) can be evaluated with complexity linear in d. Suppose the multiplication with D is a contraction so that all eigenvalues of D have abso- L L lute values smaller than one. Then one can apply a Hutchinson stochastic trace estimator of log | det(I +D )| with a Taylor approximation, truncated and re-weighted using a Russian-roulette d ,L estimator [44], see also [29, 5, 13] for similar approaches in different settings. More concretely, let N be a positive random variable with support on N and let p = P (N (cid:62) k). Then, k L(θ) = log det(I +D ) = E (cid:34) (cid:88)N (−1)k+1 ε(cid:62) (D )k ε(cid:35) , (13) L N,ε kp L k k=1 4
where ε is drawn from a Rademacher distribution. While this yields an unbiased estimator for L(θ) and its gradient as shown in Appendix A.1 if D is contractive, it can be computationally expensive L if N has a large mean or have a high variance if D has an eigenvalue that is close to 1 or −1, see L [44, 17]. Since both the first order Gaussian approximation as well as the Russian Roulette estimator hinges on D having small absolute eigenvalues, we consider a constrained optimisation approach L that penalises such large eigenvalues. For the random variable N that determines the truncation level (cid:13) (cid:13) in the Taylor series, we compute b N = (D L)N ε/(cid:13)(D L)N ε(cid:13) 2 and µ N = b(cid:62) N D Lb N . Note that this corresponds to applying N times the power iteration algorithm and with |λ | > |λ | (cid:62) . . . (cid:62) |λ | 1 2 d denoting the eigenvalues of the symmetric matrix D , almost surely µ → λ for n → ∞, see L n 1 [26]. For some δ ∈ (0, 1), we choose some differentiable monotone increasing penalty function h : R → R such that h(x) > 0 for x > δ and h(x) = 0 for x (cid:54) δ and we add the term γh(|µ |) for N γ > 0 to the loss function that we introduce below, see Appendix A.2 for an example of h. 3.2 Adaptation with a generalised speed measure Extending the objective from [54] to adapt the HMC proposal, we aim to solve (cid:90) (cid:90) (cid:104) (cid:105) arg min π(q )ν(v) − log a ((q , v), (T (v), W (v))) + β log r (T (v)) dvdq , (14) 0 0 L L L L 0 θ where T , W , r as well as the acceptance rate a depend on q and the parameters θ we want to L L L 0 adapt. Also, the hyper-parameter β > 0 can be adapted online by increasing β if the acceptance rate is above a target acceptance rate α and decreasing β otherwise. We choose α = 0.67, which is (cid:63) (cid:63) optimal for increasing d under independence assumptions [8]. One part of the objective constitutes minimizing the energy error ∆(q , v) = H(T (v), W (v)) − H(q , C−(cid:62)v) that determines the 0 L L 0 log-acceptance rate via log a(q , C−(cid:62)v) = min{0, −∆(q , v)}. Unbiased gradients of the energy 0 0 error can be obtained without stopping any gradient calculations in the backward pass. However, we found that a multi-step extension of the biased fast MALA approximation from [54] tends to improve the adaptation by stopping gradients through ∇U as shown in Appendix A.3. Suppose that the current state of the Markov chain is q. We resample the momentum v ∼ N (0, I) and aim to solve (14) by taking gradients of the penalised loss function − min{0, −∆(q, v)} − β (d log h + log | det C| + L(θ) − γh(|µ |)) , N as illustrated in Algorithm 1, which also shows how we update the hyperparameters β and γ. The adaptation scheme in Algorithm 1 requires to choose learning rates ρ , ρ , ρ and can be viewed θ β γ within a stochastic approximation framework of controlled Markov chains, see for instance [2, 1, 3]. Different conditions have been established so that infinite adaptive schemes still converge to the correct invariant distribution, such as diminishing adaptation and containment [50]. We have used Adam [37] with a constant step size to adapt the mass matrix, but have stopped the adaptation after some fixed steps so that any convergence is preserved and we leave an investigation of convergence properties of an infinite adaptive scheme for future work. 4 Numerical experiments This section illustrates the mixing performance of the entropy-based sampler for a variety of target densities. First, we consider Gaussian targets either in high dimensions or with a high condition number. Our results confirm (i) that HMC scales better than MALA for high-dimensional Gaussian targets and (ii) that the adaptation scheme learns a mass matrix that is adjusted to the geometry of the target. This is in contrast to adaptation schemes trying to optimize the ESJD [49] or variants thereof [40] that can lead to good mixing in a few components only. Next, we apply the novel adaptation scheme to Bayesian logistic regression models and find that it often outperforms NUTS, except in a few data sets where some components might mix less efficiently. We also compare the entropy-based adaptation with Riemann-Manifold based samplers for a Log-Gaussian Cox point process models. We find that both schemes mix similarly, which indicates that the gradient-based adaptation scheme can learn a suitable mass matrix without having access to the expected Fisher information matrix. Then, we consider a high-dimensional stochastic volatility model where the entropy-based scheme performs favourably compared to alternatives and illustrate that efficient sparsity assumptions can be accommodated when learning the mass matrix. Finally, we show in a toy example how the suggested 5
Algorithm 1 Sample the next state q(cid:48) and adapt β, γ and θ. 1: Sample velocity v ∼ N (0, I) and set p = C−(cid:62)v. 2: Apply integrator LF to obtain (q (cid:96), p (cid:96), ∇U (q (cid:96))) 0(cid:54)(cid:96)(cid:54)L = LF(q, p). 3: Stop gradients ∇U (q (cid:96)) = stop grad(∇U (q (cid:96))) for 0 (cid:54) (cid:96) (cid:54) L. 4: Compute Ξ L(v) using (5). 5: Compute ∆(q 0, v) using (16) and set a = min{1, e−∆(q0,v)}. 6: Compute η¯ N , y = RADEMACHER(). 7: Set L(θ) = stop grad(y)(cid:62)D Lε. (cid:16) (cid:17) 8: Set b N = stop grad (cid:107)η¯η¯ NN (cid:107)2 2 and µ N = b(cid:62) N D Lb N . 9: E(θ) = − min{0, −∆(q 0, v)} − β (d log h + log | det C| + L(θ) − γh(|µ N |)) . 10: Adapt θ ← θ − ρ θ∇ θE(θ). 11: Adapt β ← Π β [β(1 + ρ β(a − α (cid:63))]. #Π β projects onto a compact set; default value [10−2, 102]. 12: Adapt γ ← Π γ [γ + ρ γh(|µ N |)]. #Π γ projects onto a compact set; default value [103, 105]. 13: Sample u ∼ U(0, 1) and set q(cid:48) = 1 {u(cid:54)a} q L + 1 {u>a} q. 14: function D L(w): 15: #D L(w) = D Lw computes Hessian-vector products efficiently 16: z = vjp(∇U, stop grad(q ), Cw)(cid:62) (cid:98)L/2(cid:99) 17: return −h2 L2−1 C(cid:62)z 6 18: end function 19: function RADEMACHER: 20: Sample Rademacher random variable ε and truncation level N . 21: Initialise y ←− 0 and η¯ 0 = ε. 22: for k = 1...N do 23: #Apply a spectral normalisation for stability if D L is not a contraction; δ(cid:48) ∈ (0, 1). 24: Set η¯ k = D Lη¯ k−1 · min {1, δ(cid:48) (cid:107)η¯ k−1(cid:107) 2 / (cid:107)D Lη¯ k−1(cid:107) 2} and y ← y + (− p1 k)k η¯ k. 25: end for 26: return η¯ N , y 27: end function approach might be modified to sample from highly non-convex potentials. Our implementation2 builds up on tensorflow probability [39] with some target densities taken from [53]. We used 10 parallel chains throughout our experiments to adapt the mass matrix. 4.1 Gaussian targets Anisotropic Gaussian distributions. We consider sampling from a multivariate Gaussian distri- bution N (0, Σ) with strictly convex potential U (q) = 1 q(cid:62)Σ−1q for different covariance matrices 2 Σ. For c > 0, assume a covariance matrix given by Σ = δ exp (c(i − 1)/(d − 1) log 10). We set ij ij (i) c = 3 and d ∈ {103, 104} and (ii) c = 6 and d = 100, as considered in [52]. The eigenvalues of the covariance matrix are thus distributed between 1 to 100 in setting (i), while they vary from 1 and 106 in setting (ii). The preconditioning factor C is assumed to be diagonal. We adapt the sampler for 4 × 104 steps in case (i) and for 105 steps in case (ii). We compared it with a NUTS implementation in tensorflow probability (TFP) [39] with a default maximum tree depth of 10 and step sizes adapted using dual averaging [32, 47] that we denote by N in the figures below. Addition- ally, we consider a further adaptation of NUTS by adapting a diagonal mass matrix using an online variance estimate of the accepted samples as implemented in TFP and denoted AN subsequently. We also consider two objectives as a replacement of the generalised speed measure (GSM): (a) the ESJD and (b) a weighted combination of the ESJD and its inverse as suggested in Levy et al. [40], without any burn-in component, which we denote L2HMC, see Appendix D for a precise definition. We compute the minimum and mean effective sample size (minESS and meanESS) of all functions q (cid:55)→ q over i ∈ {1, . . . , d} as shown in Figure 1a-1b for d = 103 in case (i) with leapfrog steps i ranging from L = 1 to 10. It can be observed that HMC adapted with the GSM objective performs 2https://github.com/marcelah/entropy_adaptive_hmc 6
well in terms of minESS/sec for L > 1, whereas the ESJD or L2HMC objectives yield poor mixing as measured in terms of the minESS/sec. The meanESS/sec statistics are more similar for the differ- ent objectives. These observations provide some empirical evidence that the ESJD can be high even when some components mix poorly, which has been a major motivation for the GSM objective in [54]. The mass matrix learned using the GSM adapts to the target covariance as can be seen from the the condition numbers of C(cid:62)Σ−1C in Figure 1c becoming relatively close to 1. The GSM objective also yields acceptance rates approaching 1 for increasing leap-frog steps and multiplication with D becomes a contraction as shown in Appendix F.1, Figure 7. Results for d = 104 can be found L in Figure 8 in Appendix F.1 which indicate that as the dimension increases, using more leap-frog steps becomes more advantageous. For the case (ii) of a very ill-conditioned target, results in Table 1 show that the GSM objective leads to better minESS/sec values, while further statistics shown in Figure 9 illustrate that the GSM also yields to higher minESS/sec values compared to NUTS with an adapted mass matrix. We want to emphasize that for fixed L, high acceptance rates for HMC need not be disadvantageous. This is illustrated in Figure 11 in Appendix F.4 for a Gaussian target N (0, I) in dimension d = 10, where tuning just the step-size to achieve a target acceptance rate can lead to slow mixing for some L, because the proposal can make a U-turn. (a) (b) (c) Figure 1: Minimum (1a) and mean (1b) effective sample size of q (cid:55)→ q per second after adaptation i for an anisotropic Gaussian target (d = 1000). The condition number of the transformed Hessian C(cid:62)Σ−1C are shown in (1c). Correlated Gaussian distribution. We sample from a 51-dimensional Gaussian target with co- variance matrix given by the squared exponential kernel plus small white noise as in [54], with k(x , x ) = exp (cid:0) − 1 (x − x )2/0.42(cid:1) + .01δ on the regular grid [0, 4]. We consider a general i j 2 i j ij Cholesky factor C. The adaptation is performed over 105 steps. Results over 10 runs are shown in Figure 10 in Appendix F.3 and summarized in Table 2. Table 1: MinESS/sec for gradient- Table 2: MinESS/sec for gradient-based based adaptation schemes targeting an adaptation schemes targeting a correlated ill-conditioned Gaussian density (d = 100). Gaussian density (d = 51). Steps GSM ESJD L2HMC Steps GSM ESJD L2HMC 1 122.3 (15.5) 0.1 (0.01) 0.1 (0.01) 1 63.8 (3.9) 0.8 (1.6) 0.3 (0.1) 5 753.8 (22.2) 0.1 (0.02) 0.1 (0.02) 5 390.0 (5.0) 2.0 (5.4) 2.7 (2.3) 10 570.0 (37.4) 0.6 (395.2) 0.1 (0.05) 10 282.7 (7.8) 0.9 (3.7) 0.4 (0.9) 4.2 Logistic regression Consider a Bayesian logistic regression model with n data points y ∈ {0, 1} and d-dimensional i covariates x ∈ Rd for i ∈ {1, . . . , n}. Assuming a Gaussian prior with covariance matrix Σ im- i 0 (cid:104) (cid:16) (cid:17)(cid:105) plies a potential function U (q) = (cid:80)n i=1 −y ix(cid:62) i q + log 1 + ex(cid:62) i q + 1 2 q(cid:62)Σ− 0 1q. We considered six datasets (Australian Credit, Heart, Pima Indian, Ripley, German Credit and Caravan) that are commonly used for benchmarking inference methods, cf. [16]. The state dimension ranges from d = 3 to d = 87. We choose Σ = I and parameterize C via a Cholesky matrix. We adapt over 0 104 steps. HMC with a moderate number of leap-frog steps tends to perform better for four out of 7
six data sets, with subpar performance for the Australian and Caravan data in terms of minESS/sec, albeit with higher mean ESS/sec across dimensions. The adaptive HMC algorithm tends to perform well if D is contractive during iterations of the Markov chain such as for the German Credit data L set as shown in Figure 2, where the eigenvalues of D are estimated using a power iteration. If this L is not the case as for the Caravan data in Figure 3, the adapted HMC algorithm can perform worse than MALA or NUTS. More detailed diagnostics for all data sets can be found in Appendix G. (a) (b) (c) Figure 2: Minimum (2a) and mean (2b) effective sample size for a Bayesian logistic regression model for German credit data set (d = 25) after adaptation. Estimates of the eigenvalues of D in L 2c. (a) (b) (c) Figure 3: Minimum (3a) and mean (3b) effective sample size for a Bayesian logistic regression model for caravan data set (d = 87) after adaptation. Estimates of the eigenvalues of D in 3c. L 4.3 Log-Gaussian Cox Point Process Inference in a log-Gaussian Cox process model is an ideal setting for Riemann-Manifold (RM) MALA and HMC [25], as a constant metric tensor is used therein that does not de- pend on the position, making the complexity no longer cubic but only quadratic in the di- mension d of the target. Consider an area on [0, 1]2 discretized into grid locations (i, j), for i, j = 1, . . . , n. The observations y are Poisson distributed and conditionally independent ij given a latent intensity process {λ} with means λ = m exp(x ) for m = n−2 and a la- ij ij ij tent vector x drawn from a Gaussian process with constant mean µ and covariance function (cid:112) Σ = σ2 exp{− (i − i(cid:48))2 + (j − j(cid:48))2/(nβ)}. The target is proportional to p(y, x) ∝ (i,j),(i(cid:48),j(cid:48)) x (cid:81)n×n exp [y x − m exp(x )] exp (cid:2) −(x − µ1)(cid:62)Σ−1(x − µ1)/2(cid:3) . For the RM based samplers, i,j ij ij ij the preconditioning matrix is M = Λ + Σ−1 where Λ is a diagonal matrix with diagonal elements {m exp(µ + Σ )} and step sizes adapted using dual averaging. We generate simulated data for ii i d ∈ {64, 256} and adapt for 2000 steps using a Cholesky factor C. Figure 18 in Appendix H illus- trates that the entropy-based adaptation can achieve a higher minESS/sec score for d = 64 with high acceptance rates for increasing leap-frog steps. The RM samplers perform slightly better in terms of minESS/sec for d = 256, see Figure 4 and Figure 19 for a comparison of the inverse mass matrices. 4.4 Stochastic volatility model We consider a stochastic volatility model [36, 34] that has been used with minor variations for adapting HMC [25, 32, 57]. Assume that the latent log-volatilities follow an autoregressive AR(1) 8
(a) (b) (c) Figure 4: Minimum (4a) and mean (4b) effective sample size for a Cox process in dimension d = 256 after adaptation. Estimates of the eigenvalues of D using power iteration in (4c). L process so that h ∼ N (0, σ2/(1 − φ2)) and for t ∈ {1, . . . , T − 1}, h = φh + η with 1 t+1 t t+1 η ∼ N (0, σ2). The observations follow the dynamics y |h ∼ N (0, exp(µ + h )). The prior t t t t distributions for the static parameters are: the persistence of the log-volatility process (φ + 1)/2 ∼ Beta(20, 1.5); the mean log-volatility µ ∼ Cauchy(0, 2); and the scale of the white-noise process σ ∼ Half-Cauchy(0, 1). We reparametrize φ and σ with a sigmoid- and softplus-transformation, respectively. Observe that the precision matrix of the AR(1) process is tridiagonal. Since a Cholesky factor of such a matrix is tridiagonal, we consider the parameterization C = B−1 for an upper- θ triangular and tridiagonal matrix B . The required operations with such banded matrices have a θ complexity of O(d), see for instance [22]. For comparison, we also consider a diagonal matrix C. We apply the model to ten years of daily returns of the S&P500 index, giving rise to a target dimension of d = 2519. In order to account for the different number of gradient evaluations, we use 3.5 × 104/L steps for the adaptation and for evaluating the sampler based on L ∈ {1, . . . , 10} leapfrog steps. We run NUTS for 1000 steps which has a four times higher run-time compared to the other samplers. In addition to using effective sample size to assess convergence, we also report the potential scale reduction factor split-Rˆ [24, 55] where large values are indicative of poor mixing. We report results over three replications in Figure 5 with more details in Figure 20, Appendix I. First, HMC with moderately large L tends to improve the effective samples per computation time compared to the MALA case, while also having a smaller Rˆ. Second, using a tridiagonal mass matrix improves mixing compared to a diagonal one, particularly for the latent log-volatilities as seen in the median ESS/sec or median Rˆ values. The largest absolute eigenvalue of D tends to be L smaller for a tridiagonal mass matrix and the acceptance rates are approaching 100% more slowly for increasing L. Third, NUTS seems less efficient as does using a dual-adaptation scheme. We imagine that similar efficient parameterizations of M or M −1 can be used for different generali- sations of the above stochastic volatility model, such as including p sub-diagonals for log-volatilities having a higher-order AR(p) dynamics or multivariate extensions using a suitable block structure. Likewise, this approach might also be useful for inferences in different Gaussian Markov Random Field models with sparse precision matrices. (a) (b) (c) Figure 5: Minimum (5a) and median (5b) effective sample size per second and maximum Rˆ of q (cid:55)→ q for a stochastic volatility model (d = 2519) after adaptation. i 9
4.5 Learning non-linear transformations To illustrate an extension to sample from highly non-convex targets by learning a non-linear trans- formation within the suggested framework as explained in greater detail in Appendix C, we con- sider sampling from a two-dimensional Banana distribution that results from the transformation of N (0, Λ) where Λ is a diagonal matrix having entries 100 and 1 via the volume-preserving map φ (x) = (x , x + b(x2 − 100)), for b = 0.1, cf. [27]. We consider a RealNVP- b 1 2 1 type [19] transformation f = f ◦ f ◦ f where f (x , x ) = (x , x · g(s(x )) + t(x ), 3 2 1 1 1 2 1 2 1 1 f (x , x ) = (x · g(s(x )) + t(x ), x ) and f (x , x ) = (c x , c x ). The functions s and t 2 1 2 1 2 1 2 3 1 2 1 1 2 2 are neural networks with two hidden layers of size 50. For numerical stability, we found it beneficial to use a modified affine scaling function g as a sigmoid function scaled on a restricted range such as (0.5, 2), as also suggested in [6]. As an alternative, we also consider learning a linear transforma- tion f(x) = Cx for a Cholesky matrix C as well as NUTS and a standard HMC sampler with step size adapted to achieve a target acceptance rate of 0.65. Figure 6 summarizes the ESS where each method uses 4 × 105 samples before and after the adaptation. Whereas a linear transformation does not improve on standard HMC, non-linear transformations can improve the mixing efficiency. (a) (b) (c) Figure 6: Minimum (6a) and mean (6b) effective sample size per second as well as minimum effec- tive sample size (6c) for a Banana-shaped target in dimension d = 2 after adaptation. 5 Discussion and Outlook Limitations. Our approach to learn a constant mass matrix can struggle for targets where the Hes- sian varies greatly across the state space, which can yield relatively short integration times with very high acceptance rates. While this effect might be mitigated by considering non-linear transforma- tions, it remains challenging to learn flexible transformations efficiently in high dimensions. Variations of the entropy objective. Recent work [18, 11] have suggested to add the cross- entropy term (cid:82) π(q) (cid:82) r(q(cid:48)|q) log π(q(cid:48))dq(cid:48)dq to the entropy objective for optimizing the parameters of a Metropolis-Hastings kernel with proposal density r(q(cid:48)|q). Algorithm 1 can be adjusted to such variations, possibly by stopping gradients through ∇U as for optimizing the energy error term. Variations of HMC. We have considered a standard HMC setting for a fixed number of leap-frog steps. One could consider a mixture of HMC kernels with different numbers of leap-frog steps and an interesting question would be how to learn the different mass matrices jointly in an efficient way. Instead of a full velocity refreshment, partial refreshment strategies [33] can sometimes mix better. The suggested adaptation approach can yield very high acceptance rates particularly for increasing leap-frog steps and the learned mass matrix can be used with a partial refreshment. However, it would be interesting to analyse if the adaptation can be adjusted to such persistent velocity updates. It would also be of interest to analyse if similar ideas can be used to adapt different numerical integrators such as those suggested in [7] for target densities relative to a Gaussian measure or for multinomial HMC with an additional intra-trajectory sampling step [9, 59]. Our focus was on learning a mass matrix so that samples from the Markov chain can be used for estimators that are consistent for increasing iterations. However, unbiased estimators might also be constructed using coupled HMC chains [30] and one might ask if the adapted mass matrix leads to shorter meeting times in such a setting. 10
Acknowledgements The authors acknowledge the use of the UCL Myriad High Performance Computing Facility (Myr- iad@UCL), and associated support services, in the completion of this work. Funding Transparency Statement There are no additional sources of funding to disclose. References [1] Christophe Andrieu and E´ ric Moulines. On the ergodicity properties of some adaptive MCMC algorithms. The Annals of Applied Probability, 16(3):1462–1505, 2006. [2] Christophe Andrieu and Johannes Thoms. A tutorial on adaptive MCMC. Statistics and com- puting, 18(4):343–373, 2008. [3] Christophe Andrieu, Vladislav B Tadic, and Matti Vihola. On the stability of some controlled Markov chains and its applications to stochastic approximation with Markovian dynamic. The Annals of Applied Probability, 25(1):1–45, 2015. [4] Christophe Andrieu, Anthony Lee, and Sam Livingstone. A general perspective on the Metropolis-Hastings kernel. arXiv preprint arXiv:2012.14881, 2020. [5] Jens Behrmann, Will Grathwohl, Ricky TQ Chen, David Duvenaud, and Joern-Henrik Jacob- sen. Invertible Residual Networks. In International Conference on Machine Learning, pages 573–582, 2019. [6] Jens Behrmann, Paul Vicol, Kuan-Chieh Wang, Roger Grosse, and Jo¨rn-Henrik Jacobsen. Un- derstanding and mitigating exploding inverses in invertible neural networks. In International Conference on Artificial Intelligence and Statistics, pages 1792–1800. PMLR, 2021. [7] Alexandros Beskos, Frank J Pinski, Jesu´s Maria Sanz-Serna, and Andrew M Stuart. Hybrid Monte Carlo on Hilbert spaces. Stochastic Processes and their Applications, 121(10):2201– 2230, 2011. [8] Alexandros Beskos, Natesh Pillai, Gareth Roberts, Jesus-Maria Sanz-Serna, and Andrew Stu- art. Optimal tuning of the hybrid Monte Carlo algorithm. Bernoulli, 19(5A):1501–1534, 2013. [9] Michael Betancourt. A conceptual introduction to Hamiltonian Monte Carlo. arXiv preprint arXiv:1701.02434, 2017. [10] Nawaf Bou-Rabee and Jesu´s Maria Sanz-Serna. Geometric integrators and the Hamiltonian Monte Carlo method. Acta Numerica, 27:113–206, 2018. [11] Chris Cannella and Vahid Tarokh. Semi-Empirical Objective Functions for MCMC Proposal Optimization. arXiv preprint arXiv:2106.02104, 2021. [12] Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: A probabilistic programming language. Journal of statistical software, 76(1):1–32, 2017. [13] Tian Qi Chen, Jens Behrmann, David K Duvenaud, and Jo¨rn-Henrik Jacobsen. Residual flows for invertible generative modeling. In Advances in Neural Information Processing Systems, pages 9913–9923, 2019. [14] Yuansi Chen, Raaz Dwivedi, Martin J Wainwright, and Bin Yu. Fast mixing of Metropolized Hamiltonian Monte Carlo: Benefits of multi-step gradients. arXiv preprint arXiv:1905.12247, 2019. [15] Zongchen Chen and Santosh S Vempala. Optimal convergence rate of Hamiltonian Monte Carlo for strongly logconcave distributions. arXiv preprint arXiv:1905.02313, 2019. 11
[16] Nicolas Chopin, James Ridgway, et al. Leave Pima Indians alone: binary regression as a benchmark for Bayesian computation. Statistical Science, 32(1):64–87, 2017. [17] Rob Cornish, Anthony L Caterini, George Deligiannidis, and Arnaud Doucet. Relax- ing Bijectivity Constraints with Continuously Indexed Normalising Flows. arXiv preprint arXiv:1909.13833, 2019. [18] Ameer Dharamshi, Vivian Ngo, and Jeffrey S Rosenthal. Sampling by Divergence Minimiza- tion. arXiv preprint arXiv:2105.00520, 2021. [19] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using Real NVP. arXiv preprint arXiv:1605.08803, 2016. [20] Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid Monte Carlo. Physics letters B, 195(2):216–222, 1987. [21] Alain Durmus, Eric Moulines, and Eero Saksman. On the convergence of Hamiltonian Monte Carlo. arXiv preprint arXiv:1705.00166, 2017. [22] Nicolas Durrande, Vincent Adam, Lucas Bordeaux, Stefanos Eleftheriadis, and James Hens- man. Banded matrix operators for Gaussian Markov models in the automatic differentiation era. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 2780– 2789. PMLR, 2019. [23] Hong Ge, Kai Xu, and Zoubin Ghahramani. Turing: A language for flexible probabilistic inference. In International conference on artificial intelligence and statistics, pages 1682– 1690. PMLR, 2018. [24] Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. Bayesian Data Analysis. CRC press, 2013. [25] Mark Girolami and Ben Calderhead. Riemann manifold Langevin and Hamiltonian Monte Carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73 (2):123–214, 2011. [26] Gene H Golub and Charles F Van Loan. Matrix computations, volume 3. JHU Press, 2012. [27] Heikki Haario, Eero Saksman, and Johanna Tamminen. Adaptive proposal distribution for random walk Metropolis algorithm. Computational Statistics, 14(3):375–395, 1999. [28] Ernst Hairer, Christian Lubich, and Gerhard Wanner. Geometric numerical integration illus- trated by the Sto¨rmer–Verlet method. Acta numerica, 12:399–450, 2003. [29] Insu Han, Haim Avron, and Jinwoo Shin. Stochastic Chebyshev gradient descent for spectral optimization. In Advances in Neural Information Processing Systems, pages 7386–7396, 2018. [30] Jeremy Heng and Pierre E Jacob. Unbiased Hamiltonian Monte Carlo with couplings. Biometrika, 106(2):287–302, 2019. [31] Matthew Hoffman, Pavel Sountsov, Joshua V Dillon, Ian Langmore, Dustin Tran, and Srinivas Vasudevan. Neutra-lizing bad geometry in Hamiltonian Monte Carlo using neural transport. arXiv preprint arXiv:1903.03704, 2019. [32] Matthew D Hoffman and Andrew Gelman. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1):1593– 1623, 2014. [33] Alan M Horowitz. A generalized guided Monte Carlo algorithm. Physics Letters B, 268(2): 247–252, 1991. [34] Eric Jacquier, Nicholas G Polson, and Peter E Rossi. Bayesian analysis of stochastic volatility models. Journal of Business & Economic Statistics, 20(1):69–87, 2002. [35] Leif T Johnson and Charles J Geyer. Variable transformation to obtain geometric ergodicity in the random-walk Metropolis algorithm. The Annals of Statistics, 40(6):3050–3076, 2012. 12
[36] Sangjoon Kim, Neil Shephard, and Siddhartha Chib. Stochastic volatility: likelihood inference and comparison with ARCH models. The review of economic studies, 65(3):361–393, 1998. [37] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [38] Ian Langmore, Michael Dikovsky, Scott Geraedts, Peter Norgaard, and Rob Von Behren. A condition number for Hamiltonian Monte Carlo. arXiv preprint arXiv:1905.09813, 2019. [39] Junpeng Lao, Christopher Suter, Ian Langmore, Cyril Chimisov, Ashish Saxena, Pavel Sountsov, Dave Moore, Rif A Saurous, Matthew D Hoffman, and Joshua V Dillon. tfp. mcmc: Modern Markov Chain Monte Carlo tools built for modern hardware. arXiv preprint arXiv:2002.01184, 2020. [40] Daniel Levy, Matt D Hoffman, and Jascha Sohl-Dickstein. Generalizing Hamiltonian Monte Carlo with neural networks. In International Conference on Learning Representations, 2018. [41] Zengyi Li, Yubei Chen, and Friedrich T Sommer. A Neural Network MCMC sampler that maximizes Proposal Entropy. arXiv preprint arXiv:2010.03587, 2020. [42] Samuel Livingstone, Michael Betancourt, Simon Byrne, and Mark Girolami. On the geometric ergodicity of Hamiltonian Monte Carlo. Bernoulli, 25(4A):3109–3138, 2019. [43] Samuel Livingstone, Michael F Faulkner, and Gareth O Roberts. Kinetic energy choice in Hamiltonian/hybrid Monte Carlo. Biometrika, 106(2):303–319, 2019. [44] Anne-Marie Lyne, Mark Girolami, Yves Atchade´, Heiko Strathmann, Daniel Simpson, et al. On Russian roulette estimates for Bayesian inference with doubly-intractable likelihoods. Sta- tistical science, 30(4):443–467, 2015. [45] Oren Mangoubi and Aaron Smith. Rapid mixing of Hamiltonian Monte Carlo on strongly log-concave distributions. arXiv preprint arXiv:1708.07114, 2017. [46] Radford M Neal. MCMC using Hamiltonian dynamics. Handbook of markov chain monte carlo, 2(11):2, 2011. [47] Yurii Nesterov. Primal-dual subgradient methods for convex problems. Mathematical pro- gramming, 120(1):221–259, 2009. [48] Joonha Park and Yves Atchade´. Markov chain Monte Carlo algorithms with sequential pro- posals. Statistics and Computing, 30(5):1325–1345, 2020. [49] Cristian Pasarica and Andrew Gelman. Adaptively scaling the Metropolis algorithm using expected squared jumped distance. Statistica Sinica, pages 343–364, 2010. [50] Gareth O Roberts and Jeffrey S Rosenthal. Coupling and ergodicity of adaptive Markov chain Monte Carlo algorithms. Journal of applied probability, 44(2):458–475, 2007. [51] John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. Probabilistic programming in Python using PyMC3. PeerJ Computer Science, 2:e55, 2016. [52] Jascha Sohl-Dickstein, Mayur Mudigonda, and Michael DeWeese. Hamiltonian Monte Carlo Without Detailed Balance. In International Conference on Machine Learning, pages 719–726, 2014. [53] Pavel Sountsov, Alexey Radul, and contributors. Inference gym, 2020. URL https://pypi. org/project/inference_gym. [54] Michalis Titsias and Petros Dellaportas. Gradient-based Adaptive Markov Chain Monte Carlo. In Advances in Neural Information Processing Systems, pages 15704–15713, 2019. [55] Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bu¨rkner. Rank-normalization, folding, and localization: An improved R for assessing convergence of MCMC. Bayesian analysis, 1(1):1–28, 2021. 13
[56] Ziyu Wang, Shakir Mohamed, and Nando Freitas. Adaptive Hamiltonian and Riemann Mani- fold Monte Carlo. In International conference on machine learning, pages 1462–1470. PMLR, 2013. [57] Changye Wu, Julien Stoehr, and Christian P Robert. Faster Hamiltonian Monte Carlo by learning leapfrog scale. arXiv preprint arXiv:1810.04449, 2018. [58] Kai Xu, Hong Ge, Will Tebbutt, Mohamed Tarek, Martin Trapp, and Zoubin Ghahramani. Ad- vancedhmc. jl: A robust, modular and efficient implementation of advanced HMC algorithms. In Symposium on Advances in Approximate Bayesian Inference, pages 1–10. PMLR, 2020. [59] Kai Xu, Tor Erlend Fjelde, Charles Sutton, and Hong Ge. Couplings for Multinomial Hamilto- nian Monte Carlo. In International Conference on Artificial Intelligence and Statistics, pages 3646–3654. PMLR, 2021. [60] Tengchao Yu, Hongqiao Wang, and Jinglai Li. Maximum conditional entropy Hamiltonian Monte Carlo sampler. SIAM Journal on Scientific Computing, 2021. 14
Appendices A Gradient terms for the adaptation scheme A.1 Gradients for the entropy approximation Following the arguments in [13], we can compute the gradient of the term in (13) using ∂ L(θ) = Tr (cid:32) (cid:88)∞ (−1)k [D ]k ∂ {D }(cid:33) = E (cid:34) (cid:88)N (−1)k ε(cid:62) [D ]k ∂ {D } ε(cid:35) , ∂θ L ∂θ L N,ε p L ∂θ L i i k i k=0 k=0 which yields a stochastic gradient via a Russian-roulette estimator. Additionally, to avoid gradients with infinite means even if D is not contractive, we consider a L spectral normalisation, so that instead of computing recursively η = ε and η = D η for 0 k L k−1 k ∈ {1, . . . , N }, we set η¯ = ε and 0 η¯ = D η¯ · min {1, δ(cid:48) (cid:107)η¯ (cid:107) / (cid:107)D η¯ (cid:107) } (15) k L k−1 k−1 2 L k−1 2 for k ∈ {1, . . . , N } and δ(cid:48) ∈ (0, 1), such as δ(cid:48) = 0.99 in all our experiments. We obtain an estimator ∂ (cid:34) (cid:88)N (−1)k ∂ (cid:35) L(θ) ≈ E η¯(cid:62) {D } ε . ∂θ N,ε p k ∂θ L i k i k=0 A.2 Gradients for the penalty function We used the following penalty function h(x) = (x − δ)21 {x∈[δ,δ2)} + ((δ 2 − δ)2 + (δ 2 − δ)2(x − δ 2))1 {x(cid:62)δ2} throughout our experiments with δ ∈ {0.75, 0.95}, and δ = 1 + δ. The motivation was to have 2 a quadratic increase for the penalty term if the largest absolute eigenvalue approaches 1, and then smoothly switch to a linear function for values larger than δ . Gradients for this function can be 2 computed routinely using automatic differentiation. A.3 Gradients for the energy error We can write the energy error as ∆(q , v) = U (T (v)) − U (q ) + K(W (v)) − K(C−(cid:62)v) 0 L 0 L (cid:18) h2 (cid:19) = U q + LhCv − h2CC(cid:62)Ξ (v) − L CC(cid:62)∇U (q ) − U (q ) 0 L 2 0 0 (cid:13) (cid:13)2 + 1 (cid:13) (cid:13)v − h C [∇U (q ) + ∇U (q )] − hC L (cid:88)−1 ∇U (q )(cid:13) (cid:13) − 1 (cid:107)v(cid:107)2 . (16) 2 (cid:13) 2 0 L (cid:96) (cid:13) 2 (cid:13) (cid:13) (cid:96)=1 Recall from (5) that Ξ (v) is a weighted sum of potential energy gradients along the leap-frog L trajectory. For computing gradients of the energy-error for the fast approximation, we therefore stop the gradient for all ∇U (q ) for any (cid:96) ∈ {1, . . . , L}. (cid:96) B Proof of Lemma 1 Proof. We generalise the arguments from [14], Lemma 7. Proceeding by induction over n, we have for the case n = 1, for any v ∈ Rd, that DT (v) = hC and S (v) = 1 C−1q − h C(cid:62)∇U (q ) with 1 1 h 0 2 0 derivative of zero. For the case n = 2, using (3) and (5), one obtains DT (v) − 2hC − h3CC(cid:62)∇2U (T (v))C (17) 2 1 15
and moreover h2 DS (v) = − C(cid:62)∇2U (T (v))C (18) 2 2 1 which establishes (10). Clearly, (cid:107)DS (v)(cid:107) < 1 if 22h2 < 1 . 2 2 8 4(cid:107)C(cid:62)∇2U(T1(v))C(cid:107) 2 Further, for any n < L, again from (3) and (5), DT (v) = (n + 1)hC − h2CC(cid:62)DΞ (v) n+1 n+1 (cid:34) n (cid:35) (cid:88) = (n + 1)hC − h2CC(cid:62) (n + 1 − i)∇2U (T (v))DT (v) i i i=1 (cid:34) n (cid:35) (cid:88) = (n + 1)hC − h2CC(cid:62) (n + 1 − i)∇2U (T (v))ihC (I +DS (v)) i i i=1 (cid:34) n (cid:35) (cid:88) (n + 1 − i) = (n + 1)hC + (n + 1)hC −h2 iC(cid:62)∇2U (T (v))C (I +DS (v)) , n + 1 i i i=1 which shows the representation (10) for the case n + 1 by recalling that DT (v) = (n + 1)hC(I +DS (v)). n+1 n+1 Assume now that (cid:107)DS (v)(cid:107) < 1/8 holds for all (cid:96) (cid:54) n. Then for any v ∈ Rd (cid:96) 2 (cid:107)DS n+1(v)(cid:107) 2 (cid:54) nh +2 1 (cid:88)n i(n + 1 − i) (cid:13) (cid:13)C(cid:62)∇2U (T i(v))C(cid:13) (cid:13) 2 (cid:107)I +DS i(v)(cid:107) 2 i=1 (cid:54) nh +2 1 (cid:88)n L 42 (cid:13) (cid:13)C(cid:62)∇2U (T i(v))C(cid:13) (cid:13) 2 (cid:107)I +DS i(v)(cid:107) 2 i=1 h2 (cid:88)n L2 1 (cid:18) 1 (cid:19) 1 (cid:54) 1 + (cid:54) n + 1 4 4L2h2 8 8 i=1 where the second inequality follows from (n + 1 − i)i (cid:54) ( n+1−i+i )2 (cid:54) L2 , whereas the third 2 4 inequality follows from the induction hypothesis and the assumption L2h2 < sup 1 . q 4(cid:107)C(cid:62)∇2U(q)C(cid:107) 2 C Extension to learn non-linear transformations The suggested approach can perform poorly for non-convex potentials or even convex potentials such as arsing in a logistic regression model for some data sets. We illustrate here how to learn a reasonable proposal for a general potential function by considering some version of position- dependent preconditioning. Consider an invertible differentiable transformation f : Rd → Rd. The idea now is to run HMC with unit mass matrix for the transformed variables z = f −1(q) where q ∼ π. Write π˜ for the density of z and let U˜ be the corresponding potential energy function which is given by U˜ (z) = U (H(z)) − log | det Df (z)| with gradient ∇U˜ (z) = Df (z)(cid:62)∇U (f (z)) − ∇ log | det Df (z)|. The transformation f as well as U˜ generally depend on some parameters θ that we again omit for a less convoluted notation. Our approach can be seen as an alternative for instance to [31] where such a transformation is first learned by trying to approximate π˜ with a standard Gaussian density using variational inference, while the HMC hyperparameters are adapted in a second step using Bayesian optimisation. We write T˜ : v (cid:55)→ z for the transformation that maps the initial velocity v = p ∼ N (0, I) to the L L 0 L-th leapfrog step z , starting at z based on the potential function U˜ with unit mass matrix M = I. L 0 Analogously, we define the mapping W˜ : v (cid:55)→ p and similarly to (7), we define L L 1 S˜ (v) = T˜ (v) − v. L Lh L 16
We can then reparametrize the proposal at the point q = f (z ) by v (cid:55)→ f (T˜ (v)). Consequently, 0 0 L the log-density of the proposal is given by log r (f (T˜ (v))) = log ν(v) − log | det Df (T˜ (v))| − log | det DT˜ (v)|, L L L L and we can write log | det DT˜ (v)| = d log Lh + log | det(I +DS˜ (v))|. L L We use the same approximation L2 − 1 DS˜ (v) ≈ −h2 ∇2U˜ (z ) L 6 (cid:98)L/2(cid:99) based on the transformed Hessian now. Hessian-vector products can similarly be computed using vector-Jacobian products: With g(z) = grad(U˜ z), we then compute ∇2U˜ (z)w = vjp(g, z, w)(cid:62) for z = f −1(stop grad(f (z )). , (cid:98)L/2(cid:99) The motivation for stopping the gradients comes from considering the special case f : z (cid:55)→ Cz that corresponds to the position-independent preconditioning scheme above. For such a linear transfor- mation, U˜ (z) = C(cid:62)∇2U (Cz)C. To recover the previous case, we stop gradients at q = f (z ) = Cz . (cid:98)L/2(cid:99) (cid:98)L/2(cid:99) (cid:98)L/2(cid:99) Gradients for the log-accept ratio can be computed based on the log-accept ratio of the transformed chain [35]. The energy error of the transformed chain is ∆ (q , v) =U (T˜ (v)) − U (f −1(q )) + K(W˜ (v)) − K(v) θ 0 θ L θ 0 L (cid:110) (cid:104) =U f f −1(q ) + Lhv − h2Ξ˜ (v) 0 L − L h2 (cid:0) Df (f −1(q ))(cid:62)∇U (q ) − ∇ log | det Df (f −1(q ))(cid:1) (cid:105)(cid:111) 2 0 0 0 + log | det Df (z )| − U (q) + log | det Df (f −1(q))| L (cid:12)(cid:12) + 1 (cid:12) (cid:12)(cid:12) (cid:12)v − h (cid:2) Df (z )(cid:62)∇U (f (z )) − ∇ log | det Df (z ) + Df (z )(cid:62)∇U (f (z )) 2 (cid:12)(cid:12) 2 0 0 0 L L (cid:12)(cid:12) − ∇ log | det Df (z )|(cid:3) − h L (cid:88)−1 Df (z )(cid:62)∇U (f (z )) − ∇ log | det Df (z )|(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)2 L (cid:96) (cid:96) (cid:96) (cid:12)(cid:12) (cid:12)(cid:12) (cid:96)=1 1 − (cid:107)v(cid:107)2 , 2 where L Ξ˜ (v) = (cid:88) (L − i) (cid:2) Df (z )(cid:62)∇U (f (z )) − ∇ log | det Df (z )(cid:3) L i i i i=1 and z , . . . , z is the leap-frog trajectory starting at z = f −1(q ). We also stop all U gradients, 0 L 0 0 i.e. ∇U (f (z )) ← stop grad(∇U (f (z )). It can be seen that this recovers the above setting if (cid:96) (cid:96) f : z (cid:55)→ Cz. 17
D Gradient-based adaptation using the expected squared jumping distance and variations We consider the different loss functions (cid:90) (cid:90) (cid:104) (cid:105) F (θ) = − π(q )ν(v) log a{(q , v), (T (v), W (v))} − β log r (T (v)) dvdq GSM 0 0 L L L L 0 (19) (cid:90) (cid:90) (cid:104) (cid:105) F (θ) = − π(q )ν(v) a{(q , v), (T (v), W (v))} (cid:107)q − T (v)(cid:107)2 dvdq (20) ESJD 0 0 L L 0 L 0 (cid:90) (cid:90) (cid:104) a{(q , v), (T (v), W (v))} (cid:107)q − T (v)(cid:107)2 F (θ) = − π(q )ν(v) 0 L L 0 L (21) L2HMC 0 λ λ (cid:105) − dvdq . a{(q , v), (T (v), W (v))} (cid:107)q − T (v)(cid:107)2 0 0 L L 0 L The L2HMC objective (21) has been suggested in Levy et al. [40] for learning generalisations of HMC, although we ignore a burn-in term that has been included originally. In our implementation, we adapt λ > 0 online as a moving average of the expected squared jumping distance. The objectives (20) and (21) can be optimized using stochastic gradient descent similar to Algorithm 1 without the approximations as required for the GSM objective (19). E Proof of the HMC proposal reparameterizations For completeness, we provide a proof of the reparameterization (3) and (4) of the L-th step position q and momentum p using the velocity v that relates to the initial momentum p ∼ N (0, M ) L L 0 via p = C−(cid:62)v. Such representations with an identity mass matrix have been used previously in 0 [42, 21, 14]. Proof. We proceed by induction over (cid:96) ∈ {1, . . . , L}. For the case (cid:96) = 1, the recursions in (2) imply (cid:20) (cid:21) h h q = q + hCC(cid:62) p − ∇U (q ) = q + hCv − CC(cid:62)∇U (q ) 1 0 0 2 0 0 2 0 and (cid:20) (cid:21) h h h p = p − ∇U (q ) − ∇U (q ) = C−(cid:62)v − [∇U (q ) + ∇U (q )] . 1 0 2 0 2 1 2 0 1 Suppose now that the representations hold for 1 (cid:54) (cid:96) < L. Then, using the recursions in (2), (cid:20) (cid:21) h q = q + hCC(cid:62) p − ∇U (q ) (cid:96)+1 (cid:96) (cid:96) 2 (cid:96) = q − (cid:20) (cid:96)h2 CC(cid:62) + h CC(cid:62)(cid:21) ∇U (q ) + (cid:2) (cid:96)hC + hCC(cid:62)C−(cid:62)(cid:3) v − h2CC(cid:62)∇U (q ) 0 2 2 0 (cid:96) (cid:96)−1 (cid:88) − h2CC(cid:62) ∇U (q ) − h2CC(cid:62)Ξ (v) i (cid:96) i=1 (cid:20) h2 (cid:21) (cid:88)(cid:96) = q − ((cid:96) + 1) CC(cid:62) ∇U (q ) + ((cid:96) + 1)hCv − h2CC(cid:62) ∇((cid:96) + 1 − i)∇U (q ). 0 2 0 i i=1 This establishes the representation for q . The induction step for the momentum is a straightforward L application of (2) to the induction hypothesis. 18
F Gaussian targets experiments F.1 High-dimensional Gaussian targets (a) (b) (c) (d) (e) (f) Figure 7: Anisotropic Gaussian target (d = 1000). Minimum (7a), mean (7b) and median (7c) effective sample size of q (cid:55)→ q per second. Average acceptance rates in 7d and estimates of the i eigenvalues of D in 7e. Condition number of transformed Hessian C(cid:62)Σ−1C in 7f. L (a) (b) (c) (d) (e) (f) Figure 8: Independent Gaussian target (d = 10000). Minimum (8a), mean (8b) and median (8c) effective sample size of q (cid:55)→ q per second. Average acceptance rates in 8d and estimates of the i eigenvalues of D in 8e. Condition number of transformed Hessian C(cid:62)Σ−1C in 8f. L 19
F.2 Ill-conditioned anisotropic Gaussian target (a) (b) (c) (d) (e) (f) Figure 9: Ill-conditioned Gaussian target (d = 100). Minimum (9a), mean (9b) and median (9c) effective sample size of q (cid:55)→ q per second. Average acceptance rates in 9d and estimates of the i eigenvalues of D using power iteration in 9e. Condition number of transformed Hessian C(cid:62)Σ−1C L in 9f. Values computed after adaptation. F.3 Correlated Gaussian target (a) (b) (c) (d) (e) (f) Figure 10: Correlated Gaussian target (d = 51). Minimum (10a), mean (10b) and median (10c) effective sample size of q (cid:55)→ q per second. Average acceptance rates in 10d and estimates of i the eigenvalues of D using power iteration in 10e. Condition number of transformed Hessian L C(cid:62)Σ−1C in 10f. Values computed after adaptation. 20
F.4 IID Gaussian target (a) (b) (c) Figure 11: IID Gaussian target (d = 10). Minimum effective sample size of q (cid:55)→ q per second in i 11a and absolute minimum effective sample size where NUTS is run for 1/10-th of the iterations of the other schemes in 11b. Average acceptance rates in 11c. Values computed after adaptation. G Logistic regression experiments G.1 Australian credit data (a) (b) (c) (d) (e) (f) Figure 12: Bayesian logistic regression for Australian Credit data set (d = 15). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 12a, of q (cid:55)→ q2 in 12b and of q (cid:55)→ log π(q) in i i 12b. Median marginal effective sample per second in 12d and average acceptance rates in 12e and estimates of the eigenvalues of D in 12f. L 21
G.2 Heart data (a) (b) (c) (d) (e) (f) Figure 13: Bayesian logistic regression for heart data set (d = 14). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 13a, of q (cid:55)→ q2 in 13b and of q (cid:55)→ log π(q) in 13b. Median i i marginal effective sample per second in 13d and average acceptance rates in 13e and estimates of the eigenvalues of D in 13f. L G.3 Pima data (a) (b) (c) (d) (e) (f) Figure 14: Bayesian logistic regression for Pima data set (d = 8). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 14a, of q (cid:55)→ q2 in 14b and of q (cid:55)→ log π(q) in 14c. Median i i marginal effective sample per second in 14d and average acceptance rates in 14e and estimates of the eigenvalues of D in 14f. L 22
G.4 Ripley data (a) (b) (c) (d) (e) (f) Figure 15: Bayesian logistic regression for Ripley data set (d = 3). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 15a, of q (cid:55)→ q2 in 15b and of q (cid:55)→ log π(q) in 15c. Median i i marginal effective sample per second in 15d and average acceptance rates in 15e and estimates of the eigenvalues of D in 15f. L G.5 German credit data (a) (b) (c) (d) (e) (f) Figure 16: Bayesian logistic regression for German credit data set (d = 25). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 16a, of q (cid:55)→ q2 in 16b and of q (cid:55)→ log π(q) in i i 16c. Median marginal effective sample per second in 16d and average acceptance rates in 16e and estimates of the eigenvalues of D in 16f. L 23
G.6 Caravan data (a) (b) (c) (d) (e) (f) Figure 17: Bayesian logistic regression for Caravan data set (d = 87). Minimum effective sample size per second after adaptation of q (cid:55)→ q in 17a, of q (cid:55)→ q2 in 17b and of q (cid:55)→ log π(q) in i i 17c. Median marginal effective sample per second in 17d and average acceptance rates in 17e and estimates of the eigenvalues of D in 17f. L H Log-Gaussian Cox Point Process (a) (b) (c) Figure 18: Cox process in dimension d = 64. Minimum (18a) and mean (18b) effective sample size per second after adaptation. Estimates of the eigenvalues of D using power iteration in (18c). L I Stochastic volatility model 24
(a) Inverse mass matrix (Λ + (b) Inverse mass matrix CC(cid:62) (c) Inverse mass matrix CC(cid:62) Σ−1)−1 of the Riemann manifold for the entropy-based scheme with for the entropy-based scheme with based samplers. L = 1. L = 5. Figure 19: Inverse mass matrices for the Cox process with d = 256 for the different schemes. (a) (b) (c) (d) (e) (f) Figure 20: MCMC mixing efficiency for the stochastic volatility model (d = 2519) after adaptation: Minimum (20a) and median (20b) effective sample size per second. Maximum (20d) and median (20e) Rˆ of q (cid:55)→ q . Average acceptance rates (20c) and estimates of the eigenvalues of D (20f). i L (a) First 100 dimensions of M−1 (b) Last 100 dimensions of M−1 (c) Last 100 dimensions of M for for L = 5 with a tridiagonal mass for L = 5 with a tridiagonal mass L = 5 with a tridiagonal mass ma- matrix. matrix. trix. Figure 21: Learned (inverse) mass matrices for the stochastic volatility model. 25
